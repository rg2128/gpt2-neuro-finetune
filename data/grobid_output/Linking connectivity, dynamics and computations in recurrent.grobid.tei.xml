<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linking connectivity, dynamics and computations in low-rank recurrent neural networks</title>
				<funder ref="#_uXXnCDb">
					<orgName type="full">Programme Emergences of City of Paris</orgName>
				</funder>
				<funder>
					<orgName type="full">French Government</orgName>
				</funder>
				<funder ref="#_VsTkNSw #_FT2wYn3">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-08-28">28 Aug 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Francesca</forename><surname>Mastrogiuseppe</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire de Neurosciences Cognitives</orgName>
								<address>
									<postCode>INSERM U960</postCode>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Laboratoire de Physique Statistique</orgName>
								<orgName type="laboratory" key="lab2">UMR 8550</orgName>
								<orgName type="institution">CNRS</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">École Normale Supérieure -PSL Research University</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Srdjan</forename><surname>Ostojic</surname></persName>
							<email>srdjan.ostojic@ens.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire de Neurosciences Cognitives</orgName>
								<address>
									<postCode>INSERM U960</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Linking connectivity, dynamics and computations in low-rank recurrent neural networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-08-28">28 Aug 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">AF60BBA1D500E919E36FDD6D017CF0C6</idno>
					<idno type="arXiv">arXiv:1711.09672v2[q-bio.NC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-04-21T20:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>Large scale neural recordings have established that the transformation of sensory stimuli into motor outputs relies on low-dimensional dynamics at the population level, while individual neurons exhibit complex selectivity.</s><s>Understanding how low-dimensional computations on mixed, distributed representations emerge from the structure of the recurrent connectivity and inputs to cortical networks is a major challenge.</s><s>Here, we study a class of recurrent network models in which the connectivity is a sum of a random part and a minimal, low-dimensional structure.</s><s>We show that, in such networks, the dynamics are low dimensional and can be directly inferred from connectivity using a geometrical approach.</s><s>We exploit this understanding to determine minimal connectivity required to implement specific computations, and find that the dynamical range and computational capacity quickly increase with the dimensionality of the connectivity structure.</s><s>This framework produces testable experimental predictions for the relationship between connectivity, low-dimensional dynamics and computational features of recorded neurons.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p><s>Understanding the relationship between synaptic connectivity, neural activity and behavior is a central endeavor of neuroscience.</s><s>Networks of neurons encode incoming stimuli in terms of electrical activity and transform this information into decisions and motor actions through synaptic interactions, thus implementing computations that underly behavior.</s><s>Reaching a simple, mechanistic grasp of the relation between connectivity, activity and behavior is, however, highly challenging.</s><s>Cortical networks, which are believed to constitute the fundamental computational units in the mammalian brain, consist of thousands of neurons that are highly inter-connected through recurrent synapses.</s><s>Even if one were able to experimentally record the activity of every neuron and the strength of each synapse in a behaving animal, understanding the causal relationships between these quantities would remain a daunting challenge because an appropriate conceptual framework is currently lacking <ref type="bibr" target="#b14">(Gao and Ganguli, 2015)</ref>.</s><s>Simplified, computational models of neural networks provide a testbed for developing such a framework.</s><s>In computational models and trained artificial neural networks, the strengths of all synapses and the activity of all neurons are known, yet an understanding of the relation between connectivity, dynamics and input-output computations has been achieved only in very specific cases (e.g.</s><s><ref type="bibr" target="#b18">Hopfield (1982)</ref>; <ref type="bibr" target="#b5">Ben-Yishai et al. (1995)</ref>; <ref type="bibr" target="#b52">Wang (2002)</ref>).</s></p><p><s>One of the most popular and best-studied classes of network models is based on fully random recurrent connectivity <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b7">Brunel, 2000;</ref><ref type="bibr" target="#b50">van Vreeswijk and Sompolinsky, 1996)</ref>.</s><s>Such networks display internally generated irregular activity that closely resembles spontaneous cortical patterns recorded in-vivo <ref type="bibr" target="#b41">(Shadlen and Newsome, 1998)</ref>.</s><s>However, randomly connected recurrent networks display only very stereotyped responses to external inputs <ref type="bibr" target="#b34">(Rajan et al., 2010)</ref>, can implement only a limited range of inputoutput computations and their spontaneous dynamics are typically high dimensional <ref type="bibr" target="#b53">(Williamson et al., 2016)</ref>.</s><s>To implement more elaborate computations and low-dimensional dynamics, classical network models rely instead on highly structured connectivity, in which every neuron belongs to a distinct cluster, and is selective to only one feature of the task (e.g.</s><s><ref type="bibr" target="#b52">Wang (2002)</ref>; <ref type="bibr" target="#b2">Amit and Brunel (1997)</ref>; <ref type="bibr" target="#b23">Litwin-Kumar and Doiron (2012)</ref>).</s><s>Actual cortical connectivity appears to be neither fully random nor fully structured <ref type="bibr" target="#b17">(Harris and Mrsic-Flogel, 2013)</ref>, and the activity of individual neurons displays a similar mixture of stereotypy and disorder <ref type="bibr" target="#b37">(Rigotti et al., 2013;</ref><ref type="bibr" target="#b26">Mante et al., 2013;</ref><ref type="bibr" target="#b9">Churchland and Shenoy, 2007)</ref>.</s><s>To take these observations into account and implement general-purpose computations, a large variety of functional approaches have been developed for training recurrent networks and designing appropriate connectivity matrices <ref type="bibr" target="#b18">(Hopfield, 1982;</ref><ref type="bibr" target="#b19">Jaeger and Haas, 2004;</ref><ref type="bibr" target="#b24">Maass et al., 2007;</ref><ref type="bibr" target="#b45">Sussillo and Abbott, 2009;</ref><ref type="bibr" target="#b12">Eliasmith and Anderson, 2004;</ref><ref type="bibr" target="#b6">Boerlin et al., 2013;</ref><ref type="bibr" target="#b32">Pascanu et al., 2013;</ref><ref type="bibr" target="#b28">Martens and Sutskever, 2011)</ref>.</s><s>A unified conceptual picture of how connectivity determines dynamics and computations is, however, currently missing <ref type="bibr" target="#b4">(Barak, 2017;</ref><ref type="bibr" target="#b44">Sussillo, 2014)</ref>.</s></p><p><s>Remarkably, albeit developed independently and motivated by different goals, several of the functional approaches for designing connectivity appear to have reached similar solutions <ref type="bibr" target="#b18">(Hopfield, 1982;</ref><ref type="bibr" target="#b19">Jaeger and Haas, 2004;</ref><ref type="bibr" target="#b45">Sussillo and Abbott, 2009;</ref><ref type="bibr" target="#b12">Eliasmith and Anderson, 2004;</ref><ref type="bibr" target="#b6">Boerlin et al., 2013)</ref>, in which the implemented computations do not determine every single entry in the connectivity matrix but instead rely on a specific type of minimal, low-dimensional structure, so that in mathematical terms the obtained connectivity matrices are low rank.</s><s>In classical Hopfield networks <ref type="bibr" target="#b18">(Hopfield, 1982;</ref><ref type="bibr" target="#b3">Amit et al., 1985)</ref>, a rank-one term is added to the connectivity matrix for every item to be memorized, and each of these terms fixes a single dimension, i.e. row/column combination, of the connectivity matrix.</s><s>In echo-state <ref type="bibr" target="#b19">(Jaeger and Haas, 2004;</ref><ref type="bibr" target="#b24">Maass et al., 2007)</ref> and FORCE learning <ref type="bibr" target="#b45">(Sussillo and Abbott, 2009)</ref>, and similarly within the Neural Engineering Framework <ref type="bibr" target="#b12">(Eliasmith and Anderson, 2004)</ref>, computations are implemented through feedback loops from readout units to the bulk of the network.</s><s>Each feedback loop is mathematically equivalent to adding a rank-one component and fixing a single row/column combination of the otherwise random connectivity matrix.</s><s>In the predictive spiking theory <ref type="bibr" target="#b6">(Boerlin et al., 2013)</ref> the requirement that information is represented efficiently leads again to a connectivity matrix with similar low-rank form.</s><s>Taken together, the results of these studies suggest that a minimal, low-rank structure added on top of random recurrent connectivity may provide a general and unifying framework for implementing computations in recurrent networks.</s></p><p><s>Based on this observation, here we study a class of recurrent networks in which the connectivity is a sum of a structured, low-rank part and a random part.</s><s>We show that in such networks, both spontaneous and stimulus-evoked activity are low-dimensional and can be predicted from the geometrical relationship between a small number of high-dimensional vectors that represent the connectivity structure and the feed-forward inputs.</s><s>This understanding of the relationship between connectivity and network dynamics allows us to directly design minimal, low-rank connectivity structures that implement specific computations.</s><s>We focus on four tasks of increasing complexity, starting with basic binary discrimination and ending with context-dependent evidence integration <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>.</s><s>We find that the dynamical repertoire of the network increases quickly with the dimensionality of the connectivity structure, so that rank-two connectivity structures are already sufficient to implement complex, context-dependent tasks <ref type="bibr" target="#b26">(Mante et al., 2013;</ref><ref type="bibr" target="#b40">Saez et al., 2015)</ref>.</s><s>For each task, we illustrate the relationship between connectivity, low-dimensional dynamics and the performed computation.</s><s>In particular, our framework naturally captures the ubiquitous observation that single-neuron responses are highly heterogeneous and mixed <ref type="bibr" target="#b37">(Rigotti et al., 2013;</ref><ref type="bibr" target="#b26">Mante et al., 2013;</ref><ref type="bibr" target="#b9">Churchland and Shenoy, 2007;</ref><ref type="bibr" target="#b25">Machens et al., 2010)</ref>, while the dimensionality of the dynamics underlying computations is low and increases with task complexity <ref type="bibr" target="#b14">(Gao and Ganguli, 2015)</ref>.</s><s>Crucially, for each task, our framework produces experimentally testable predictions that directly relate connectivity, the dominant dimensions of the dynamics, and the computational features of individual neurons.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p><s>We studied a class of models which we call low-rank recurrent networks.</s><s>In these networks, the connectivity matrix was given by a sum of an uncontrolled, random matrix and a structured, controlled matrix P .</s><s>The structured matrix P was low rank, i.e. it consisted only of a small number of independent rows and columns, and its entries were assumed to be weak (of order 1/N , where N is the number of units in the network).</s><s>We considered P moreover to be fixed and known, and uncorrelated with the random part gχ, which was considered unknown except for its statistics (mean 0, variance g 2 /N ).</s><s>As in classical models, the networks consisted of N firing rate units with a sigmoid input-output transfer function <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b45">Sussillo and Abbott, 2009)</ref>:</s></p><formula xml:id="formula_0">ẋi (t) = -x i (t) + N j=1 J ij φ(x j (t)) + I i ,<label>(1)</label></formula><p><s>where x i (t) is the total input current to unit i, J ij = gχ ij + P ij is the connectivity matrix, φ(x) = tanh(x) is the current-to-rate transfer function, and I i is the external, feed-forward input to unit i.</s></p><p><s>To connect with the previous literature and introduce the methods that underlie our results, we start by describing the spontaneous dynamics (I i = 0) in a network with a unit-rank structure P .</s><s>We then turn to the response to external inputs, the core of our results that we exploit to demonstrate how low-rank networks can implement four tasks of increasing complexity.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-dimensional spontaneous activity in networks with unit-rank structure</head><p><s>We started with the simplest possible type of low-dimensional connectivity, a matrix P with unit-rank (Fig. <ref type="figure" target="#fig_0">1</ref> A).</s><s>Such a matrix is specified by two N -dimensional vectors m = {m i } and n = {n j }, which fully determine all its entries.</s><s>Every column in this matrix is a multiple of the vector m, and every row is a multiple of the vector n, so that the individual entries are given by</s></p><formula xml:id="formula_1">P ij = m i n j N .<label>(2)</label></formula><p><s>We will call m and n respectively the right-and left-connectivity vectors (as they correspond to the right and left eigenvectors of the matrix P , see Methods), and we consider them arbitrary, but fixed and uncorrelated with the random part of the connectivity.</s><s>As we will show, the spontaneous network dynamics can be directly understood from the geometrical arrangement of the vectors m and n.</s></p><p><s>In absence of structured connectivity, the dynamics are determined by the strength g of the random connectivity: for g &lt; 1, the activity in absence of inputs decays to zero, while for g &gt; 1 it displays strong, chaotic fluctuations <ref type="bibr" target="#b43">(Sompolinsky et al., 1988)</ref>.</s><s>Our first aim was to understand how the interplay between the fixed, low-rank part and the random part of the connectivity shapes the spontaneous activity in the network.</s></p><p><s>Our analysis of network dynamics relies on an effective, statistical description that can be mathematically derived if the network is large and the low-dimensional part of the connectivity is weak (i.e. if P ij scales inversely with the number of units N in the network as in Eq. 2).</s><s>Under those assumptions, the activity of each unit can Side panels: samples of dynamics from finite networks simulations (parameters indicated by colored dots in the phase diagram).</s><s>C-D.</s><s>Activity statistics as the random strength g is increased and the structure strength is fixed to 2.2 (dashed line in B).</s><s>C: Activity along the vector m, as quantified by κ = n i [φ i ] .</s><s>Blue (resp.</s><s>red) lines: theoretical prediction for stationary (resp.</s><s>chaotic) dynamics.</s><s>D: Activity variance due to random connectivity.</s><s>Blue and pink lines: static heterogeneity, red: temporal variance that quantifies chaotic activity.</s><s>Dots: simulations of finite-size networks.</s><s>See Methods for details.</s></p><p><s>be described in terms of the mean and variance of the total input it receives.</s><s>Dynamical equations for these quantities can be derived by extending the classical dynamical mean-field theory <ref type="bibr" target="#b43">(Sompolinsky et al., 1988)</ref>.</s><s>This theory effectively leads to a low-dimensional description of network dynamics in terms of equations for a couple of macroscopic quantities.</s><s>Full details of the analysis are provided in the Methods; here, we focus only on the main results.</s></p><p><s>The central ingredient of the theory is an equation for the average equilibrium input µ i to unit i:</s></p><formula xml:id="formula_2">µ i = κm i , where κ = 1 N N j=1 n j φ j .<label>(3)</label></formula><p><s>The scalar quantity κ represents the overlap between the left-connectivity vector n and the N -dimensional vector [φ] = { φ j } that describes the mean firing activity of the network ([φ j ] is the firing rate of unit j averaged over different realizations of the random component of the connectivity, and depends implicitly on κ).</s><s>The overlap κ therefore quantifies the degree of structure along the vector n in the activity of the network.</s><s>If κ &gt; 0, the equilibrium activity of each neuron is correlated with the corresponding component of the vector n, while κ = 0 implies no such structure is present.</s><s>The overlap κ is the key macroscopic quantity describing the network dynamics, and our theory provides equations specifying its dependence on network parameters.</s></p><p><s>If one represents the network activity as a point in the N -dimensional state-space where every dimension corresponds to the activity of a single unit, Eq. 3 shows that the structured part of the connectivity induces a one-dimensional organization of the spontaneous activity along the vector m.</s><s>This one-dimensional organization, however, emerges only if the overlap κ does not vanish.</s><s>As the activity of the network is organized along the vector m, and κ quantifies the projection of the activity onto the vector n, non-vanishing values of κ require a non-vanishing overlap between vectors m and n.</s><s>This overlap, given by m T n/N = j m j n j /N , directly quantifies the strength of the structure in the connectivity.</s><s>The connectivity structure strength m T n/N and the activity structure strength κ are therefore directly related, but in a highly non-linear manner.</s><s>If the connectivity structure is weak, the network only exhibits homogeneous, unstructured activity corresponding to κ = 0 (Fig. <ref type="figure" target="#fig_0">1</ref> B blue).</s><s>If the connectivity structure is strong, structured heterogeneous activity emerges (κ &gt; 0), and the activity of the network at equilibrium is organized in one dimension along the vector m (Fig. <ref type="figure" target="#fig_0">1</ref> B green and C), while the random connectivity induces additional heterogeneity along the remaining N -1 directions.</s><s>Note that, because of the symmetry in the specific input-output function we use, when a heterogeneous equilibrium state exists, the configuration with the opposite sign is an equilibrium state too, so that the network activity is bistable (for more general asymmetric transfer functions, this bistability is still present, although the symmetry is lost, see Fig. <ref type="figure">S7</ref>).</s></p><p><s>The random part of the connectivity disrupts the organization of the activity induced by the connectivity structure through two different effects.</s><s>The first effect is that as the random strength g is increased, for any given realization of the random part of the connectivity, the total input to unit i will deviate more strongly from the expected mean µ i (Fig. <ref type="figure" target="#fig_0">1 D</ref>).</s><s>As a consequence, the activity along the N -1 directions that are orthogonal to m increases, resulting in a noisy input to individual neurons that smoothens the gain of the non-linearity.</s><s>This effectively leads to a reduction of the overall structure in the activity as quantified by κ (Fig. <ref type="figure" target="#fig_0">1 C</ref>).</s><s>A second, distinct effect is that increasing the random strength eventually leads to chaotic activity as in purely random networks.</s><s>Depending on the strength of the structured connectivity, two different types of chaotic dynamics can emerge.</s><s>If the disorder in the connectivity is much stronger than structure, the overlap κ is zero (Fig. <ref type="figure" target="#fig_0">1 C</ref>).</s><s>As a result, the mean activity of all units vanishes and the dynamics consist of unstructured, N -dimensional temporal fluctuations (Fig. <ref type="figure" target="#fig_0">1 D</ref>), as in the classical chaotic state of fully random networks (Fig. <ref type="figure" target="#fig_0">1</ref> B red).</s><s>In contrast, if the strengths of the random and structured connectivity are comparable, a structured type of chaotic activity emerges, in which κ &gt; 0 so that the mean activity of different units is organized in one dimension along the direction m as shown by Eq. 3, but the activity of different units now fluctuates in time (Fig. <ref type="figure" target="#fig_0">1</ref> B orange).</s><s>As for structured static activity, in this situation the system is bistable as states with opposite signs of κ always exist.</s></p><p><s>The phase diagram in Fig. <ref type="figure" target="#fig_0">1</ref> B summarizes the different types of spontaneous dynamics that can emerge as function of the strength of structured and random components of the connectivity matrix.</s><s>Altogether, the structured component of connectivity favors a one-dimensional organization of network activity, while the random component favors high-dimensional, chaotic fluctuations.</s><s>Particularly interesting activity emerges when the structure and disorder are comparable, in which case the dynamics show one-dimensional structure combined with high-dimensional temporal fluctuations that can give rise to dynamics with very slow timescales (see Fig. <ref type="figure" target="#fig_12">S6</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Two-dimensional activity in response to an external input</head><p><s>We now turn to the response to an external, feed-forward input (Fig. <ref type="figure" target="#fig_1">2 A</ref>).</s><s>At equilibrium, the total average input to unit i is the sum of a recurrent input κm i and the feed-forward input I i :</s></p><formula xml:id="formula_3">µ i = κm i + I i , where κ = 1 N N j=1 n j φ j .<label>(4)</label></formula><p><s>Transient, temporal dynamics close to this equilibrium are obtained by including temporal dependencies in κ and I i (see Methods, Eq. 102).</s><s>Fig. <ref type="figure" target="#fig_1">2</ref> B illustrates the response of the network to a step input.</s><s>The response of individual units is highly heterogeneous, different units showing increasing, decreasing or multi-phasic responses.</s><s>While every unit responds differently, the theory predicts that, at the level of the N -dimensional state space representing the activity of the whole population, the trajectory of the activity lies on average on the two-dimensional plane spanned by the right-connectivity vector m and the vector I = {I i } that corresponds to the pattern of external inputs (Fig. <ref type="figure" target="#fig_1">2</ref> B).</s><s>Applying to the simulated activity a dimensionality reduction technique (see <ref type="bibr" target="#b10">Cunningham and Yu (2014)</ref>  for a recent review) such as Principal Components Analysis confirms that the two dominant dimensions of the activity indeed lie in the m -I plane (Fig. <ref type="figure" target="#fig_1">2 C</ref>), while the random part of connectivity leads to additional activity in the remaining N -2 directions that grows quickly with the strength of random connectivity g (see Fig. <ref type="figure" target="#fig_2">S3</ref>).</s><s>This approach therefore directly links the connectivity in the network to the emerging low-dimensional dynamics, and shows that the dominant dimensions of activity are determined by a combination of feed-forward inputs and connectivity <ref type="bibr" target="#b51">(Wang et al., 2018)</ref>.</s><s>The contribution of the connectivity vector m to the two-dimensional trajectory of activity is quantified by the overlap κ between the network activity [φ] and the left-connectivity vector n (Eq.</s><s>4).</s><s>If κ = 0, the activity trajectory is one-dimensional, and simply propagates the pattern of feed-forward inputs.</s><s>This is in particular the case for fully random networks.</s><s>If κ = 0, the network response is instead a non-trivial two-dimensional combination of the input and connectivity structure patterns.</s><s>In general, the value of κ, and therefore the organization of network activity, depends on the geometric arrangement of the input vector I with respect to the connectivity vectors m and n, as well as on the strength of the random component of the connectivity g.</s></p><p><s>As the neural activity lies predominantly in the m -I plane, a non-vanishing κ, together with non-trivial two-dimensional activity is obtained when the vector n has a non-zero component in the m -I plane.</s><s>Two qualitatively different input-output regimes can be distinguished.</s><s>The first one is obtained when the connectivity vectors m and n are orthogonal to each other (Fig. <ref type="figure" target="#fig_1">2</ref> D left and center).</s><s>In that case, the overlap between them is zero, and the spontaneous activity in the network bears no sign of the underlying connectivity structure.</s><s>Adding an external input can, however, reveal this connectivity structure and generate non-trivial two-dimensional activity if the input vector I has a non-zero overlap with the left-connectivity vector n.</s><s>In such a situation, the vector n picks up the component of the activity along the feed-forward input direction I.</s><s>This leads to a non-zero overlap κ, which in turn implies that the network activity will have a component along the rightconnectivity vector m.</s><s>Increasing the external input along the direction of n will therefore progressively increase the response along m (Fig. <ref type="figure" target="#fig_1">2</ref> D center), leading to a two-dimensional output.</s></p><p><s>A second, qualitatively different input-output regime is obtained when the connectivity vectors m and n have a strong enough overlap along a common direction (Fig. <ref type="figure" target="#fig_1">2</ref> D right).</s><s>As already shown in Fig. <ref type="figure" target="#fig_0">1</ref>, an overlap larger than unity between m and n induces bistable, structured spontaneous activity along the dimension m.</s><s>Adding an external input along the vector n increases the activity along m, but also eventually suppresses one of the bistable states.</s><s>Large external inputs along the n direction therefore reliably set the network into a state in which the activity is a two-dimensional combination of the input direction and the connectivity direction m.</s><s>This can lead to a strongly non-linear input-output transformation if the network was initially set in the state that lies on the opposite branch (Fig. <ref type="figure" target="#fig_1">2 D right</ref>).</s></p><p><s>An additional effect of an external input is that it generally tends to suppress chaotic activity present when the random part of connectivity is strong (Figs.</s><s><ref type="figure" target="#fig_2">S3</ref> and<ref type="figure" target="#fig_3">S4</ref>).</s><s>This suppression occurs irrespectively of the specific geometrical configuration between the input I and connectivity vectors m and n, and therefore independently of the two input-output regimes described above.</s><s>Altogether, external inputs suppress both chaotic and bistable dynamics (Fig. <ref type="figure" target="#fig_3">S4</ref>), and therefore always decrease the amount of variability in the dynamics <ref type="bibr" target="#b8">(Churchland and al., 2010;</ref><ref type="bibr" target="#b34">Rajan et al., 2010)</ref>.</s></p><p><s>In summary, external, feed-forward inputs to a network with unit-rank connectivity structure in general lead to two-dimensional trajectories of activity.</s><s>The elicited trajectory depends on the geometrical arrangement of the pattern of inputs with respect to the connectivity vectors m and n, which play different roles.</s><s>The rightconnectivity vector m determines the output pattern of network activity, while the left-connectivity vector n instead selects the inputs that give rise to outputs along m.</s><s>An output structured along m can be obtained when n selects recurrent inputs (non-zero overlap between n and m) or when it selects external inputs (non-zero overlap between n and I).</s></p><p><s>Higher-rank structure leads to a rich dynamical repertoire This far we focused on unit-rank connectivity structure, but our framework can be directly extended to higher rank structure.</s><s>A more general structured component of rank r N can be written as a superposition of r independent unit-rank terms</s></p><formula xml:id="formula_4">P ij = m (1) i n (1) j N + . . . + m (r) i n (r) j N ,<label>(5)</label></formula><p><s>and is in principle characterized by 2r vectors m (k) and n (k) .</s><s>In such a network, the average dynamics lie in the (r + 1)-dimensional subspace spanned by the r right-connectivity vectors m (k) , k = 1, . . .</s><s>, r and the input vector I, while the left connectivity vectors n (k) select the inputs amplified along the corresponding dimension m (k) .</s><s>The details of the dynamics will in general depend on the geometrical arrangement of these 2r vectors among themselves and with respect to the input pattern.</s><s>The number of possible configurations increases quickly with the structure rank, leading to a wide repertoire of dynamical states that includes continuous attractors (Fig. <ref type="figure" target="#fig_4">S5</ref>) and sustained oscillatory activity (Fig. <ref type="figure">S8</ref>).</s><s>In the remainder of this manuscript, we will explore only the rank-two case.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementing a simple discrimination task</head><p><s>Having developed an intuitive, geometric understanding of how a given unit-rank connectivity structure determines the low-dimensional dynamics in a network, we now reverse our approach to ask how a given computation can be implemented by choosing appropriately the structured part of the connectivity.</s><s>We start with the computation underlying one of the most basic and most common behavioral tasks, Go-Nogo stimulus discrimination.</s><s>In this task, an animal has to produce a specific motor output, e.g.</s><s>press a lever or lick a spout, in response to a stimulus I A (the Go stimulus), and ignore another stimuli I B (Nogo stimuli).</s><s>This computation can be implemented in a straightforward way in a recurrent network with a unit-rank connectivity structure.</s><s>While such a simple computation does not in principle require a recurrent network, the implementation we describe here illustrates in a transparent manner the relationship between connectivity, dynamics and computations in low-rank networks, and leads to non-trivial and directly testable experimental predictions.</s><s>It also provides the basic building block for more complex tasks, which we turn to in the next sections.</s></p><p><s>We model the sensory stimuli as random patterns of external inputs to the network, so that the two stimuli are represented by two fixed, randomly-chosen N -dimensional vectors I A and I B .</s><s>To model the motor response, we supplement the network with an output unit, which produces a linear readout z(t) = 1 N i w i φ(x i (t)) of network activity (Fig. <ref type="figure" target="#fig_2">3 A</ref>).</s><s>The readout weights w i are chosen randomly and form also a fixed N -dimensional vector w.</s><s>The task of the network is to produce an output that is selective to the Go stimulus: the readout z at the end of stimulus presentation needs to be non-zero for the input pattern I A that corresponds to the Go stimulus, and zero for the other input I B .</s></p><p><s>The two N -dimensional vectors m and n that generate the appropriate unit-rank connectivity structure to implement the task can be directly determined from our description of network dynamics.</s><s>As shown in Eq. 4 and Fig. <ref type="figure" target="#fig_1">2</ref>, the response of the network to the input pattern I is in general two-dimensional and lies in the plane spanned by the vectors m and I.</s><s>The output unit will therefore produce a non-zero readout only if the readout vector w has a non-vanishing overlap with either m or I.</s><s>As w is assumed to be uncorrelated, and therefore orthogonal, to all input patterns, this implies that the connectivity vector m needs to have a non-zero overlap with the readout vector w for the network to produce a non-trivial output.</s><s>This output will depend on the amount of activity along m, quantified by the overlap κ.</s><s>As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, the overlap κ will be non-zero only if n has a non-vanishing overlap with the input pattern.</s><s>Altogether, implementing the Go-Nogo task therefore requires that the right-connectivity vector m is correlated with the readout vector w, and that the left-connectivity vector n is correlated with the Go stimulus I A .</s></p><p><s>Choosing m = w and n = I A , therefore provides the simplest unit-rank connectivity that implements the desired computation.</s><s>Fig. <ref type="figure" target="#fig_2">3</ref> illustrates the activity in the corresponding network.</s><s>At the level of individual units, by construction both stimuli elicit large and heterogeneous responses (Fig. <ref type="figure" target="#fig_2">3 B</ref>) that display mixed selectivity (Fig. <ref type="figure" target="#fig_2">3 D</ref>).</s><s>As predicted by the theory, the response to stimulus B is dominantly one-dimensional and organized along the input direction I B , while the response to stimulus A is two-dimensional and lies in the plane defined by the right-connectivity vector m and the input direction I A (Fig. <ref type="figure" target="#fig_2">3 C</ref>).</s><s>The readout from the network corresponds to the projection of the activity onto the m direction, and is non-zero only in response to stimulus A (Fig. <ref type="figure" target="#fig_2">3</ref> E), so that the network indeed implements the desired Go-Nogo task.</s><s>Our framework therefore allows us to directly link the connectivity, the low-dimensional dynamics and the computation performed by the network, and leads to two experimentally testable predictions.</s><s>The first one is that performing a dimensionality-reduction separately on responses to the two stimuli should lead to larger dimensionality of the trajectories in response to the Go stimulus.</s><s>The second prediction is that for the Go stimulus, the dominant directions of activity depend on the recurrent connectivity in the network, while for the Nogo stimulus they do not.</s><s>More specifically, for the activity elicited by the Go stimulus, the dominant principal components are combinations of the input vector I A and right-connectivity vector m.</s><s>Therefore if two neurons have large principal component weights, they are expected to also have large m weights and therefore stronger mutual connections than average (Fig. <ref type="figure" target="#fig_2">3</ref> F top).</s><s>In contrast, for the activity elicited by the Nogo stimulus, the dominant principal components are determined solely by the feed-forward input, so that no correlation between dominant PC weights and recurrent connectivity is expected (Fig. <ref type="figure" target="#fig_2">3</ref> F bottom).</s><s>This prediction can in principle be directly tested in experiments analogous to <ref type="bibr" target="#b22">Ko et al. (2011)</ref>, where calcium imaging in behaving animals is combined with measurements of connectivity in a subset of recorded neurons.</s><s>Note that in this setup very weak structured connectivity is sufficient to implement computations, so that the expected correlations may be weak if the random part of the connectivity is strong (see Fig. <ref type="figure" target="#fig_4">S5</ref>).</s></p><p><s>The unit-rank connectivity structure forms the fundamental scaffold for the desired input-output transform.</s><s>The random part of the connectivity adds variability around the target output, and can induce additional chaotic fluctuations.</s><s>Summing the activity of individual units through the readout unit, however, averages out this heterogeneity, so that the readout error decreases with network size as 1/ √ N (Fig. <ref type="figure" target="#fig_4">S5</ref>).</s><s>The present implementation is therefore robust to noise, and has desirable computational properties in terms of generalization to novel stimuli.</s><s>In particular, it can be extended in a straightforward way to the detection of a category of Go stimuli, rather than a single stimulus (Fig. <ref type="figure" target="#fig_2">3 G</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detection of a noisy stimulus</head><p><s>We now turn to a slightly more complex task: integration of a continuous, noisy stimulus.</s><s>In contrast to the previous discrimination task, where the stimuli were completely different (i.e.</s><s>orthogonal), here we consider a continuum of stimuli that differ only along the intensity of a single feature, such as the coherence of a random-dot kinetogram <ref type="bibr" target="#b30">(Newsome et al., 1989)</ref>.</s><s>In a given stimulus presentation, this feature moreover fluctuates in time.</s><s>We therefore represent each stimulus as c(t)I, where I is a fixed, randomly chosen input vector that encodes the relevant stimulus feature, and c(t) is the amplitude of that feature.</s><s>We consider a Go-Nogo version of this task, in which the network has to produce an output only if the average value of c is larger than a threshold (Fig. <ref type="figure" target="#fig_3">4 A</ref>).</s></p><p><s>As for the basic discrimination task, the central requirements for a unit-rank network to implement this task are that the right-connectivity vector m is correlated with the readout vector w, and the left-connectivity vector n is correlated with the input pattern I.</s><s>A key novel requirement in the present task is however that the response needs to be non-linear to produce the Go output when the strength of the input along I is larger than the threshold.</s><s>As shown in Fig. <ref type="figure" target="#fig_1">2</ref> D, such a non-linearity can be obtained when the left-and right-connectivity vectors n and m have a strong enough overlap.</s><s>We therefore add a shared component to m and n along a direction orthogonal to both w and I.</s><s>In that setup, if the stimulus intensity c is low, the network will be in a bistable regime, in which the activity along the direction m can take two distinct values for the same input (Fig. <ref type="figure" target="#fig_1">2</ref> D right).</s><s>Assuming that the lower state represents a Nogo output, and that the network is initialized in this state at the beginning of the trial, increasing the stimulus intensity c above a threshold will lead to a sudden jump, and therefore a non-linear detection of the stimulus.</s><s>Because the input amplitude fluctuates noisily in time, whether such a jump occurs depends on the integrated estimate of the stimulus intensity.</s><s>The timescale over which this estimate is integrated is determined by the time-constant of the effective exponential filter describing the network dynamics.</s><s>In our unit-rank network, this time-constant is set by the connectivity strength, i.e. the overlap between the left-and right-connectivity vectors m and n, which also determines the value of the threshold.</s><s>Arbitrarily large timescales can be obtained by adjusting this overlap close to the bifurcation value, in which case the threshold becomes arbitrarily small (Fig. <ref type="figure" target="#fig_3">4 F</ref>).</s><s>In this section, we fix the structure strength so that the threshold is set to 0.5, which corresponds to an integration timescale of the order of the time constant of individual units.</s></p><p><s>Fig. <ref type="figure" target="#fig_3">4</ref> illustrates the activity in an example implementation of this network.</s><s>In a given trial, as the stimulus is noisy, the activity of the individual units fluctuates strongly (Fig. <ref type="figure" target="#fig_3">4 B</ref>).</s><s>Our theory predicts that the population trajectory on average lies in the plane defined by the connectivity vector m and the input pattern I (Fig. <ref type="figure" target="#fig_3">4 D</ref>).</s><s>Activity along the m direction is picked up by the readout, and its value at the end of stimulus presentation determines the output (Fig. <ref type="figure" target="#fig_3">4 C</ref>).</s><s>Because of the bistable dynamics in the network, whether the m direction is explored, and an output produced, depends on the specific noisy realization of the stimulus.</s><s>Stimuli with an identical average strength can therefore either lead to two-dimensional trajectories of activity and Go responses, or one-dimensional trajectories of activity corresponding to Nogo responses (Fig. <ref type="figure" target="#fig_3">4 D</ref>).</s><s>The probability of generating an output as function of stimulus strength follows a sigmoidal psychometric curve that reflects the underlying bistability (Fig. <ref type="figure" target="#fig_3">4 G</ref>).</s><s>Note that the bistability is not clearly apparent on the level of individual units.</s><s>In particular, the activity of individual units is always far from saturation, as their inputs are distributed along a zero-centered Gaussian (Eq.</s><s>4).</s></p><p><s>The responses of individual units are strongly heterogeneous and exhibit mixed selectivity to stimulus strength and output choice (Fig. <ref type="figure" target="#fig_3">4 E</ref>).</s><s>A popular manner to interpret such activity at the population level is a targeted dimensional reduction approach, in which input and choice dimensions are determined through regression analyses <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>.</s><s>As expected from our theoretical analysis, the two dimensions obtained through regression are closely related to m and I; in particular, the choice dimension is highly correlated with the right-connectivity vector m (Fig. <ref type="figure" target="#fig_3">4 E</ref>).</s><s>As a result, the plane in which network activity dominantly lies corresponds to the plane defined by the choice and the input dimensions (Fig. <ref type="figure" target="#fig_3">4 D</ref>).</s><s>Our framework therefore directly links recurrent connectivity and effective output choice direction through the low-dimensional dynamics.</s><s>A resulting experimentally testable prediction is that neurons with strong choice regressors have stronger mutual connections (Fig. <ref type="figure" target="#fig_3">4 H</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A context-dependent discrimination task</head><p><s>We next consider a context-dependent discrimination task, in which the relevant response to a stimulus depends on an additional, explicit contextual cue.</s><s>Specifically, we focus on the task studied in <ref type="bibr" target="#b40">Saez et al. (2015)</ref> where in one context (referred to as Context A), the stimulus A requires a Go output, and the stimulus B a Nogo, while in the other context (referred to as Context B), the associations are reversed (Fig. <ref type="figure" target="#fig_4">5 A</ref>).</s><s>This task is a direct extension of the basic binary discrimination task introduced in Fig. <ref type="figure" target="#fig_2">3</ref>, yet it is significantly more complex as it represents a hallmark of cognitive flexibility: a non-linearly separable, XOR-like computation that a single-layer feed-forward network cannot solve <ref type="bibr" target="#b36">(Rigotti et al., 2010;</ref><ref type="bibr" target="#b13">Fusi et al., 2016)</ref>.</s><s>We will show that this task can be implemented in a rank-two recurrent network that is a direct extension of the unit-rank network used for the discrimination task in Fig. <ref type="figure" target="#fig_3">4</ref>.</s></p><p><s>This context-dependent task can be seen as a combination of two basic, opposite Go-Nogo discriminations, each of which can be independently implemented by a unit-rank structure with the right-connectivity vector m correlated to the readout, and the left-connectivity vector correlated to the Go input (I A for Context A, I B for Context B).</s><s>Combining two such unit-rank structures, with left-connectivity vectors n (1) and n (2) correlated respectively with I A and I B , leads to a rank-two connectivity structure that serves as a scaffold for the present task.</s><s>The cues for context A and B are represented by additional inputs along random vectors I ctxA and I ctxB , presented for the full length of the trial <ref type="bibr" target="#b35">(Remington et al., 2018)</ref> (Fig. <ref type="figure" target="#fig_4">5 C</ref>).</s><s>These inputs are the only contextual information incorporated in the network.</s><s>In particular, the readout vector w is fixed and independent of the context <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>.</s><s>Crucially, since the readout w needs to produce an output for both input stimuli, both right-connectivity vectors m (1) and m (2) need to be correlated with it.</s></p><p><s>The key requirement for implementing context-dependent discrimination is that each contextual input effectively switches off the irrelevant association.</s><s>To implement this requirement, we rely on the same non-linearity as for the noisy discrimination task, based on the overlap between the left-and right-connectivity vectors (Fig. <ref type="figure" target="#fig_1">2  D</ref>).</s><s>We however exploit an additional property, which is that the threshold of the non-linearity (i.e. the position of the transition from a bistable to a mono-stable region in Fig. <ref type="figure" target="#fig_1">2 D</ref>) can be controlled by an additional modulatory input along the overlap direction between m and n (Figs. 5 B and S4).</s><s>Such a modulatory input acts as an effective offset for the bistability at the macroscopic, population level (see Eq. 153 in Methods).</s><s>A stimulus of a given strength (e.g. unit strength in Fig. <ref type="figure" target="#fig_4">5 B</ref>) may therefore induce a transition from the lower to the upper state (Fig. <ref type="figure" target="#fig_4">5</ref> B top), or no transition (Fig. <ref type="figure" target="#fig_4">5</ref> B bottom) depending on the strength of the modulatory input that sets the threshold value.</s><s>While in the noisy discrimination task, the overlap between m and n was chosen in an arbitrary direction, in the present setting we take the overlaps between each pair of left-and right-connectivity vectors to lie along the direction of the corresponding contextual input (i.e.</s><s>m (1) and n (1) overlap along I ctxA , m (2) and n (2) along I ctxB ), so that contextual inputs directly modulate the threshold of the non-linearity.</s><s>The final rank-two setup is described in detail in the Methods.</s></p><p><s>Fig. <ref type="figure" target="#fig_4">5</ref> illustrates the activity in an example of the resulting network implementation.</s><s>The contextual cue is present from the very beginning of the trial, and effectively sets the network in a context-dependent initial state (Fig. <ref type="figure" target="#fig_4">5 C</ref>) that corresponds to the lower of the two bistable states.</s><s>The low-dimensional response of the network to the following stimulus is determined by this initial state and the sustained contextual input.</s><s>If the cue for context A is present, stimulus A leads to the crossing of the non-linearity, a transition from the lower to the upper state, and therefore a two-dimensional response in the plane determined by I A and w (Figs. 5 E top left), generating a Go output (Fig. <ref type="figure" target="#fig_4">5 D</ref>).</s><s>In contrast, if the cue for context B is present, the threshold of the underlying non-linearity is increased in the direction of input I A (Fig. <ref type="figure" target="#fig_4">5</ref> B bottom), so that the presentation of stimulus A does not induce a transition between the lower and upper states, but leads only to a one-dimensional trajectory orthogonal to the readout, and therefore a Nogo response (Fig. <ref type="figure" target="#fig_4">5</ref> E top right).</s><s>The situation is totally symmetric in response to stimulus B (Fig. <ref type="figure" target="#fig_4">5</ref> E bottom), so that contextual cues fully reverse the stimulus-response associations (Fig. <ref type="figure" target="#fig_4">5 F</ref>).</s><s>Overall, this context-dependent discrimination relies on strongly non-linear interactions between the stimulus and contextual inputs, that on the connectivity level are implemented by overlaps between the connectivity vectors along the contextual inputs.</s><s>A central, experimentally testable prediction of our framework is therefore that, if a network is implementing this computation, units with strong contextual selectivity have on average stronger mutual connections (Fig. <ref type="figure" target="#fig_4">5 G</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A context-dependent evidence integration task</head><p><s>We finally examine a task inspired by <ref type="bibr" target="#b26">Mante et al. (2013)</ref> that combines context-dependent output and fluctuating, noisy inputs.</s><s>The stimuli now consist of superpositions of two different features A and B, and the strengths of both features fluctuate in time during a given trial.</s><s>In <ref type="bibr" target="#b26">Mante et al. (2013)</ref>, the stimuli were random dot kinetograms, and the features A and B corresponded to the direction of motion and color of these stimuli.</s><s>The task consists in classifying the stimuli according to one of those features, the relevant one being indicated by an explicit contextual cue (Fig. <ref type="figure" target="#fig_5">6 A</ref>).</s></p><p><s>We implemented a Go-Nogo version of the task, in which the output is required to be non-zero when the relevant feature is stronger than a prescribed threshold (arbitrarily set to 0.5).</s><s>The present task is therefore a direct combination of the detection task introduced in Fig. <ref type="figure" target="#fig_3">4</ref> and the context-dependent discrimination task of Fig. <ref type="figure" target="#fig_4">5</ref>, but the individual stimuli are now two-dimensional, as they consist of two independently varied features A and B. In this task, a significant additional difficulty is that on every trial the irrelevant feature needs to be ignored, even if it is stronger than the relevant feature (e.g.</s><s>color coherence stronger than motion coherence on a motion-context trial).</s></p><p><s>This context-dependent evidence integration task can be implemented with exactly the same rank-two configuration as the basic context-dependent discrimination in Fig. <ref type="figure" target="#fig_4">5</ref>, with contextual gating relying on the same non-linear mechanism as in Fig. <ref type="figure" target="#fig_4">5</ref> B. The contextual cue is presented throughout the trial (Fig. <ref type="figure" target="#fig_5">6</ref> B), and determines which of the features of the two-dimensional stimulus leads to non-linear dynamics along the direction of connectivity vectors m (1) and m (2) (Fig. <ref type="figure" target="#fig_5">6 D</ref>).</s><s>These directions share a common component along the readout vector w, and the readout unit picks up the activity along that dimension.</s><s>As a consequence, depending on the contextual cue, the same stimulus can lead to opposite outputs (Fig. <ref type="figure" target="#fig_5">6 C</ref>).</s><s>Altogether, in Context A, the output is independent of the values of feature B, and conversely in Context B (Fig. <ref type="figure" target="#fig_5">6 E</ref>).</s><s>The output therefore behaves as if it were based on two orthogonal readout directions, yet the readout direction is unique and fixed, and the output relies instead on a context-dependent selection of the relevant input feature <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>.</s></p><p><s>An important additional requirement in the present task with respect to the basic context-dependent integration is that the network needs to perform temporal integration to average out temporal fluctuations in the stimulus.</s><s>As illustrated in Fig. <ref type="figure" target="#fig_5">6 B-C</ref>, the network dynamics in response to stimuli indeed exhibit a slow timescale, and progressively integrate the input.</s><s>Strikingly, such slow dynamics do not require additional constraints on network connectivity; they are a direct consequence of the rank-two connectivity structure used In every trial, a pair of contextual inputs determines the relevant input feature.</s><s>The task consists in producing an output if the average strength of the relevant feature is larger than a threshold.</s><s>B. Dynamics in a sample network.</s><s>Top: stimulus and contextual inputs.</s><s>Bottom: activity of four units in contexts A (crimson) and B (pink).</s><s>C. Readout dynamics in the two contexts.</s><s>D. Average population trajectories projected onto the planes spanned by vectors w, I A and I B .</s><s>Blue (resp.</s><s>green) trajectories have been sorted according to the value of the strength of stimulus A (resp.</s><s>B), and averaged across stimulus B (resp.</s><s>A).</s><s>E. Network performance.</s><s>Top row: probability of response as function of input strengths cA and cB (simulated data).</s><s>Bottom: probability of response averaged over cB .</s><s>Continuous line: theoretical prediction; dots: simulations.</s><s>F. Projection of the population activity onto the plane defined by the orthogonal components of the vectors m (1) and m (2) , and comparison with the underlying circular attractor (see Methods).</s><s>Trajectories are sorted by the strength of the relevant stimulus, and averaged across the non-relevant one.</s><s>The direction of the projections of the regression axes for choice and context are indicated in gray.</s><s>See Methods for details.</s></p><p><s>for contextual gating (in fact the dynamics are already slow in the basic contextual discrimination task, see Fig. <ref type="figure" target="#fig_4">5 C-D</ref>).</s><s>More specifically, the symmetry between the two contexts implies that two sets of left-and rightconnectivity vectors have identical overlaps (i.e.</s><s>m (1)T n (1) = m (2)T n (2) ).</s><s>Without further constraints on the connectivity, such a symmetric configuration leads to an emergence of a continuous line attractor, with the shape of a two-dimensional ring in the plane defined by m (1) and m (2) (see Methods and Fig. <ref type="figure" target="#fig_4">S5</ref>).</s><s>In the implementation of the present task, on top of symmetric overlaps, the four connectivity vectors include a common direction along the readout vector.</s><s>This additional constraint eliminates the ring attractor, and stabilizes only two equilibrium states that correspond to Go and Nogo outputs.</s><s>Yet, the ring attractor is close in parameter space, and this proximity induces a slow manifold in the dynamics, so that the trajectories leading to a Go output slowly evolve along two different sides of the underlying ring depending on the context (Fig. <ref type="figure" target="#fig_5">6 F</ref>).</s><s>As a result, the two directions in the plane m (1) -m (2) correspond to choice and context axis as found by regression analysis (Fig. <ref type="figure" target="#fig_5">6 F</ref>).</s><s>A similiar mechanism for context-dependent evidence integration based on a line attractor was previously identified by reverse-engineering a trained recurrent network <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>.</s><s>Whether the underlying dynamical structure was a ring as in our case, or two line attractors for the two contexts depended on the details of the network training protocol (V.</s><s>Mante, Cosyne 2018).</s><s>Here we show that such a mechanism based on a ring attractor can be implemented in a minimal network with rank-two connectivity structure, but other solutions can certainly be found.</s><s>Note that this rank-two network can also serve as an alternative implementation for context-independent evidence integration in which the integration timescale and the threshold value are fully independent in contrast to the unit-rank implementation (Fig. <ref type="figure" target="#fig_3">4</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p><s>Motivated by the observation that a variety of approaches for implementing computations in recurrent networks rely on a common type of connectivity structure, we studied a class of models in which the connectivity matrix consists of a sum of a fixed, low-rank term and a random part.</s><s>Our central result is that the low-rank connectivity structure induces low-dimensional dynamics in the network, a hallmark of population activity recorded in behaving animals <ref type="bibr" target="#b14">(Gao and Ganguli, 2015)</ref>.</s><s>While low-dimensional activity is usually detected numerically using dimensional-reduction techniques <ref type="bibr" target="#b10">(Cunningham and Yu, 2014)</ref>, we showed that a mean-field theory allows us to directly predict the low-dimensional dynamics based on the connectivity and input structure.</s><s>This approach led us to a simple, geometrical understanding of the relationship between connectivity and dynamics, and enabled us to design minimal-connectivity implementations of specific computations.</s><s>In particular, we found that the dynamical repertoire of the network increases quickly with the rank of the connectivity structure, so that ranktwo networks can already implement a variety of computations.</s><s>In this study, we have not explicitly considered structures with rank higher than two, but our theoretical framework is in principle valid for arbitrary rank r N , where N is the size of the network.</s><s>While other works have examined dynamics in networks with a mixture of structured and random connectivity (e.g.</s><s><ref type="bibr" target="#b39">Roudi and Latham (2007)</ref>; <ref type="bibr" target="#b0">Ahmadian et al. (2015)</ref>), the most classical approach for implementing computations in recurrent networks has been to endow them with a clustered <ref type="bibr" target="#b52">(Wang, 2002;</ref><ref type="bibr" target="#b2">Amit and Brunel, 1997;</ref><ref type="bibr" target="#b23">Litwin-Kumar and Doiron, 2012)</ref> or distance-dependent connectivity <ref type="bibr" target="#b5">(Ben-Yishai et al., 1995)</ref>.</s><s>Such networks inherently display low-dimensional dynamics similar to our framework <ref type="bibr" target="#b11">(Doiron and Litwin-Kumar, 2014;</ref><ref type="bibr" target="#b53">Williamson et al., 2016)</ref>, as clustered connectivity is in fact a special case of low-rank connectivity.</s><s>Clustered connectivity, however, is highly ordered: each neuron belongs to a single cluster and therefore is selective to a single task feature (e.g. a given stimulus, or a given output).</s><s>Neurons in clustered networks are therefore highly specialized and display pure selectivity <ref type="bibr" target="#b37">(Rigotti et al., 2013)</ref>.</s><s>Here, instead, we have considered random low-rank structures, which generate activity organized along heterogeneous directions in state space.</s><s>As a consequence, stimuli and outputs are represented in a random, highly distributed manner and individual neurons are typically responsive to several stimuli, outputs, or combinations of the two.</s><s>Such mixed selectivity is a ubiquitous property of cortical neurons <ref type="bibr" target="#b37">(Rigotti et al., 2013;</ref><ref type="bibr" target="#b26">Mante et al., 2013;</ref><ref type="bibr" target="#b9">Churchland and Shenoy, 2007)</ref>, and confers additional computational properties to our networks <ref type="bibr" target="#b21">(Kanerva, 2009)</ref>.</s><s>In particular, it allowed us to easily extend to a context-dependent situation <ref type="bibr" target="#b26">(Mante et al., 2013;</ref><ref type="bibr" target="#b40">Saez et al., 2015)</ref> a network implementation of a basic discrimination task.</s><s>This is typically difficult to do in clustered, purely selective networks <ref type="bibr" target="#b36">(Rigotti et al., 2010)</ref>.</s></p><p><s>The type of connectivity used in our study is closely related to the classical framework of Hopfield networks <ref type="bibr" target="#b18">(Hopfield, 1982;</ref><ref type="bibr" target="#b3">Amit et al., 1985)</ref>.</s><s>The aim of Hopfield networks is to store in memory specific patterns of activity by creating for each pattern a corresponding fixed-point in the network dynamics.</s><s>This is achieved by adding a unit-rank term for each item, and one approach for investigating the capacity of such a setup has relied on the mean-field theory of a network with a connectivity that consists of a sum of a rank-one term and a random matrix <ref type="bibr" target="#b49">(Tirozzi and Tsodyks, 1991;</ref><ref type="bibr" target="#b42">Shiino and Fukai, 1993;</ref><ref type="bibr" target="#b39">Roudi and Latham, 2007)</ref>.</s><s>While this approach is clearly close to the one adopted in the present study, there are important differences.</s><s>Within Hopfield networks, the unit-rank terms are symmetric, so that the corresponding left-and right-connectivity vectors are identical for each pattern.</s><s>Moreover, the unit-rank terms that correspond to different patterns are generally uncorrelated.</s><s>In contrast, here we have considered the more general case where the left-and right-eigenvectors are different, and potentially correlated between different rank-one terms.</s><s>Most importantly, our main focus was on responses to external inputs and input-output computations, rather than memorizing items.</s><s>In particular we showed that left-and right-connectivity vectors play different roles with respect to processing inputs, with the left-connectivity vector implementing input-selection, and the right-connectivity vector determining the output of the network.</s></p><p><s>Our study is also directly related to echo-state networks (ESN) <ref type="bibr" target="#b19">(Jaeger and Haas, 2004)</ref> and FORCE learning <ref type="bibr" target="#b45">(Sussillo and Abbott, 2009)</ref>.</s><s>In those frameworks, randomly connected recurrent networks are trained to produce specified outputs using a feedback loop from a readout unit to the network, which is mathematically equivalent to adding a rank-one term to the random connectivity matrix <ref type="bibr" target="#b24">(Maass et al., 2007)</ref>.</s><s>In their most basic implementation, both ESN and FORCE learning train only the readout weights.</s><s>The training is performed for a fixed, specified realization of the random connectivity, so that the final rank-one structure is correlated with the random part of the connectivity and may be strong with respect to it.</s><s>In contrast, the results presented here rely on the assumption that the low-rank structure is weak and independent from the random part.</s><s>Although ESN and FORCE networks do not necessarily fulfill this assumption, in ongoing work we found that our approach describes well networks trained using ESN or FORCE to produce a constant output <ref type="bibr" target="#b38">(Rivkind and Barak, 2017)</ref>.</s><s>Note that in our framework, the computations rely solely on the structured part of the connectivity, but ongoing work suggests that the random part of the connectivity may play an important role during training.</s></p><p><s>The specific network model used here is identical to most studies based on trained recurrent networks <ref type="bibr" target="#b45">(Sussillo and Abbott, 2009;</ref><ref type="bibr" target="#b26">Mante et al., 2013;</ref><ref type="bibr" target="#b44">Sussillo, 2014)</ref>.</s><s>It is highly simplified and lacks many biophysical constraints, the most basic ones being positive firing rates, the segregation between excitation and inhibition and interactions through spikes.</s><s>Recent works have investigated extensions of the abstract model used here to networks with biophysical constraints <ref type="bibr" target="#b31">(Ostojic, 2014;</ref><ref type="bibr" target="#b20">Kadmon and Sompolinsky, 2015;</ref><ref type="bibr" target="#b16">Harish and Hansel, 2015;</ref><ref type="bibr" target="#b29">Mastrogiuseppe and Ostojic, 2017;</ref><ref type="bibr" target="#b48">Thalmeier et al., 2016)</ref>.</s><s>Additional work will be needed to implement the present framework in networks of spiking neurons.</s></p><p><s>Our results imply novel, directly testable experimental predictions relating connectivity, low-dimensional dynamics and computational properties of individual neurons.</s><s>Our main result is that the dominant components of low-dimensional dynamics are a combination of feed-forward input patterns, and vectors specifying the lowrank recurrent connectivity (Fig. <ref type="figure" target="#fig_1">2 C</ref>).</s><s>A direct implication is that, if the low-dimensional dynamics in the network are generated by low-rank recurrent connectivity, two neurons that have large loadings in the dominant principal components will tend to have mutual connections stronger than average (Fig. <ref type="figure" target="#fig_2">3</ref> F top).</s><s>In contrast, if the low-dimensional dynamics are not generated by recurrent interactions, but instead driven by feed-forward inputs alone, no correlation between principal components and connectivity is expected (Fig. <ref type="figure" target="#fig_2">3</ref> F bottom).</s><s>Since the low-dimensional dynamics based on recurrent connectivity form the scaffold for computations in our model, this basic prediction can be extended to various task-dependent properties of individual neurons.</s><s>For instance, if the recurrent connectivity implements evidence integration, two units with strong choice regressors are predicted to have mutual connections stronger than average (Fig. <ref type="figure" target="#fig_3">4 H</ref>).</s><s>Analogously, if recurrent connections implement context-dependent associations, two units with strong context regressors are expected to share connections stronger than average (Fig. <ref type="figure" target="#fig_4">5 G</ref>).</s><s>Such predictions can in principle be directly tested in experiments that combine calcium imaging of neural activity in behaving animals with measurements of connectivity between a subset of recorded neurons <ref type="bibr" target="#b22">(Ko et al., 2011)</ref>.</s><s>It should be noted however that very weak structured connectivity is sufficient to implement computations, so that the expected correlations between connectivity and various selectivity indices may be weak.</s></p><p><s>The class of recurrent networks we considered here is based on connectivity matrices that consist of an explicit sum of a low-rank and a random part.</s><s>While this may seem as a limited class of models, in fact any arbitrary matrix can be approximated with a low-rank one, e.g. by keeping a small number of dominant singular values and singular vectors <ref type="bibr" target="#b27">(Markovsky, 2012)</ref> -this is the basic principle underlying dimensionality reduction.</s><s>A recurrent network with any arbitrary connectivity matrix can therefore in principle be approximated by a low-rank recurrent network.</s><s>From this point of view, our theory suggests a simple conjecture: the lowdimensional structure in connectivity determines low-dimensional dynamics and computational properties of recurrent networks.</s><s>While more work is needed to establish under which precise conditions a low-rank network provides a good computational approximation of a full recurrent network, this conjecture provides a simple and practically useful working hypothesis for reverse-engineering trained neural networks <ref type="bibr" target="#b46">(Sussillo and Barak, 2012)</ref>, and relating connectivity, dynamics and computations in neural recordings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STAR Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact for Reagent and Resource Sharing</head><p><s>Further requests for resources should be directed to and will be fulfilled by the Lead Contact, Srdjan Ostojic (srdjan.ostojic@ens.fr).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Details</head><p><s>The network model</s></p><p><s>We study large recurrent networks of rate units.</s><s>Every unit in the network is characterized by a continuous variable x i (t), commonly interpreted as the total input current.</s><s>More generically, we also refer to x i (t) as the activation variable.</s><s>The output of each unit is a non-linear function of its inputs modeled as a sigmoidal function φ(x).</s><s>In line with previous works <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b45">Sussillo and Abbott, 2009;</ref><ref type="bibr" target="#b38">Rivkind and Barak, 2017)</ref>, we focus on φ(x) = tanh(x), but we show that qualitatively similar dynamical regimes appear in network models with more realistic, positively defined activation functions (Fig. <ref type="figure">S7</ref>).</s><s>The transformed variable φ(x i (t)) is interpreted as the firing rate of unit i, and is also referred to as the activity variable.</s><s>The time evolution is specified by the following dynamics:</s></p><formula xml:id="formula_5">ẋi (t) = -x i (t) + N j=1 J ij φ(x j (t)) + I i .<label>(6)</label></formula><p><s>We considered a particular class of connectivity matrices, which can be written as a sum of two terms:</s></p><formula xml:id="formula_6">J ij = gχ ij + P ij .<label>(7)</label></formula><p><s>Similarly to <ref type="bibr" target="#b43">(Sompolinsky et al., 1988)</ref>, χ ij is a Gaussian all-to-all random matrix, where every element is drawn from a centered normal distribution with variance 1/N .</s><s>The parameter g scales the strength of random connections in the network, and we refer to it also as the random strength.</s><s>The second term P ij is a low-rank matrix.</s><s>In this study, we consider the low-rank part of the connectivity fixed, while the random part varies between different realizations of the connectivity.</s><s>Our results rely on two simplifying assumptions.</s><s>The first one is that the low-rank term and the random term are statistically uncorrelated.</s><s>The second one is that, as stated in Eq. 8, the structured connectivity is weak in the large N limit, i.e. it scales as 1/N , while the random connectivity components χ ij scale as 1/ √ N .</s><s>We first consider the simplest case where P ij is a rank-one matrix, which can generally be written as the external product between two one-dimensional vectors m and n:</s></p><formula xml:id="formula_7">P ij = m i n j N .<label>(8)</label></formula><p><s>According to our first assumption, the entries of vectors m and n are independent of the random bulk of the connectivity χ ij .</s><s>Note that the only non-zero eigenvalue of P is given by the scalar product m T n/N , and the corresponding right and left eigenvectors are, respectively, vectors m and n.</s><s>In the following, we will refer to the eigenvalue m T n/N as the strength of the connectivity structure, and to m and n as the right-and left-connectivity vectors.</s><s>Here we focus on vectors obtained by generating the components from a joint Gaussian distribution.</s><s>More general connectivity structures of rank r N can be written as a sum of unit-rank terms</s></p><formula xml:id="formula_8">P ij = m (1) i n (1) j N + . . . + m (r) i n (r) j N ,<label>(9)</label></formula><p><s>and are therefore specified by r pairs of vectors m (k) and n (k) , where different m vectors are linearly independent, and similarly for n vectors.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of Dynamical Mean-Field theory</head><p><s>Our results rely on a mathematical analysis of network dynamics based on Dynamical Mean-Field (DMF) theory <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b34">Rajan et al., 2010;</ref><ref type="bibr" target="#b20">Kadmon and Sompolinsky, 2015)</ref>.</s><s>To help navigate the analysis, here we provide first a succint overview of the approach.</s><s>Full details are given further down in the section Details of Dynamical Mean-Field theory.</s><s>DMF theory allows one to derive an effective description of the dynamics by averaging over the disorder originating from the random part of the connectivity.</s><s>Across different realizations of the random connectivity matrix χ ij , the sum of inputs to unit i is approximated by a Gaussian stochastic process η i (t)</s></p><formula xml:id="formula_9">N j=1 J ij φ(x j (t)) + I i ≈ η i (t),<label>(10)</label></formula><p><s>so that each unit obeys a Langevin-like equation:</s></p><formula xml:id="formula_10">ẋi (t) = -x i (t) + η i (t).<label>(11)</label></formula><p><s>The Gaussian processes η i can in principle have different first and second-order statistics for each unit, but are otherwise statistically independent across different units.</s><s>As a consequence, the activations x i of different units are also independent Gaussian stochastic processes, coupled only through their first and second-order statistics.</s></p><p><s>The core of DMF theory consists of self-consistent equations for the mean µ i and auto-correlation function</s></p><formula xml:id="formula_11">∆ I i (t).</formula><p><s>At equilibrium (i.e. in absence of transient dynamics) the equation for the mean µ i of x i is obtained by directly averaging Eq. 6 over the random part of the connectivity.</s><s>For a unit-rank connectivity, it reads</s></p><formula xml:id="formula_12">µ i = κm i + I i ,<label>(12)</label></formula><p><s>where</s></p><formula xml:id="formula_13">κ = 1 N N j=1 n j φ j .<label>(13)</label></formula><p><s>In the last equation, we adopted the short-hand notation φ i (t) := φ(x i (t)).</s><s>Here φ j is the average firing rate of unit j, i.e. φ(x j ) averaged over the Gaussian variable x j .</s><s>In a geometrical interpretation, the quantity κ represents the overlap between the left-connectivity vector n and the vector of average firing rates.</s><s>Equivalently, it is given by a population average of n j φ j , which can also be expressed as κ = dm dn dI p(m, n, I) n Dzφ(mκ</s></p><formula xml:id="formula_14">+ I + ∆ I 0 z)<label>(14)</label></formula><p><s>where p(m, n, I) is the joint distribution of components of vectors m, n and I.</s></p><formula xml:id="formula_15">∆ I 0 is the variance of x i (see below), and Dz = +∞ -∞ e -z 2 2 √ 2π dz.</formula><p><s>The auto-correlation function ∆ I i (t) quantifies the fluctuations of the activation x i around the expected mean.</s><s>Computing this auto-correlation function shows that it is identical for all units in the network, i.e. independent of i (see Eq. 27).</s><s>It can be decomposed into a static variance, which quantifies the fluctuations of the equilibrium values of x i across different realizations of the random component of the connectivity, and an additional temporal variance which is present when the network is in a temporally fluctuating, chaotic state.</s><s>In a stationary state, the variance ∆ I 0 ≡ ∆ I (t = 0) can be expressed as</s></p><formula xml:id="formula_16">∆ I 0 = g 2 1 N N j=1 [φ 2 i ].<label>(15)</label></formula><p><s>where [φ 2 i ] is the average of φ 2 i (x) over the Gaussian variable x i .</s><s>The right-hand-sides of Eqs. 13 and 15 show that both the mean µ i and variance ∆ I 0 depend on populationaveraged, macroscopic quantities.</s><s>To fully close the DMF description, the equations for single-unit statistics need to be averaged over the population.</s><s>For static equilibrium dynamics, this leads to two coupled equations for two macroscopic quantities, the overlap κ and the static, population-averaged variance ∆ 0 :</s></p><formula xml:id="formula_17">κ = F (κ, ∆ 0 ) ∆ 0 = G(κ, ∆ 0 ).<label>(16)</label></formula><p><s>Here F and G are two non-linear functions, the specific form of which depends on the geometrical arrangement of the connectivity vectors m and n and the input vector I.</s><s>For temporally fluctuating, chaotic dynamics an additional macroscopic quantity (corresponding to the temporal variance) needs to be taken into account.</s><s>In that case, the full DMF description is given by a system of three non-linear equations for three unknowns.</s><s>The equilibrium states of the network dynamics are therefore obtained by solving these systems of equations using standard non-linear methods.</s></p><p><s>To describe the transient dynamics and assess the stability of the obtained equilibrium states, we determined the spectrum of eigenvalues at the obtained equilibrium fixed points.</s><s>This spectrum consists of two components: a continuous, random component distributed within a circle in the complex plane, and a single outlier induced by the structured part of the connectivity (Fig. <ref type="figure" target="#fig_7">S1 A,</ref><ref type="figure">D</ref>).</s><s>The radius of the continuous component and the value of the outlier depend on the connectivity parameters.</s><s>Although the two quantities in general are non-trivially coupled, the value of the radius is mostly controlled by the strength of the disorder, while the value of the outlier increases with the strength m T n/N of the rank-one structure (Fig. <ref type="figure" target="#fig_7">S1 F</ref>).</s><s>The equilibrium is stable as long as the real part of all eigenvalues is less than unity.</s><s>For large connectivity structure strengths, the outlier crosses unity, generating an instability that leads to the appearance of one-dimensional structured activity.</s><s>Increasing the disorder strength on the other hand leads to another instability, corresponding to the radius of the continuous component crossing unity.</s><s>This instability gives rise to chaotic, fluctuating activity.</s></p><p><s>When a linear readout with weights w i is added to the network, its average output is given by</s></p><formula xml:id="formula_18">z(t) = 1 N N i=1 w i φ i (t) ,<label>(17)</label></formula><p><s>i.e. by the projection of the average network firing rate on the readout vector w.</s><s>This quantity is analogous to κ, except that the vector n is replaced by the vector w, so that similarly to Eq. 14, the average readout can also be expressed as z = dm dw dI p(m, w, I) w Dyφ(mκ</s></p><formula xml:id="formula_19">+ I + ∆ I 0 y)<label>(18)</label></formula><p><s>and therefore directly depends on the joint distribution p(m, w, I) which characterizes the geometric arrangement of vectors m, w and I.</s></p><p><s>The DMF theory can be directly extended to connectivity structures of rank r greater than one.</s><s>The equilibrium mean input to unit i is then given by</s></p><formula xml:id="formula_20">µ i = r k=1 κ (k) m (k) i + I i . (<label>19</label></formula><formula xml:id="formula_21">)</formula><p><s>The activity therefore lives in an (r + 1)-dimensional space determined by the r right-connectivity vectors m (k) and the input vector I.</s><s>It is characterized by r overlaps κ (k) , each of which quantifies the amount of activity along the corresponding direction m (k) .</s><s>Averaging over the population, the DMF theory then leads to a system of r + 1 nonlinear coupled equations for describing stationary dynamics.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of Dynamical Mean-Field theory</head><p><s>Here we provide the full details of the mathematical analysis.</s><s>We start by examining the activity of a network with a rank-one structure in absence of external inputs (I i = 0 ∀i in Eq. 6).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single-unit equations for spontaneous dynamics</head><p><s>We start by determining the statistics of the effective noise η i to unit i, defined by</s></p><formula xml:id="formula_22">η i (t) = g N j=1 χ ij φ(x j (t)) + m i N N j=1 n j φ(x j (t)).<label>(20)</label></formula><p><s>The DMF theory relies on the hypothesis that a disordered component in the coupling structure, here represented by χ ij , efficiently decorrelates single neuron activity when the network is sufficiently large.</s><s>We will show that this hypothesis of decorrelated activity is self-consistent for the specific network architecture we study.</s></p><p><s>As in standard DMF derivations, we characterize self-consistently the distribution of η i by averaging over different realizations of the random matrix χ ij <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b34">Rajan et al., 2010)</ref>.</s><s>In the following, <ref type="bibr">[.]</ref> indicates an average over the realizations of the random matrix χ ij , while .</s><s>stands for an average over different units of the network.</s><s>Note that the network activity can be equivalently characterized in terms of input current variables x i (t) or their non-linear transforms φ(x i (t)).</s><s>As these two quantities are not independent, the statistics of the distribution of the latter can be written in terms of the statistics of the former.</s></p><p><s>The mean of the effective noise received by unit i is given by:</s></p><formula xml:id="formula_23">[η i (t)] = g N j=1 [χ ij φ(x j (t))] + m i N N j=1 n j [φ(x j (t))].<label>(21)</label></formula><p><s>Under the hypothesis that in large networks, neural activity decorrelates (more specifically, that activity φ(x j (t)) is independent of its outgoing weights), we have:</s></p><formula xml:id="formula_24">[η i (t)] = g N j=1 [χ ij ][φ(x j (t))] + m i N N j=1 n j [φ(x j (t))] = m i κ (22) as [χ ij ] = 0.</formula><p><s>Here we introduced</s></p><formula xml:id="formula_25">κ := 1 N N j=1 n j [φ(x j (t))] = n j [φ j (t)] ,<label>(23)</label></formula><p><s>which quantifies the overlap between the mean population activity vector and the left-connectivity vector n.</s></p><p><s>Similarly, the noise correlation function is given by</s></p><formula xml:id="formula_26">[η i (t)η j (t + τ )] =g 2 N k=1 N l=1 [χ ik χ jl ][φ(x k (t))φ(x l (t + τ ))] + m i m j N 2 N k=1 N l=1 n k n l [φ(x k (t))φ(x l (t + τ ))].<label>(24)</label></formula><p><s>Note that every cross-term in the product vanishes since [χ ij ] = 0. Similarly to standard DMF derivations <ref type="bibr" target="#b43">(Sompolinsky et al., 1988)</ref>, the first term on the r.h.s.</s><s>vanishes for cross-correlations (i = j) while it survives in the auto-correlation function (i = j), as [χ ik χ jl ] = δ ij δ kl /N .</s><s>We get:</s></p><formula xml:id="formula_27">[η i (t)η j (t + τ )] = δ ij g 2 [φ i (t)φ i (t + τ )] + m i m j N 2 N k=1 N l=1 n k n l [φ(x k (t))φ(x l (t + τ ))].<label>(25)</label></formula><p><s>We focus now on the second term in the right-hand side.</s><s>The corresponding sum contains N terms where k = l.</s><s>This contribution vanishes in the large N limit because of the 1/N 2 scaling.</s><s>According to our starting hypothesis, when k = l, activity decorrelates:</s></p><formula xml:id="formula_28">[φ k (t)φ l (t + τ )] = [φ k (t)][φ l (t + τ )].</formula><p><s>To the leading order in N , we get:</s></p><formula xml:id="formula_29">[η i (t)η j (t + τ )] = δ ij g 2 [φ i (t)φ i (t + τ )] + m i m j N 2 k n k [φ(x k (t))] l =k n l [φ(x l (t + τ ))] = δ ij g 2 [φ i (t)φ i (t + τ )] + m i m j κ 2 (26) so that: [η i (t)η j (t + τ )] -[η i (t)][η j (t)] = δ ij g 2 [φ i (t)φ i (t + τ )] .<label>(27)</label></formula><p><s>We therefore find that the statistics of the effective input are uncorrelated across different units, so that our initial hypothesis is self-consistent.</s></p><p><s>To conclude, for every unit i, we computed the first-and the second-order statistics of the effective input η i (t).</s><s>The expressions we obtained show that the individual noise statistics depend on the statistics of the full network activity.</s><s>In particular, the mean of the effective input depends on the average overlap κ, but varies from unit to unit through the components of the right-connectivity vector m.</s><s>On the other hand, the autocorrelation of the effective input is identical for all units, and determined by the population-averaged firing rate auto-correlation</s></p><formula xml:id="formula_30">[φ i (t)φ i (t + τ )] .</formula><p><s>Once the statistics of η i (t) have been determined, a self-consistent solution for the activation variable x i (t) can be derived by solving the Langevin-like stochastic process from Eq. 11.</s><s>As a first step, we look at its stationary solutions, which correspond to the fixed points of the original network dynamics.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Population-averaged equations for stationary solutions</head><p><s>For any solution that does not depend on time, the mean µ i and the variance ∆ I 0 of the variable x i with respect to different realizations of the random connectivity coincide with the statistics of the effective noise η i .</s><s>From Eqs. 22 and 27, the mean µ i and variance ∆ I 0 of the input to unit i therefore read</s></p><formula xml:id="formula_31">µ i := [x i ] = m i κ ∆ I 0 := [x 2 i ] -[x i ] 2 = g 2 [φ 2 i ]<label>(28)</label></formula><p><s>while any other cross-variance</s></p><formula xml:id="formula_32">[x i x j ] -[x i ][x j ]</formula><p><s>vanishes.</s><s>We conclude that, on average, the structured connectivity P ij shapes the network activity along the direction specified by its right eigenvector m.</s><s>Such a heterogeneous stationary state critically relies on a non-vanishing overlap κ between the left eigenvector n and the average population activity vector <ref type="bibr">[φ]</ref>.</s><s>Across different realizations of the random connectivity, the input currents x i fluctuate around these mean values.</s><s>The typical size of fluctuations is determined by the individual variance ∆ I 0 , equal for every unit in the network.</s><s>The r.h.s. of Eq. 28 contains two population averaged quantities, the overlap κ and the second moment of the activity [φ 2 i ] .</s><s>To close the equations, these quantities need to be expressed self-consistently.</s><s>Averaging Eq. 28 over the population, we get expressions for the population-averaged mean µ and variance ∆ 0 of the input:</s></p><formula xml:id="formula_33">µ := [x i ] = m i κ ∆ 0 := [x 2 i ] -[x i ] 2 = g 2 [φ 2 i ] + ( m 2 i -m i 2 )κ 2 . (<label>29</label></formula><formula xml:id="formula_34">)</formula><p><s>Note that the total population variance ∆ 0 is a sum of two terms: the first term, proportional to the strength of the random part of connectivity, coincides with the individual variability ∆ I 0 which emerges from different realizations of χ ij ; the second term, proportional to the variance of the right-connectivity vector m, coincides with the variance induced at the population level by the spread of the mean values µ i ∝ m i .</s><s>When the vector m is homogeneous (m i = m), input currents x i are centered around the same mean value µ, and the second variance term vanishes.</s></p><p><s>We next derive appropriate expression for the r.h.s.</s><s>terms κ and [φ 2 i ] .</s><s>To start with, we rewrite [φ i ] by substituting the average over the random connectivity with the equivalent Gaussian integral:</s></p><formula xml:id="formula_35">[φ i ] = Dzφ(µ i + ∆ I 0 z) (<label>30</label></formula><formula xml:id="formula_36">)</formula><p><s>where we used the short-hand notation Dz =</s></p><formula xml:id="formula_37">+∞ -∞ e -z 2 2 √</formula><p><s>2π dz.</s><s>To obtain κ, [φ i ] needs to be multiplied by n i and averaged over the population.</s><s>This average can be expressed by representing the fixed vectors m and n through the joint distribution of their elements over the components:</s></p><formula xml:id="formula_38">p(m, n) = 1 N N j=1 δ(m -m j )δ(n -n j ).<label>(31)</label></formula><p><s>This leads to</s></p><formula xml:id="formula_39">κ = n i Dzφ(µ i + ∆ I 0 z) = dm dn p(m, n) n Dzφ(mκ + ∆ I 0 z).<label>(32)</label></formula><p><s>Similarly, a suitable expression for the second-order momentum of the firing rate is given by:</s></p><formula xml:id="formula_40">[φ 2 i ] = dm p(m) Dzφ 2 (mκ + ∆ I 0 z).<label>(33)</label></formula><p><s>Eqs. 32 and 33, combined with Eq. 29, provide a closed set of equations for determining κ and ∆ 0 once the vectors m and n have been specified.</s></p><p><s>To further simplify the problem, we reduce the full distribution p(m, n) of elements m i and n i to their firstand second-order momenta.</s><s>That is equivalent to substituting the probability density p(m, n) with a bivariate Gaussian distribution.</s><s>We therefore write:</s></p><formula xml:id="formula_41">m = M m + Σ m 1 -ρ x 1 + Σ m √ ρ y n = M n + Σ n 1 -ρ x 2 + Σ n √ ρ y (34)</formula><p><s>where x 1 , x 2 and y are three normal Gaussian processes.</s><s>Here, M m (resp.</s><s>M n ) and Σ m (resp.</s><s>Σ n ) correspond to the mean and the standard deviation of m (resp.</s><s>n), while the covariance between m and n is given by m</s></p><formula xml:id="formula_42">i n i - M m M n = Σ m Σ n ρ.</formula><formula xml:id="formula_43">κ = Dy Dx 2 (M n + Σ n 1 -ρx 2 + Σ n √ ρy) × Dz Dx 1 φ(κ(M m + Σ m 1 -ρx 1 + Σ m √ ρy) + ∆ I 0 z)<label>(35)</label></formula><p><s>which gives rise to three terms when expanding the sum</s></p><formula xml:id="formula_44">M n + Σ n √ 1 -ρx 2 + Σ n √ ρy.</formula><p><s>The first term can be rewritten as:</s></p><formula xml:id="formula_45">M n Dz φ(M m κ + ∆ I 0 + Σ 2 m κ 2 z) = M n Dz φ(µ + ∆ 0 z) = M n [φ i ] ,<label>(36)</label></formula><p><s>which coincides with the overlap between vectors n and [φ] along the unitary direction u = (1, 1, ...1)/N .</s><s>In the last step, we rewrote our expression for κ in terms of the population averaged statistics µ and ∆ 0 (Eq.</s><s>29).</s></p><p><s>The second term vanishes, while the third one gives:</s></p><formula xml:id="formula_46">Σ n √ ρ Dy y Dz Dx 1 φ(κ(M m + Σ m 1 -ρx 1 + Σ m √ ρy) + ∆ I 0 z) = κρΣ m Σ n [φ i ]<label>(37)</label></formula><p><s>which coincides with the overlap between n and [φ] in a direction orthogonal to u.</s><s>Here we used the equality:</s></p><formula xml:id="formula_47">Dz zf (z) = Dz df (z) dz<label>(38)</label></formula><p><s>which is obtained by integrating by parts.</s></p><p><s>Through a similar reasoning we obtain:</s></p><formula xml:id="formula_48">[φ 2 i ] = Dz φ 2 (µ + ∆ 0 z) (39)</formula><p><s>as in standard DMF derivations.</s></p><p><s>To conclude, the mean-field description of stationary solutions reduces to the system of three implicit equations for µ, κ and ∆ 0 :</s></p><formula xml:id="formula_49">µ = M m κ ∆ 0 = g 2 [φ 2 i ] + Σ 2 m κ 2 κ = M m [φ i ] + κρΣ m Σ n [φ i ] . (40)</formula><p><s>Both averages <ref type="bibr">[.]</ref> are performed with respect to a Gaussian distribution of mean µ and variance ∆ 0 .</s><s>Once µ, ∆ 0 and κ have been determined, the single unit mean µ i and the individual variance ∆ I 0 are obtained from Eq. 28.</s></p><p><s>The dynamical mean-field equations given in Eq. 40 can be fully solved to determine stationary solutions.</s><s>Detailed descriptions of these solutions are provided further down for two particular cases: (i) overlap between m and n only along the unitary direction u (M m = 0, M n = 0, ρ = 0); (ii) overlap between m and n only in a direction orthogonal to u (M m = M n = 0, ρ = 0).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transient dynamics and stability of stationary solutions</head><p><s>We now turn to transient dynamics around fixed points, and to the related problem of evaluating whether the stationary solutions found within DMF are stable with respect to the original network dynamics (Eq.</s><s>6).</s></p><p><s>For any given realization of the connectivity matrix, the network we consider is completely deterministic.</s><s>We can then study the local, transient dynamics by linearizing the dynamics around any stationary solution.</s><s>We therefore look at the time evolution of a small displacement away from the fixed point:</s></p><formula xml:id="formula_50">x(t) = x 0 i + x 1 i (t).</formula><p><s>For any generic stationary solution {x 0 i } the linearized dynamics are given by the stability matrix S ij which reads:</s></p><formula xml:id="formula_51">S ij = φ (x 0 j ) gχ ij + m i n j N . (<label>41</label></formula><formula xml:id="formula_52">)</formula><p><s>If the real part of every eigenvalue of S ij is smaller than unity, the perturbation decays in time and thus the stationary solution is stable.</s></p><p><s>Homogeneous stationary solutions We first consider homogeneous stationary solutions, for which x 0 i = x for all units.</s><s>A particular homogeneous solution is the trivial solution x i = 0, which the network admits for all parameter values when the transfer function is φ(x) = tanh(x).</s><s>Other homogeneous solutions can be obtained when the vector m is homogeneous, i.e. m i = M m for all i.</s></p><p><s>For homogeneous solutions, the stability matrix reduces to a scaled version of the connectivity matrix J ij :</s></p><formula xml:id="formula_53">S ij = φ (x)J ij . (<label>42</label></formula><formula xml:id="formula_54">)</formula><p><s>We are thus left with the problem of evaluating the eigenspectrum of the global connectivity matrix J ij .</s><s>The matrix J ij consists of a full-rank component χ ij , the entries of which are drawn at random, and of a structured component of small dimensionality with fixed entries.</s><s>We focus on the limit of large networks; in that limit, an analytical prediction for the spectrum of its eigenvalues can be derived.</s></p><p><s>Because of the 1/N scaling, the matrix norm of P ij is bounded as N increases.</s><s>We can then apply results from random matrix theory <ref type="bibr" target="#b47">(Tao, 2013)</ref> which predict that, in the large N limit, the eigenspectra of the random and the structured parts do not interact, but sum together.</s><s>The eigenspectrum of J ij therefore consists of two separated components, inherited respectively from the random and the structured terms (Fig. <ref type="figure" target="#fig_7">S1 A</ref>).</s><s>Similarly to <ref type="bibr" target="#b15">(Girko, 1985)</ref>, the random term χ ij returns a set of N -1 eigenvalues which lie on the complex plane in a compact circular region of radius g.</s><s>In addition to this component, the eigenspectrum of J ij contains the non-zero eigenvalues of P ij : in the case of a rank-one matrix, one single outlier eigenvalue is centered at the position i m i n i /N = m i n i .</s><s>In Fig. <ref type="figure" target="#fig_7">S1</ref> B we measure both the outlier position and the radius of the compact circular component.</s><s>We show that deviations from the theoretical predictions are in general small and decay to zero as the system size is increased.</s></p><p><s>Going back to the stability matrix S ij = φ (x)J ij , we conclude that a homogeneous stationary solution can lose stability in two different ways, when either m T n/N or g become larger than 1/φ (x).</s><s>We expect different kinds of instabilities to occur in the two cases.</s><s>When g crosses the instability line, a large number of random directions become unstable at the same time.</s><s>As in <ref type="bibr" target="#b43">(Sompolinsky et al., 1988)</ref>, this instability is expected to lead to the onset of irregular temporal activity.</s><s>When the instability is lead by the outlier, instead, the trivial fixed point becomes unstable in one unique direction given by the corresponding eigenvector.</s><s>When g = 0, this eigenvector coincides exactly with m.</s><s>For finite values of the disorder g, the outlier eigenvector fluctuates depending on the random part of the connectivity, but remains strongly correlated with m (Fig. <ref type="figure" target="#fig_7">S1 C</ref>), which therefore determines the average direction of the instability.</s><s>Above the instability, as the network dynamics is completely symmetric with respect to a change of sign of the input variables, we expect the non-linear boundaries to generate two symmetric stationary solutions.</s></p><p><s>Heterogeneous stationary solutions A second type of possible stationary solutions are heterogeneous fixed points, in which different units reach different equilibrium values.</s><s>For such fixed points, the linearized stability matrix S ij is obtained by multiplying each column of the connectivity matrix J ij by a different gain value (see Eq. 41), so that the eigenspectrum of S ij is not trivially related to the spectrum of J ij .</s></p><p><s>Numerical investigations reveal that, as for J ij , the eigenspectrum of S ij consists of two discrete components: one compact set of N -1 eigenvalues contained in a circle on the complex plane, and a single isolated outlier eigenvalue (Fig. <ref type="figure" target="#fig_7">S1 D</ref>).</s></p><p><s>As previously noticed in <ref type="bibr" target="#b16">(Harish and Hansel, 2015)</ref>, the radius of the circular compact set r can be computed as in <ref type="bibr" target="#b33">(Rajan and Abbott, 2006;</ref><ref type="bibr" target="#b1">Aljadeff et al., 2015b)</ref> by summing the variances of the distributions in every column of S ij .</s><s>To the leading order in N :</s></p><formula xml:id="formula_55">r = g 1 N N j=1 φ 2 (x 0 j )<label>(43)</label></formula><p><s>which, in large networks, can be approximated by the mean-field average:</s></p><formula xml:id="formula_56">r = g [φ 2 i ] .<label>(44)</label></formula><p><s>Note that, because of the weak scaling in P ij , the structured connectivity term does not appear explicitly in the expression for the radius.</s><s>As the structured part of the connectivity determines the heterogeneous fixed point, the value of r however depends implicitly on the structured connectivity term through [φ 2 i ] , which is computed as a Gaussian integral over a distribution with mean µ and variance ∆ 0 given by Eq. 40.</s><s>In Fig. <ref type="figure" target="#fig_7">S1 D-F</ref>, we show that Eq. 44 approximates well the radius of finite-size, numerically computed eigenspectra.</s><s>Whenever the mean-field theory predicts instabilities led by r, we expect the network dynamics to converge to irregular non-stationary solutions.</s><s>Consistently, at the critical point, where r = 1, the DMF equations predict the onset of temporally fluctuating solutions (see later on in Methods).</s></p><p><s>We now turn to the problem of evaluating the position of the outlier eigenvalue.</s><s>In the case of heterogeneous fixed points, the structured and the random components of the matrix S ij are strongly correlated, as they both scale with the multiplicative factor φ (x 0 j ), which correlates with the particular realization of the random part of the connectivity χ ij .</s><s>As a consequence, χ ij cannot be considered as a truly random matrix with respect to m i φ (x 0 j )n j /N , and in contrast to the case of homogeneous fixed points, results from <ref type="bibr" target="#b15">(Girko, 1985)</ref> do not hold.</s><s>We determined numerically the position of the outlier in finite-size eigenspectra (Fig. <ref type="figure" target="#fig_7">S1 D-F</ref>).</s><s>We found that its value indeed significantly deviates from the only non-zero eigenvalue of the rank-one structure m i φ (x 0 j )n j /N , which can be computed in the mean-field framework (when ρ = 0, it corresponds to</s></p><formula xml:id="formula_57">M m M n [φ i ] +M n κΣ 2 m [φ i ]</formula><p><s>).</s><s>On the other hand, the value of the outlier coincides exactly with the eigenvalue of m i φ (x 0 j )n j /N whenever the random component χ ij is shuffled (black dots in Fig. <ref type="figure" target="#fig_7">S1 F</ref>).</s><s>This observation confirms that the position of the outlier critically depends on the correlations existing between the rank-one structure m i φ (x 0 j )n j /N and its specific realization of the random bulk χ ij .</s></p><p><s>Mean-field analysis of transient dynamics and stability of stationary solutions As for heterogeneous fixed points we were not able to assess the position of the outlying eigenvalue using random matrix theory, we turned to a mean-field analysis to determine transient activity.</s><s>This analysis allowed us to determine accurately the position of the outlier, and therefore the stability of heterogeneous fixed points.</s><s>The approach exploited here is based on <ref type="bibr" target="#b20">(Kadmon and Sompolinsky, 2015)</ref>.</s></p><p><s>We consider the stability of the single unit activation x i when averaged across different realizations of the random connectivity and its random eigenmodes.</s><s>Directly averaging across realizations the network dynamics defined in Eq. 6 yields the time evolution of the mean activation µ i of unit i:</s></p><formula xml:id="formula_58">μi (t) = -µ i (t) + m i κ(t). (<label>45</label></formula><formula xml:id="formula_59">)</formula><p><s>We observe that we can write:</s></p><formula xml:id="formula_60">µ i (t) = m i κ(t)</formula><p><s>, where κ is the low-pass filtered version of κ:</s></p><formula xml:id="formula_61">(1 + d/ dt)κ(t) = κ(t).</formula><p><s>Small perturbations around the fixed point solution read:</s></p><formula xml:id="formula_62">µ i (t) = µ 0 i + µ 1 i (t)</formula><p><s>. The equilibrium values µ 0 i correspond to the DMF stationary solution computed from Eq. 28 and 40: µ 0 i = m i κ 0 .</s><s>The first-order perturbations thus obey:</s></p><p><s>μi</s></p><formula xml:id="formula_63">1 (t) = -µ 1 i (t) + m i κ 1 (t),<label>(46)</label></formula><p><s>indicating that the decay time scale of the mean activity is inherited by the decay time constant of κ 1 .</s><s>An additional equation for the time evolution of κ 1 thus needs to be derived.</s><s>When activity is perturbed, the firing activity φ i of unit i can be evaluated at the first order:</s></p><formula xml:id="formula_64">φ 0 i → φ 0 i + φ 1 i (t) = φ(x 0 i ) + φ (x 0 i )x 1 i (t).</formula><p><s>As a consequence, the first-order in κ reads:</s></p><formula xml:id="formula_65">κ 1 (t) = n i [φ (x 0 i )x 1 i (t)] .<label>(47)</label></formula><p><s>Summing Eq. 47 to its time-derivative, we get:</s></p><formula xml:id="formula_66">κ1 (t) = -κ 1 (t) + (1 + d dt ) n i [φ (x 0 i )x 1 i (t)] .<label>(48)</label></formula><p><s>In order to simplify the r.h.s., we start by considering the average with respect to the random part of the connectivity for a single unit i.</s><s>In order to compute [φ (x 0 i )x 1 i ], we explicitly build x 0 i and x t i := x i (t) as Gaussian variables centered respectively in µ 0 i and µ t i .</s><s>We will call ∆ I0 0 and ∆ It 0 the variances of the two variables, and ∆ I,t:0 their two-times correlation defined by ∆ I,t:0 = [</s></p><formula xml:id="formula_67">x t i x 0 i ] -[x t i ][x 0 i ].</formula><p><s>We can then write the two variables as</s></p><formula xml:id="formula_68">x 0 i = µ 0 i + ∆ I0 0 -∆ I,t:0 x 1 + √ ∆ I,t:0 y x t i = µ t i + ∆ It 0 -∆ I,t:0 x 2 + √ ∆ I,t:0 y<label>(49)</label></formula><p><s>The first-order response of x i is given by the difference between x t i and x 0 i , and reads:</s></p><formula xml:id="formula_69">x 1 i = µ 1 i + ∆ It 0 -∆ I,t:0 x 2 -∆ I0 0 -∆ I,t:0 x 1 .<label>(50)</label></formula><p><s>As in classical DMF derivations <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b34">Rajan et al., 2010;</ref><ref type="bibr" target="#b20">Kadmon and Sompolinsky, 2015)</ref>, x 1 , x 2 and y are standard normal variables.</s><s>By integrating over their distributions we can write:</s></p><formula xml:id="formula_70">[φ (x 0 i )x 1 i ] = Dx 1 Dx 2 µ 1 i + ∆ It 0 -∆ I,t:0 x 2 -∆ I0 0 -∆ I,t:0 x 1 × Dyφ µ 0 i + ∆ I0 0 -∆ I,t:0 x 1 + √ ∆ I,t:0 y . (<label>51</label></formula><formula xml:id="formula_71">)</formula><p><s>Integrating by parts as in Eq. 38 we get:</s></p><formula xml:id="formula_72">[φ (x 0 i )x 1 i ] = µ 1 i [φ i ] + ∆ I,t:0 -∆ I0 0 [φ i ]<label>(52)</label></formula><p><s>where the Gaussian integrals [φ i ] and [φ i ] are evaluated using the fixed point statistics.</s></p><p><s>Note that, at the fixed point, ∆ I,t:0 = ∆ I0 0 .</s><s>As a consequence, ∆ I,t:0 -∆ I0 0 gives a first-order response:</s></p><formula xml:id="formula_73">∆ I,1:0 := ∆ I,t:0 -∆ I0 0 = [x 1 i x 0 i ] -[x 1 i ][x 0 i ] = [x 1 i x 0 i ] -µ 0 i µ 1 i (<label>53</label></formula><formula xml:id="formula_74">)</formula><p><s>which can be rewritten as a function of the global second-order statistics ∆</s></p><formula xml:id="formula_75">1:0 = [x 1 i x 0 i ] -[x 1 i ] [x 0 i ] as: ∆ I,1:0 = ∆ 1:0 -{ µ 1 i µ 0 i -µ 1 i µ 0 i } = ∆ 1:0 -Σ 2 m κ0 κ1 .<label>(54)</label></formula><p><s>Eq. 54 can be rewritten in terms of the first-order perturbation for the global equal-time variance: ∆ 1 0 = ∆ t 0 -∆ 0 0 .</s><s>We consider that, by definition:</s></p><formula xml:id="formula_76">∆ 1:0 = N j=1 x 1 j ∂∆ t:0 ∂x t j 0 ∆ 1 0 = N j=1 x 1 j ∂∆ t 0 ∂x t j 0 . (<label>55</label></formula><formula xml:id="formula_77">)</formula><p><s>We then observe that, when the derivatives are evaluated at the fixed point, we have:</s></p><formula xml:id="formula_78">∂∆ t:0 ∂x t j 0 = 1 2 ∂∆ t 0 ∂x t j 0 ,<label>(56)</label></formula><p><s>and we conclude that:</s></p><formula xml:id="formula_79">∆ 1:0 = 1 2 ∆ 1 0<label>(57)</label></formula><p><s>.</s></p><p><s>Eq. 52 thus becomes:</s></p><formula xml:id="formula_80">[φ (x 0 i )x 1 i ] = m i κ1 [φ i ] + ∆ 1 0 2 -Σ 2 m κ0 κ1 [φ i ].<label>(58)</label></formula><p><s>In a second step, we perform the average across different units of the population, by writing m and n as in Eq. 34.</s><s>After some algebra, we get:</s></p><formula xml:id="formula_81">n i [φ (x 0 i )x 1 i (t)] = κ1 (M m M n + ρΣ m Σ n ) [φ i ] + ρκ 0 M m Σ m Σ n [φ i ] + ∆ 1 0 2 M n [φ i ] + ρκ 0 Σ m Σ n [φ i ] := κ1 a + ∆ 1 0 b<label>(59)</label></formula><p><s>where constants a and b were defined as:</s></p><formula xml:id="formula_82">a = (M m M n + ρΣ m Σ n ) [φ i ] + ρκ 0 M m Σ m Σ n [φ i ] b = 1 2 M n [φ i ] + ρκ 0 Σ m Σ n [φ i ] .<label>(60)</label></formula><p><s>The time evolution of κ can be finally rewritten as:</s></p><formula xml:id="formula_83">κ1 (t) = -κ 1 (t) + (1 + d dt ) κ1 a + ∆ 1 0 b ,<label>(61)</label></formula><p><s>so that the time evolution of the perturbed variance must be considered as well.</s></p><p><s>In order to isolate the evolution law of ∆ 0 , we rewrite the activation variable x i (t) by separating the uniform and the heterogeneous components: x i (t) = µ(t) + δx i (t).</s><s>The time evolution for the residual δx i (t) is given by:</s></p><formula xml:id="formula_84">δ x i (t) = -δx i (t) + g N j=1 χ ij φ(x j (t)) + (m i -M m )κ(t)<label>(62)</label></formula><p><s>so that, squaring:</s></p><formula xml:id="formula_85">dδx i (t) dt 2 + 2δx i (t) dδx i (t) dt + δx i (t) 2 = g 2 N j=1 N k=1 χ ij χ ik φ(x j (t))φ(x k (t)) + (m i -M m ) 2 κ(t) 2 + g(m i -M m )κ(t) N k=1 χ ij φ(x k (t)).<label>(63)</label></formula><p><s>Averaging over i and the realizations of the disorder yields:</s></p><formula xml:id="formula_86">d∆ 0 (t) dt = -∆ 0 (t) + g 2 [φ 2 i (t)] + Σ 2 m κ(t) 2 - dδx i (t) dt 2 := -∆ 0 (t) + G(µ, ∆ 0 , κ) - dδx i (t) dt 2 (64)</formula><p><s>as by definition we have: [δx 2 i (t)] = ∆ 0 (t).</s><s>Expanding the dynamics of ∆ 0 to the first order, we get:</s></p><formula xml:id="formula_87">∆1 0 (t) = -∆ 1 0 (t) + µ 1 ∂G ∂µ 0 + ∆ 1 0 ∂G ∂∆ 0 0 + κ 1 ∂G ∂κ 0 . (<label>65</label></formula><formula xml:id="formula_88">)</formula><p><s>Note that we could neglect the contributions originating from the last term of Eq. 64 because they do not enter at the leading order.</s><s>Indeed we have:</s></p><formula xml:id="formula_89">∂ ∂µ dδx i (t) dt 2 0 = 2 dδx i (t) dt ∂ ∂µ dδx i (t) dt 0 = 0<label>(66)</label></formula><p><s>since temporal derivatives for every i vanish when evaluated at the fixed point.</s></p><p><s>A little algebra returns the last three linear coefficients:</s></p><formula xml:id="formula_90">∂G ∂µ 0 = 2g 2 [φ i φ i ] ∂G ∂∆ 0 0 = g 2 [φ 2 i ] + [φ i φ i ] ∂G ∂κ 0 = 2Σ 2 m κ 0 .<label>(67)</label></formula><p><s>Collecting all the results together in Eq. 61 we obtain:</s></p><formula xml:id="formula_91">κ1 (t) = -κ 1 (t) + aκ 1 (t) + b µ 1 ∂G ∂µ 0 + ∆ 1 0 ∂G ∂∆ 0 0 + κ 1 ∂G ∂κ 0 . (<label>68</label></formula><formula xml:id="formula_92">)</formula><p><s>By averaging Eq. 45 we furthermore obtain:</s></p><formula xml:id="formula_93">μ1 (t) = -µ 1 (t) + M m κ 1 . (<label>69</label></formula><formula xml:id="formula_94">)</formula><p><s>We finally obtained that the perturbation time scale is determined by the population-averaged dynamics:</s></p><formula xml:id="formula_95">d dt   µ 1 ∆ 1 0 κ 1   = -   µ 1 ∆ 1 0 κ 1   + M   µ 1 ∆ 1 0 κ 1   (<label>70</label></formula><formula xml:id="formula_96">)</formula><p><s>where the evolution matrix M is defined as:</s></p><formula xml:id="formula_97">M =   0 0 M m 2g 2 [φ i φ i ] g 2 [φ 2 i ] + [φ i φ i ] 2Σ 2 m κ 0 2bg 2 [φ i φ i ] bg 2 [φ 2 i ] + [φ i φ i ] b2Σ 2 m κ 0 + a   . (<label>71</label></formula><formula xml:id="formula_98">)</formula><p><s>Note that one eigenvalue of matrix M, which corresponds to the low-pass filtering between κ and µ, is always fixed to zero.</s></p><p><s>Eqs. 70 and 71 reveal that, during the relaxation to equilibrium, the transient dynamics of the first-and second-order statistics of the activity are tightly coupled.</s><s>Diagonalizing M allows to retrieve the largest decay timescale of the network, which indicates the average, structural stability of stationary states.</s></p><p><s>When an outlier eigenvalue is present in the eigenspectrum of the stability matrix S ij , the largest decay time scale from M predicts its position.</s><s>The corresponding eigenvector ê contains indeed a structured component along m, which is not washed out by averaging across different realizations of χ ij .</s></p><p><s>The second non-zero eigenvalue of M, which vanishes at g = 0, measures a second and smaller effective timescale, which derives from averaging across the remaining N -1 random modes.</s></p><p><s>Varying g, we computed the largest eigenvalue of M for corresponding stationary solutions of mean-field equations.</s><s>In Fig. <ref type="figure" target="#fig_7">S1</ref> F we show that, when the stability eigenspectrum includes an outlier eigenvalue, its position is correctly predicted by the largest eigenvalue of M. The mismatch between the two values is small and can be understood as a finite-size effect (Fig. <ref type="figure" target="#fig_7">S1 E</ref>, gray).</s></p><p><s>To conclude, we found that the stability of arbitrary stationary solutions can be assessed by evaluating, with the help of mean-field theory, both the values of the radius (Eq.</s><s>44) and the outlier (Eq.</s><s>71) of the stability eigenspectrum.</s><s>Instabilities led by the two different components are expected to reshape activity into two qualitatively different classes of dynamical regimes, which are discussed in detail, further in Methods, for two specific classes of structures.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamical Mean Field equations for chaotic solutions</head><p><s>When a stationary state loses stability due to the compact component of the stability eigenspectrum, the network activity starts developing irregular temporal fluctuations.</s><s>Such temporally fluctuating states can be described within the DMF theory by taking into account the full temporal auto-correlation function of the effective noise η i <ref type="bibr" target="#b43">(Sompolinsky et al., 1988)</ref>.</s><s>For the sake of simplicity, here we derive directly the mean-field equations for population-averaged statistics, and we eventually link them back to single unit quantities.</s></p><p><s>By differentiating twice Eq. 11, and by substituting the appropriate expression for the statistics of the noise η i , we derive that the auto-correlation function</s></p><formula xml:id="formula_99">∆(τ ) = [x i (t + τ )x i (t)] -[x i (t)] 2 obeys the second-order differential equation: ∆(τ ) = ∆(τ ) -g 2 [φ i (t)φ i (t + τ )] -Σ 2 m κ 2 . (<label>72</label></formula><formula xml:id="formula_100">)</formula><p><s>In this context, the activation variance ∆ 0 coincides with the peak of the full auto-correlation function: ∆ 0 = ∆(τ = 0).</s><s>We expect the total variance to include a temporal term, coinciding with the amplitude of chaotic fluctuations, and a quenched one, representing the spread across the population due to the disorder in χ ij and the structure imposed by the right-connectivity vector m.</s></p><p><s>In order to compute the full rate auto-correlation function [φ i (t)φ i (t + τ )] , we need to explicitly build two correlated Gaussian variables x(t) and x(t + τ ), such that:</s></p><formula xml:id="formula_101">[x i (t)] = [x i (t + τ )] = µ [x 2 i (t)] -[x i (t)] 2 = [x 2 i (t + τ )] -[x i (t)] 2 = ∆ 0 [x i (t + τ )x i (t)] -[x i (t)] 2 = ∆(τ ).<label>(73)</label></formula><p><s>Following previous studies <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b34">Rajan et al., 2010)</ref>, we obtain:</s></p><formula xml:id="formula_102">[φ i (t)φ i (t + τ )] = Dz Dxφ(µ + ∆ 0 -∆x + √ ∆z) 2 (<label>74</label></formula><formula xml:id="formula_103">)</formula><p><s>where we used the short-hand notation ∆ := ∆(τ ) and we assumed for simplicity ∆ &gt; 0. As we show later, this requirement is satisfied by our final solution.</s></p><p><s>In order to visualize the dynamics of the solutions of Eq. 72, we study the equivalent problem of a classical particle moving in a one-dimensional potential <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b34">Rajan et al., 2010)</ref>:</s></p><formula xml:id="formula_104">∆(τ ) = - ∂V ∂∆ (75)</formula><p><s>where the potential V is given by an integration over ∆:</s></p><formula xml:id="formula_105">V (∆, ∆ 0 ) = - ∆ 2 2 + g 2 [Φ i (t)Φ i (t + τ )] + Σ 2 m κ 2 ∆ (<label>76</label></formula><formula xml:id="formula_106">)</formula><p><s>and Φ(x) =</s></p><p><s>x -∞ φ(x ) dx .</s><s>As the potential V depends self-consistently on the initial condition ∆ 0 , the shape of the auto-correlation function ∆(τ ) depends parametrically on the value of ∆ 0 .</s><s>Similarly to previous works, we isolate the solutions that decay monotonically from ∆ 0 to an asymptotic value ∆(τ → ∞) := ∆ ∞ , where ∆ ∞ is determined by dV / d∆| ∆=∆∞ = 0.</s><s>This translates into a first condition to be imposed.</s><s>A second equation comes from the energy conservation condition: V (∆ 0 , ∆ 0 ) = V (∆ ∞ , ∆ 0 ).</s><s>Combined with the usual equation for the mean µ and the overlap κ, the system of equations to be solved becomes:</s></p><formula xml:id="formula_107">µ = M m κ κ = M n [φ i ] + ρκ [φ i ] ∆ 2 0 -∆ 2 ∞ 2 = g 2 DzΦ 2 (µ + ∆ 0 z) -Dz DxΦ(µ + ∆ 0 -∆ ∞ x + ∆ ∞ z) 2 + Σ 2 m κ 2 (∆ 0 -∆ ∞ ) ∆ ∞ = g 2 Dz Dxφ(µ + ∆ 0 -∆ ∞ x + ∆ ∞ z) 2 + Σ 2 m κ 2 . (<label>77</label></formula><formula xml:id="formula_108">)</formula><p><s>The temporally fluctuating state is therefore described by a closed set of equations for the mean activity µ, the overlap κ, the zero-lag variance ∆ 0 and the long-time variance ∆ ∞ .</s><s>The difference ∆ 0 -∆ ∞ represents the amplitude of temporal fluctuations.</s><s>If temporal fluctuations are absent, ∆ 0 = ∆ ∞ , and the system of equations we just derived reduces to the DMF description for stationary solutions given in Eq. 40.</s></p><p><s>A similar set of equations can be derived for single unit activity.</s><s>As for static stationary states, the mean activity of unit i is given by</s></p><formula xml:id="formula_109">µ i = m i κ.<label>(78)</label></formula><p><s>The static variance around this mean activity is identical for all units and given by</s></p><formula xml:id="formula_110">∆ I ∞ = g 2 Dz Dxφ(µ + ∆ 0 -∆ ∞ x + ∆ ∞ z) 2 = ∆ ∞ -Σ 2 m κ 2<label>(79)</label></formula><p><s>while the temporal component ∆ I T of the variance is identical to the population averaged temporal variance</s></p><formula xml:id="formula_111">∆ I T = ∆ 0 -∆ ∞ . (<label>80</label></formula><formula xml:id="formula_112">)</formula><p><s>To conclude, similarly to static stationary states, the structured connectivity P ij shapes network activity in the direction defined by its right eigenvector m whenever the overlap κ does not vanish.</s><s>For this reason, the mean-field theory predicts in some parameter regions the existence of more than one chaotic solution.</s><s>A formal analysis of the stability properties of the different solutions has not been performed.</s><s>We nevertheless observe from numerical simulations that chaotic solutions tend to inherit the stability properties of the stationary solution they develop from.</s><s>Specifically, when an homogeneous solution generates two heterogeneous bistable ones, we notice that the former loses stability in favor of the latter.</s></p><p><s>We finally observe that the critical coupling at which the DMF theory predicts the onset of chaotic fluctuations can be computed by imposing that, at the critical point, the concavity of the potential function V (∆) is inverted <ref type="bibr" target="#b43">(Sompolinsky et al., 1988;</ref><ref type="bibr" target="#b16">Harish and Hansel, 2015)</ref>:</s></p><formula xml:id="formula_113">d 2 V (∆, ∆ 0 ) d∆ 2 ∆∞ = 0 (81)</formula><p><s>and the temporal component of the variance vanishes: ∆ 0 = ∆ ∞ .</s><s>These two conditions are equivalent to the expression:</s></p><formula xml:id="formula_114">1 = g 2 [φ 2 i ]</formula><p><s>where, as we saw, g 2 [φ 2 i ] coincides with the squared value of the radius of the compact component of the stability eigenspectrum (Eq.</s><s>44).</s><s>In the phase diagram of Fig. <ref type="figure" target="#fig_0">1</ref> B, we solved this equation for g to derive the position of the instability boundary from stationary to chaotic regimes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spontaneous dynamics: structures overlapping on the unitary direction</head><p><s>In this section, we analyze in detail a specific case, in which the connectivity vectors m and n overlap solely along the unitary direction u = (1, 1, ...1)/N .</s><s>Within the statistical description of vector components, in this situation the joint probability density p(m, n) can be replaced by the product two normal distributions (respectively, N (M m , Σ 2 m ) and N (M n , Σ 2 n )).</s><s>The mean values M m and M n represent the projections of m and n on the common direction u, and the overlap between m and n is given by M m M n .</s><s>The components m and n are otherwise independent, the fluctuations representing the remaining parts of m and n that lie along mutually orthogonal directions.</s><s>In this situation, the expression for κ simplifies to</s></p><formula xml:id="formula_115">κ = n i [φ i ] = M n [φ i ]<label>(82)</label></formula><p><s>so that a non-zero overlap κ can be obtained only if the mean population activity [φ i ] is non-zero.</s><s>Choosing independently drawn m and n vectors thus slightly simplifies the mean-field network description.</s><s>The main qualitative features resulting from the interaction between the structured and the random component of the connectivity can however already be observed, and more easily understood, within this simplified setting.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stationary solutions</head><p><s>The DMF description for stationary solutions reduces to a system of two non-linear equations for the population averaged mean µ and variance ∆ 0 :</s></p><formula xml:id="formula_116">µ = M m M n [φ i ] := F (µ, ∆ 0 ) ∆ 0 = g 2 [φ 2 i ] + Σ 2 m M 2 n [φ i ] 2 := G(µ, ∆ 0 ).<label>(83)</label></formula><p><s>The population averages [φ i ] and [φ 2 i ] are computed as Gaussian integrals similarly to Eq. 39.</s><s>Eq. 83 can be solved numerically for µ and ∆ 0 by iterating the equations up to convergence, which is equivalent to numerically simulating the two-dimensional dynamical system given by</s></p><formula xml:id="formula_117">μ(t) = -µ + F (µ, ∆ 0 ) ∆0 (t) = -∆ 0 + G(µ, ∆ 0 ),<label>(84)</label></formula><p><s>since the fixed points of this dynamical system correspond to solutions of Eq. 83.</s><s>Gaussian integrals in the form of [φ i ] are evaluated numerically through Gauss-Hermite quadrature with a sampling over 200 points.</s><s>Unstable solutions can be computed by iterating the same equations after having inverted the sign of the time variable in the first equation.</s></p><p><s>As the system of equations in Eq. 83 is two-dimensional, we can investigate the number and the nature of stationary solutions through a simple graphical approach (Fig. <ref type="figure" target="#fig_7">S1 G</ref>).</s><s>We plot on the µ -∆ 0 plane the loci of points where the two individual equations</s></p><formula xml:id="formula_118">µ = F (µ, ∆ 0 ) ∆ 0 = G(µ, ∆ 0 )<label>(85)</label></formula><p><s>are satisfied.</s><s>In analogy with dynamical systems approaches, we refer to the two corresponding curves as the DMF nullclines.</s><s>The solutions of Eq. 83 are then given by the intersections of the two nullclines.</s></p><p><s>To begin with, we focus on the nullcline defined by the first equation (also referred to as the µ nullcline).</s><s>With respect to µ, F (µ, ∆ 0 ) is an odd sigmoidal function whose maximal slope depends on the value of ∆ 0 and M m M n .</s><s>When g = 0 and Σ m = 0, the input variance ∆ 0 vanishes.</s><s>In this case, the points of the µ nullcline trivially reduce to the roots of the equation: µ = M m M n φ(µ), which admits either one (M m M n &lt; 1), or three solutions (M m M n &gt; 1).</s><s>Non-zero values of g and Σ m imply finite and positive values of ∆ 0 .</s><s>As ∆ 0 increases, the solutions to the equation µ = M m M n [φ i ] vary smoothly, delineating the full nullcline in the µ -∆ 0 plane.</s><s>As in the case without disorder (g = 0 and Σ m = 0), for low structure strengths (M m M n &lt; 1), the µ nullcline consists of a unique branch: µ = 0 ∀∆ 0 .</s><s>At high structure strengths (M m M n &gt; 1), instead, its shape smoothly transforms into a symmetric pitchfork.</s></p><p><s>The ∆ 0 nullcline is given by the solutions of ∆ 0 = G(µ, ∆ 0 ) for ∆ 0 as function of µ.</s><s>As G(µ, ∆ 0 ) depends quadratically on µ, the ∆ 0 nullcline has a symmetric V -shape centered in µ = 0.</s><s>The ordinate of its vertex is controlled by the parameter g, as the second term of the second equation in 83 vanishes at µ = 0.</s><s>For µ = 0, the slope of G(µ, ∆ 0 ) in ∆ 0 = 0 is equal to g 2 .</s><s>As a consequence, for g &lt; 1, the vertex of the ∆ 0 nullcline is fixed in (0, 0), while for g &gt; 1, the vertex is located at ∆ 0 &gt; 0 and an isolated point remains at (0, 0).</s></p><p><s>The stationary solutions of the DMF equations are determined by the intersections between the two nullclines.</s><s>For all values of the parameters, the nullclines intersect in µ = 0, ∆ 0 = 0, corresponding to the trivial, homogeneous stationary solution.</s><s>The existence of other solutions are determined by the qualitative features of the individual nullclines, that depend on whether M m M n and g are smaller or greater than one (Fig. <ref type="figure" target="#fig_7">S1</ref> G).</s><s>The following qualitative situations can be distinguished: (i) for M m M n &lt; 1 and g &lt; 1, only the trivial solutions exist; (ii) for M m M n &gt; 1, two additional, symmetric solutions exist for non-zero values of µ and ∆ 0 , corresponding to symmetric, heterogeneous stationary states; (iii) for g &gt; 1, an additional solution exist for µ = 0 and ∆ 0 &gt; 0, corresponding to a heterogeneous solution in which individual units have non-zero stationary activity, but the population-average vanishes.</s><s>For M m M n &gt; 1, this solution can co-exist with the symmetric heterogeneous ones, but in the limit of large g these solutions disappear (Fig. <ref type="figure" target="#fig_7">S1 G</ref>).</s></p><p><s>The next step is to assess the stability of the various solutions.</s><s>As explained earlier on, the stability of the trivial state µ = 0, ∆ 0 = 0 can be readily assessed using random matrix theory arguments (Fig. <ref type="figure" target="#fig_7">S1 A-B</ref>).</s><s>This state is stable only for M m M n &lt; 1 and g &lt; 1.</s><s>At M m M n = 1, it loses stability due to the outlying eigenvalue of the stability matrix, leading to the bifurcation already observed at the level of nullclines.</s><s>At g = 1, the instability is due to the radius of the bulk of the spectrum.</s><s>This leads to a chaotic state, not predicted from the nullclines for the stationary solutions.</s></p><p><s>The stability of heterogeneous stationary states is assessed by determining separately the radius of the bulk of the spectrum and the position of the outlier (Fig. <ref type="figure" target="#fig_7">S1 D-F</ref>).</s><s>The radius is determined from Eq. 44.</s><s>The outlier is instead computed as the leading eigenvalue of the stability matrix given in Eq. 71.</s><s>Note that in the present framework, where the overlap is defined along the unitary direction, it is possible to show that the latter is equivalent to computing the leading stability eigenvalue of the effective dynamical system introduced in Eq. 84, linearized around the corresponding fixed point.</s><s>The bifurcation obtained when the outlier crosses unity is equivalent to the bifurcation predicted from the nullclines when the symmetric solutions disappear in favor of the heterogeneous solution of mean zero (Fig. <ref type="figure" target="#fig_7">S1 G</ref>).</s><s>For M m M n &gt; 1, we however find that as g is increased, the radius of the bulk of the spectrum always leads to a chaotic instability before the outlier becomes unstable.</s><s>Correspondingly, the µ = 0 and ∆ 0 &gt; 0 stationary state that exist for large g is never stable.</s></p><p><s>Chaotic solutions For large g, the instabilities of the stationary points generated by the bulk of the spectrum are expected to give rise to chaotic dynamics.</s><s>We therefore turn to the DMF theory for chaotic states, which are described by an additional variable that quantifies temporal fluctuations.</s><s>For the case studied here of connectivity vectors m and n overlapping only along the unitary direction, Eq. 77 become</s></p><formula xml:id="formula_119">µ = F (µ, ∆ 0 , ∆ ∞ ) = M m M n Dzφ(µ + ∆ 0 z) ∆ 0 = G(µ, ∆ 0 , ∆ ∞ ) = ∆ 2 ∞ + 2g 2 DzΦ 2 (µ + ∆ 0 z) -Dz DxΦ(µ + ∆ 0 -∆ ∞ x + ∆ ∞ z) 2 + M 2 n Σ 2 m [φ i ] 2 (∆ 0 -∆ ∞ ) 1 2 ∆ ∞ = H(µ, ∆ 0 , ∆ ∞ ) = g 2 Dz Dxφ(µ + ∆ 0 -∆ ∞ x + ∆ ∞ z) 2 + M 2 n Σ 2 m [φ i ] 2 .</formula><p><s>(86)</s></p><p><s>As the system to be solved is now three-dimensional, graphical approaches have only limited use.</s><s>Similarly to the stationary state, a practical and stable way to find numerically the solutions is to iterate the dynamical system given by</s></p><formula xml:id="formula_120">μ = -µ + F (µ, ∆ 0 , ∆ ∞ ) ∆0 = -∆ 0 + G(µ, ∆ 0 , ∆ ∞ ) ∆∞ = -∆ ∞ + H(µ, ∆ 0 , ∆ ∞ ). (<label>87</label></formula><formula xml:id="formula_121">)</formula><p><s>where the double Gaussian integrals from Eq. 86 can be evaluated numerically as two nested Gauss-Hermite quadratures.</s><s>Note that stationary states simply correspond to solutions for which ∆ 0 = ∆ ∞ .</s></p><p><s>As for stationary solutions, different types of chaotic solutions appear depending on the values of the structure strength M m M n and the disorder strength g.</s><s>If g &gt; 1 and M m M n &lt; 1, a single chaotic state exists corresponding to µ = 0 and ∆ ∞ = 0, meaning that the temporally averaged activity of all units vanishes, so that fluctuations are only temporal (Fig. <ref type="figure" target="#fig_0">1 B red</ref>).</s><s>As M m M n crosses unity, two symmetric states appear with non-zero values of µ and ∆ ∞ .</s><s>These states correspond to bistable heterogeneous chaotic states (Fig. <ref type="figure" target="#fig_0">1</ref> B orange) that are analogous to bistable heterogeneous stationary states.</s></p><p><s>The critical disorder strength g B at which heterogeneous chaotic states emerge (gray boundary in the phase diagram of Fig. <ref type="figure" target="#fig_0">1</ref>) is computed by evaluating the linear stability of the dynamics in 87 around the central solution (0, ∆ 0 , 0).</s><s>A long but straightforward algebra reveals that the stability matrix, evaluated in (0, ∆ 0 , 0), is simply given by   </s></p><formula xml:id="formula_122">M m M n φ 0 0 0 g 2 ( φ 2 + Φφ -Φ φ ) ∆0 0 0 0 g 2 φ 2    ,<label>(88)</label></formula><p><s>such that g B corresponds to the value of the random strength g for which the largest of its three eigenvalues crosses unity.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spontaneous dynamics: structures overlapping on an arbitrary direction</head><p><s>In the previous section, we focused on the simplified scenario where the connectivity vectors m and n overlapped only in the unitary direction.</s><s>Here, we briefly turn to the opposite case where the overlap along the unitary direction u vanishes (i.e.</s><s>M m = 0, M n = 0), but the overlap ρ along a direction orthogonal to u is non-zero.</s><s>As we will show, although the equations describing the network activity present some formal differences, they lead to qualitatively similar regimes.</s><s>The same qualitative results apply as well to the general case, where an overlap exists on both the unitary and an orthogonal direction.</s></p><p><s>The network dynamics can be studied by solving the DMF equations 40 and 77 by setting µ = 0. Stationary solutions are now determined by:</s></p><formula xml:id="formula_123">κ = ρκΣ m Σ n [φ i (0, ∆ 0 )] := F (κ, ∆ 0 ) ∆ 0 = g 2 [φ 2 i (0, ∆ 0 )] + Σ 2 m κ 2 := G(κ, ∆ 0 ).<label>(89)</label></formula><p><s>Note that, in this more general case, the relevant first-order statistics of network activity is given by the overlap κ, which now can take non-zero values even when the population-averaged activity [φ i ] vanishes.</s></p><p><s>As in the previous case, the stationary solutions can be analyzed in terms of nullclines (Fig. <ref type="figure" target="#fig_1">S2 A</ref>).</s><s>The main difference lies in the κ nullcline given by κ = ρκΣ m Σ n [φ i (0, ∆ 0 )] .</s><s>As both sides of the first equation are linear and homogeneous in κ, two classes of solutions exist: a trivial solution (κ = 0 for any ∆ 0 ), and a non-trivial one (∆ 0 = ∆0 for any κ), with ∆0 determined by:</s></p><formula xml:id="formula_124">[φ i (0, ∆0 )] = 1/(ρΣ m Σ n ).<label>(90)</label></formula><p><s>Because 0 &lt; φ (x) &lt; 1, Eq. 90 admits non-trivial solutions only for sufficiently large overlap values: ρ &gt; 1/Σ m Σ n .</s><s>In consequence, the κ nullcline takes qualitatively different shapes depending on the value of ρ: (i) for ρ &lt; 1/Σ m Σ n , it consists only of a vertical branch κ = 0; (ii) for ρ &gt; 1/Σ m Σ n an additional horizontal branch ∆ 0 = ∆0 appears (Fig. <ref type="figure" target="#fig_1">S2 A</ref>).</s></p><p><s>The ∆ 0 branch is qualitatively similar to the previously studied case of m and n overlapping along the unitary direction, with a qualitative change when the disorder parameter g crosses unity.</s></p><p><s>The stationary solutions are given by the intersections between the two nullclines.</s><s>Although the shape of the κ nullcline is distinct from the shape of the µ nullcline studied in the previous case, qualitatively similar regimes are found.</s><s>The trivial stationary state κ = 0, ∆ 0 = 0 exists for all parameter values.</s><s>When the structure strength ρΣ m Σ n exceeds unity, two symmetric heterogeneous states appear with non-zero κ values of opposite signs (but vanishing mean µ).</s><s>Finally for large g an additional state appears with κ = 0, ∆ 0 &gt; 0.</s></p><p><s>Similarly to Fig. <ref type="figure" target="#fig_0">1</ref>, the solutions of Eq. 89, which correspond to stationary activity states, are shown in blue in Fig. <ref type="figure" target="#fig_1">S2 B-D</ref>.</s></p><p><s>In Fig. <ref type="figure" target="#fig_1">S2</ref> B we address their stability properties: again we find that when non-centered stationary solutions exist, the central fixed point becomes unstable.</s><s>The instability is led by the outlier eigenvalue of the stability eigenspectrum.</s><s>Similarly to Fig. <ref type="figure" target="#fig_0">1</ref>, furthermore, the DMF theory predicts an instability to chaotic phases for high g values.</s><s>As for stationary states, both heterogeneous and homogeneous chaotic solutions are admitted (Fig. <ref type="figure" target="#fig_1">S2</ref> C-D); heterogeneous chaotic states exist in a parameter region where the values of g and ρ are comparable.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response to external inputs</head><p><s>In this section, we examine the effect of non-vanishing external inputs on the network dynamics.</s><s>We consider the situation in which every unit receives a potentially different input I i , so that the pattern of inputs at the network level is characterized by the N -dimensional vector I = {I i }.</s><s>The network dynamics in general depend on the geometrical arrangement of the vector I with respect to the connectivity vectors m and n.</s><s>Within the statistical description used in DMF theory, the input pattern is therefore characterized by the first-and second-order statistics M I and Σ I of its elements, as well as by the value of the correlations Σ mI and Σ nI with the vectors m and n.</s><s>In geometric terms, M I quantifies the component of I along the unit direction u, while Σ mI and Σ nI quantify the overlaps with m and n along directions orthogonal to u.</s><s>For the sake of simplicity, here we consider two connectivity vectors m and n that overlap solely on the unitary direction (ρ = 0).</s><s>The two vectors thus read (see Eq. 34):</s></p><formula xml:id="formula_125">m = M m + Σ m x 1 n = M n + Σ n x 2 . (<label>91</label></formula><formula xml:id="formula_126">)</formula><p><s>The input pattern can overlap with the connectivity vectors on the common (u) and on the orthogonal directions (x 1 and x 2 ).</s><s>It can moreover include further orthogonal components of strength Σ ⊥ .</s><s>The most general expression for the input vector can thus be written as:</s></p><formula xml:id="formula_127">I = M I + Σ mI Σ m x 1 + Σ nI Σ n x 2 + Σ ⊥ h (92)</formula><p><s>where h is a standard normal vector.</s><s>We first focus on the equilibrium response to constant inputs, and then turn to transient dynamics.</s></p><p><s>The mean-field equations in presence of external inputs can be derived in a straightforward fashion by following the same steps as in the input-free case.</s><s>We start by considering the statistics of the effective coupling term, which is given by ξ i (t) = η i (t) + I i (t), with η i (t) defined as in Eq. 20.</s><s>We can then exploit the statistics of η i (t) which have been computed in the previous paragraphs to obtain the equation for the mean activity:</s></p><formula xml:id="formula_128">µ i = [x i ] = m i κ + I i .<label>(93)</label></formula><p><s>Eq. 93 indicates that the direction of the average network activity is determined by a combination of the structured recurrent connectivity and the external input pattern.</s><s>The final direction of the activation vector in the N -dimensional population space is controlled by the value of the overlap κ, which depends on the relative orientations of m, n and I. Its value is given by the self-consistent equation:</s></p><formula xml:id="formula_129">κ = n i [φ i ] = n i Dzφ(m i κ + I i + ∆ I 0 z i ) = M n [φ i ] + Σ nI [φ i ] ,<label>(94)</label></formula><p><s>as both vectors m and I share non-trivial overlap directions with n.</s></p><p><s>The second-order statistics of the noise are given by:</s></p><formula xml:id="formula_130">[ξ i (t)ξ j (t + τ )] = δ ij g 2 [φ i (t)φ i (t + τ )] + m i m j κ 2 + (m i I j + m j I i )κ + I i I j . (<label>95</label></formula><formula xml:id="formula_131">)</formula><p><s>Averaging across the population we obtain:</s></p><formula xml:id="formula_132">[ξ i (t)ξ i (t + τ )] -[ξ i (t)] 2 = g 2 [φ 2 i ] + Σ 2 m κ 2 + 2Σ mI κ + Σ 2 I .<label>(96)</label></formula><p><s>The first term of the r.h.s.</s><s>represents the quenched variability inherited from the random connectivity matrix, while Σ 2 µ = Σ 2 m κ 2 + 2Σ mI κ + Σ 2 I represents the variance induced by the structure, which is inherited from both vectors m and I (Eq.</s><s>93).</s><s>From Eq. 92, the variance of the input reads:</s></p><formula xml:id="formula_133">Σ 2 I = Σ 2 mI Σ 2 m + Σ 2 nI Σ 2 n + Σ 2 ⊥ .<label>(97)</label></formula><p><s>The final DMF equations to be solved are given by the following system:</s></p><formula xml:id="formula_134">µ = M m κ + M I ∆ = ∆ -g 2 [φ i (t)φ(t + τ )] + Σ 2 m κ 2 + 2Σ mI κ + Σ 2 I κ = M n [φ i ] + Σ nI [φ i ]<label>(98)</label></formula><p><s>which, similarly to the cases we examined in detail so far, admits both stationary and chaotic solutions.</s><s>As for spontaneous dynamics, the instabilities to chaos are computed by evaluating the radius of the eigenspectrum of the stability matrix S ij (Eq.</s><s>44).</s><s>The stability matrix can admit an outlier eigenvalue as well, whose value can be predicted with a mean-field stability analysis.</s><s>Extending the arguments already presented in the previous paragraphs allows to show that the effective stability matrix M is given by:</s></p><formula xml:id="formula_135">M =   0 0 M m 2g 2 [φ i φ i ] g 2 [φ 2 i ] + [φ i φ i ] 2Σ 2 m κ 0 + 2Σ mI 2bg 2 [φ i φ i ] bg 2 [φ 2 i ] + [φ i φ i ] b(2Σ 2 m κ 0 + 2Σ mI ) + a   ,<label>(99)</label></formula><p><s>with:</s></p><formula xml:id="formula_136">a = M m M n [φ i ] + M m Σ nI [φ i ] b = 1 2 {M n [φ i ] + Σ nI [φ i ] } . (<label>100</label></formula><formula xml:id="formula_137">)</formula><p><s>As in the input-free case, when the stability eigenspectrum contains one outlier eigenvalue, its position is well predicted by the largest eigenvalue of M.</s></p><p><s>In the following, we refer to Fig. <ref type="figure" target="#fig_1">2</ref> and analyse in detail the contribution of every input direction to the final network dynamics.</s></p><p><s>In Fig. <ref type="figure" target="#fig_1">2</ref> D (left), we consider a unit-rank structure whose vectors m and n are orthogonal: M m = M n = 0.</s><s>The input direction is orthogonal to the connectivity vectors: Σ mI = Σ nI = 0, so that the input strength is quantified by the amplitude of the component along h (Σ ⊥ ).</s><s>In this configuration, because of Eq. 94, the amount of structured activity quantified by κ systematically vanishes.</s></p><p><s>In Fig. <ref type="figure" target="#fig_1">2</ref> D (center), we consider again orthogonal connectivity vectors, but we take an input pattern which overlaps with n along x 2 .</s><s>We keep Σ ⊥ = 1 fixed and we vary the component of the input along n by increasing Σ nI .</s><s>As can be seen from the equation for κ (Eq.</s><s>98), the overlap Σ nI between the input and the left vector n has the effect of increasing the value of κ, which would otherwise vanish since the structure has null strength (M n = 0).</s><s>In response to the input, a structured state emerges.</s><s>From the same equation, furthermore, one can notice that the Σ nI term has the effect of breaking the sign reversal symmetry (x → -x) that characterizes the mean-field equations in the case of spontaneous dynamics.</s></p><p><s>In Fig. <ref type="figure" target="#fig_1">2</ref> D (right), we include strong non-vanishing structure strengths (M m M n = 3.5).</s><s>In absence of external activity, the network dynamics thus admit two bistable solutions (Fig. <ref type="figure" target="#fig_0">1</ref>).</s><s>We consider an input pattern that correlates with n but is orthogonal to the structure overlap direction (M I = 0, Σ nI &gt; 0).</s><s>In this configuration, the external input has the effect of disrupting the symmetry between the two stable solutions.</s><s>For sufficiently strong input values, one of the two stable solutions disappears by annihilating with the unstable one.</s></p><p><s>In Fig. <ref type="figure" target="#fig_3">S4</ref> C, we show that the value of the critical input strength for which one of the two stable solution disappears can be controlled by an additional external input that overlaps with n on a different, orthogonal direction.</s><s>Specifically, in Fig. <ref type="figure" target="#fig_3">S4 C</ref>, we tune the additional input along the direction of the structure overlap u.</s><s>This input component can be thought as a modulatory signal which controls the way the network dynamics process the input stimulus along x 2 .</s><s>In models of computational tasks that employ non-linear input responses (Fig. <ref type="figure" target="#fig_3">4</ref>), a modulatory input along the structure overlap can regulate the threshold value of the input strength that the network has learnt to detect.</s><s>Similarly, in Figs. <ref type="figure" target="#fig_4">5</ref> and<ref type="figure" target="#fig_5">6</ref>, modulatory inputs are used to completely block the response to the non-relevant input stimulus, so that the readout can produce context-dependent outputs.</s></p><p><s>Asymmetric solutions A major effect of external inputs is that they break the sign reversal symmetry (x → -x) present in the network dynamics without inputs.</s><s>As a consequence, in the parameter regions where the network dynamics admit bistable structured states, the two stable solutions are characterized by different statistics and stability properties.</s></p><p><s>To illustrate this effect, we focus on the simple case where the external input pattern I overlaps with the connectivity vectors m and n solely on the unitary direction (M I = 0, Σ mI = Σ nI = 0).</s><s>The solutions of the system of equations corresponding to stationary states can be visualized with the help of the graphical approach, which unveils the symmetry breaking of network dynamics induced by external inputs (Fig. <ref type="figure" target="#fig_3">S4 D</ref>).</s></p><p><s>Similarly to the input-free case, the ∆ 0 nullcline consists of a symmetric V -shaped curve.</s><s>In contrast to before, however, the vertex of the nullcline is no longer fixed in (0, 0), but takes positive ordinate values also at low g values.</s><s>The value of G(0, ∆ 0 ), indeed, does not vanish, because of the finite contribution from the input pattern Σ 2 I .</s><s>The nullcline curves of µ are instead strongly asymmetric.</s><s>For low M m M n values, one single µ nullcline exists.</s><s>In contrast to the input-free case, this nullcline is no longer centered in zero.</s><s>As a consequence, it intersects the ∆ 0 nullclines in one non-zero point, corresponding to a unique heterogeneous stationary solution.</s></p><p><s>As M m M n increases, a second, separated branch can appear.</s><s>In contrast to the input-free case, the structure strength at which the second branch appears is not always equal to unity, but depends on the mean value of the input.</s><s>If M m M n is strong enough, the negative branch of the nullcline can intersect the ∆ 0 nullcline in two different fixed points, while a third solution is built on the positive µ nullcline.</s><s>As g increases, the two intersections on the negative branch become closer and closer and they eventually collapse together.</s><s>At a critical value g B , the network activity discontinuously jumps from negative to positive mean solutions.</s></p><p><s>As they are no longer symmetrical, the stability of the positive and the negative fixed points has to be assessed separately, and gives rise to different instability boundaries.</s><s>Computing the position of the outlier reveals that, when more than one solution is admitted by the mean-field system of equations, the centered one is always unstable.</s></p><p><s>As the stability boundaries of different stationary solutions do not necessarily coincide, in presence of external input patterns the phase diagram of the dynamics are in general more complex (Fig. <ref type="figure" target="#fig_3">S4 A-C</ref>).</s><s>Specifically, hybrid dynamical regimes, where one static solution co-exists with a chaotic attractor, can be observed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transient dynamics</head><p><s>We now turn to transient dynamics evoked by a temporal step in the external input (Fig. <ref type="figure" target="#fig_1">2 B</ref>).</s><s>We specifically examine the projection of the activation vector and its average onto the two salient directions spanned by vectors m and I.</s></p><p><s>The transient dynamics of relaxation to a stationary solution can be assessed by linearizing the mean-field dynamics.</s><s>We compute the time course of the average activation vector {µ i }, and we finally project it onto the two orthogonal directions which are indicated in the small insets of Fig. <ref type="figure" target="#fig_1">2 B</ref>.</s></p><p><s>Similarly to Eq. 45, the time evolution of µ i is governed by:</s></p><formula xml:id="formula_138">μi (t) = -µ i (t) + m i κ(t) + I i (t)<label>(101)</label></formula><p><s>so that, at every point in time:</s></p><formula xml:id="formula_139">µ i (t) = m i κ(t) + Ĩi (t),<label>(102)</label></formula><p><s>where κ(t) and Ĩi (t) coincide with the low-pass filtered versions of κ(t) and I(t).</s></p><p><s>When the network activity is freely decaying back to an equilibrium stationary state, Ĩi (t) coincides with a simple exponential relaxation to the pattern I i .</s><s>The decay time scale is set by the time evolution of activity (Eq.</s><s>6), which is taken here to be equal to unity:</s></p><formula xml:id="formula_140">Ĩi (t) = I i + (I ic i -I i )e -t .<label>(103)</label></formula><p><s>The time scale of κ(t) is inherited from the dynamics of κ(t).</s><s>We thus refer to our mean-field stability analysis, and compute the relaxation time of the population statistics κ(t) as the largest eigenvalue of the stability matrix M. The eigenvalue predicts a time constant τ r , which is in general larger than unity.</s><s>As a consequence, the relaxation of κ(t) obeys, for small displacements:</s></p><formula xml:id="formula_141">κ(t) = κ 0 + (κ ic -κ 0 )e -t τr , (<label>104</label></formula><formula xml:id="formula_142">)</formula><p><s>where the asymptotic value of κ 0 is determined from the equilibrium mean-field equations (Eqs.</s><s>98).</s><s>Finally, the time course of κ(t) is derived as the low-pass filter version of Eq. 104 with unit decay time scale.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rank-two connectivity structures</head><p><s>In the following paragraphs, we provide the detailed analysis for network models with rank-two connectivity structures.</s><s>The structured component of the connectivity can be written as:</s></p><formula xml:id="formula_143">P ij = m (1) i n (1) j N + m (2) i n (2) j N , (<label>105</label></formula><formula xml:id="formula_144">)</formula><p><s>where the vector pairs m (1) and m (2) , n (1) and n (2) are assumed to be linearly independent.</s></p><p><s>As in the case of unit-rank structures, we determine the network statistics by exploiting the link between linear stability analysis and mean-field description.</s><s>The study of the properties of eigenvalues and eigenvectors for the low-dimensional matrix P ij helps to predict the complex behavior of activity above the instability and to restrict our attention to the cases of interest.</s></p><p><s>The mean activity of the network in response to a fixed input pattern I i is given by:</s></p><formula xml:id="formula_145">µ i = κ 1 m (1) i + κ 2 m (2) i + I i . (<label>106</label></formula><formula xml:id="formula_146">)</formula><p><s>The final direction of the population activity is thus determined by the overlap values κ 1 = n</s></p><p><s>(1)</s></p><formula xml:id="formula_147">i [φ i ] and κ 2 = n (2) i [φ i ] .</formula><p><s>The expression of the mean-field equations for the first-and second-order statistics are determined by the geometrical arrangement of the connectivity and the input vectors.</s><s>Similarly to the unit-rank case, the simplest mean-field solutions correspond to stationary states, which inherit the structure of the most unstable eigenvectors of the connectivity matrix J ij .</s><s>The stability of the heterogeneous stationary states can be assessed as before by evaluating separately the value of the radius (Eq.</s><s>44) and the position of the outliers of the linear stability matrix S ij .</s></p><p><s>Similarly to the unit-rank case, it is possible to compute the position of the outlier eigenvalues by studying the linearized dynamics of the network statistics close to the fixed point, that is given by:</s></p><formula xml:id="formula_148">d dt     µ 1 ∆ 1 0 κ 1 1 κ 1 2     = -     µ 1 ∆ 1 0 κ 1 1 κ 1 2     + M     µ 1 ∆ 1 0 κ 1 1 κ 1 2     .</formula><p><s>(107) Note that, in κ l k , the subscript k = 1, 2 refers to the left vector n (k) with which the overlap is computed, while the superscript l = 0, 1 indicates the order of the perturbation away from the fixed point.</s></p><p><s>In order to compute the elements of the linear stability matrix M, we follow and extend the reasoning discussed in details for the unit-rank case.</s><s>We start by considering the time evolution of the linearized activity µ 1 i , which similarly to Eq. 45 reads:</s></p><formula xml:id="formula_149">μ1 i (t) = -µ 1 i + m (1) i κ 1 1 + m (2) i κ 1 2 . (<label>108</label></formula><formula xml:id="formula_150">)</formula><p><s>At every point in time, we can write:</s></p><formula xml:id="formula_151">µ t i = m (1) i κt 1 + m (2) i κt 2 , where κt k is the low-pass filtered version of κ t k : (1 + d/ dt)κ t k = κ t k .</formula><p><s>In the case of orthogonal (zero mean), random connectivity vectors, we get:</s></p><formula xml:id="formula_152">μ1 (t) = -µ 1 , (<label>109</label></formula><formula xml:id="formula_153">)</formula><p><s>so that the elements in the first row of M vanish.</s><s>In analogy with Eq. 64, the linearized dynamics of ∆ 0 gives instead:</s></p><formula xml:id="formula_154">∆1 0 = -∆ 1 0 + 2g 2 [φ i φ i ] µ 1 + g 2 { [φ 2 i ] + [φ i φ i ] }∆ 1 0 + 2Σ 2 m κ 0 1 κ 1 1 + 2Σ 2 m κ 0 2 κ 1 2 . (<label>110</label></formula><formula xml:id="formula_155">)</formula><p><s>Similarly to the unit-rank case (Eq.</s><s>47), in order to determine the linear response of κ 1 we need to compute:</s></p><formula xml:id="formula_156">κ 1 1 = n (1) i [x 1 i φ (x 0 i )] = n (1) i µ i [φ i ] + ∆ 1 0 2 -µ 1 i µ 0 i -µ 1 i µ 0 i n (1) i [φ i ]<label>(111)</label></formula><p><s>A similar expression can be derived for κ 1 2 .</s></p><p><s>In general, the integrals in the r.h.s.</s><s>can be expressed in terms of the perturbations κ1 1 , κ1 2 and ∆ 1 0 , leading to expressions of the form:</s></p><formula xml:id="formula_157">κ 1 1 = a 11 κ1 1 + a 12 κ1 2 + b 1 ∆ 1 0 κ 1 2 = a 21 κ1 1 + a 22 κ1 2 + b 2 ∆ 1 0 .</formula><p><s>(112)</s></p><p><s>Applying the operator (1 + d/ dt) to the Eq. 111 allows to reshape the results in the final matrix form:</s></p><formula xml:id="formula_158">M =     0 0 0 0 2g 2 [φ i φ i ] g 2 [φ 2 i ] + [φ i φ i ] 2Σ 2 m κ 0 1 2Σ 2 m κ 0 2 2b 1 g 2 [φ i φ i ] b 1 g 2 [φ 2 i ] + [φ i φ i ] 2b 1 Σ 2 m κ 0 1 + a 11 2b 1 Σ 2 m κ 0 2 + a 12 2b 2 g 2 [φ i φ i ] b 2 g 2 [φ 2 i ] + [φ i φ i ] 2b 2 Σ 2 m κ 0 1 + a 21 2b 2 Σ 2 m κ 0 2 + a 22     ,<label>(113)</label></formula><p><s>where the values of the constants a and b depend on the geometric arrangement of the structure and the input vectors.</s></p><p><s>In the following, we consider several specific cases of interest.</s><s>Note that the non-linear network dynamics is determined by the relative orientation of the structure and input vectors, but also by the characteristics of the statistical distribution of their elements.</s><s>In contrast to the cases we analyzed so far, the precise shape of the distribution of the entries in the connectivity vectors can play an important role when the rank of P ij is larger than unity.</s><s>In the following, we focus on the case of broadly, normally distributed patterns.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rank-two structures with null overlap</head><p><s>The simplest case we consider consists of rank-two matrices whose four connectivity vectors m (1) , m (2) , n (1) and n (2) are mutually orthogonal.</s><s>From the point of view of responses to inputs, networks with this structure behave as superpositions of two independent unit-rank structures.</s></p><p><s>Similarly to the unit-rank case, if the connectivity vectors are orthogonal, the network is silent in absence of external inputs: κ 1 = κ 2 = 0.</s><s>A single homogeneous state -stationary or chaotic -is the unique stable attractor of the dynamics.</s><s>Consistently, the eigenspectrum of J ij does not contain any outlier, since every eigenvalue of P ij vanishes.</s></p><p><s>In order to compute the eigenspectrum of P ij , we can rotate the matrix onto a basis defined by an orthonormal set of vectors, and compute its eigenvalues in the transformed basis.</s><s>For simplicity, we consider an orthonormal set whose first four vectors are built from the connectivity vectors:</s></p><formula xml:id="formula_159">u 1 = α 1 m (1) u 2 = α 2 m (2) u 3 = α 3 n (1) u 4 = α 4 n (2) ,<label>(114)</label></formula><p><s>where the coefficient α k (k = 1, ..., 4) denote the normalization factors.</s><s>In this basis, the first four rows and columns of the rotated matrix P ij read:</s></p><formula xml:id="formula_160">P ij = 1 N     0 0 1 α1α3 0 0 0 0 1 α2α4 0 0 0 0 0 0 0 0     ,<label>(115)</label></formula><p><s>all the remaining entries being fixed to 0. From the present matrix form, it easy to verify that all the eigenvalues of P ij , and thus all the eigenvalues of P ij , vanish.</s><s>Note that rewriting P ij in an orthonormal basis simplifies the search for its eigenvalues also in more complex cases where the connectivity vectors share several overlap directions.</s><s>In those cases, a proper basis needs to be built starting from the connectivity vectors through a Gram-Schmidt orthonormalization process.</s></p><p><s>As a side note we observe that, even though P ij (and thus P ij ) admits only vanishing eigenvalues, its rank is still equal to two.</s><s>Indeed, the rank can be computed as N minus the dimensionality of the kernel associated to P ij , defined by any vector x obeying P x = 0.</s><s>As P ij contains N -2 empty rows, the last equations impose two independent contraints on the components of x.</s><s>As a consequence, the dimensionality of the kernel equals N -2, and the rank is equal to two.</s></p><p><s>We turn to responses that are obtained in presence of external inputs.</s><s>We examine the network dynamics in response to a normalized input I which partially correlates with one of the left-connectivity vectors, here n (1) :</s></p><formula xml:id="formula_161">I = n (1) Σ nI Σ 2 n + x Σ 2 I - Σ 2 nI Σ 4 n . (<label>116</label></formula><formula xml:id="formula_162">)</formula><p><s>Similarly to the unit-rank case, we find that I elicits a network response in the plane Im (1) .</s><s>The overlap values are given by:</s></p><formula xml:id="formula_163">κ 1 = Σ nI [φ i ] κ 2 = 0, (<label>117</label></formula><formula xml:id="formula_164">)</formula><p><s>and they can be used to close the mean-field equations together with the equation for the first (µ = 0) and second-order statistics.</s><s>In the case of stationary states we have:</s></p><formula xml:id="formula_165">∆ 0 = g 2 [φ 2 i ] + Σ 2 m κ 2 1 + κ 2 2 + Σ 2 I . (<label>118</label></formula><formula xml:id="formula_166">)</formula><p><s>Similar arguments allow to derive the two equations needed for the chaotic states.</s></p><p><s>In order to assess the stability of the stationary states, we evaluate the position of the outliers in the stability eigenspectrum by computing the eigenvalues of M (Eq.</s><s>113).</s><s>In the case of orthogonal structures and correlated input patterns I, a little algebra reveals that all the a values vanish, while we have:</s></p><formula xml:id="formula_167">b 1 = 1 2 Σ nI [φ i ] b 2 = 0.<label>(119)</label></formula><p><s>We conclude that the first and the last row of M always vanish.</s><s>Furthermore, the second and the third rows are proportional one to the other.</s><s>As a consequence, the stability analysis predicts at most one outlier eigenvalue, which is indeed observed in the spectrum (not shown).</s><s>The outlier is negative, as the effect of introducing inputs in the direction of the left vector n (1) is to further stabilize the dynamics.</s><s>As it will be shown, more than one outlier can be observed in the case where the low-dimensional structure involves overlap directions.</s></p><p><s>Rank-two structures with internal pairwise overlap As a second case, we consider structured matrices where the two connectivity pairs m (1) and n (1) , m (2) and n (2) share two different overlap directions, defined by vectors y 1 and y 2 .</s><s>We set:</s></p><formula xml:id="formula_168">m (1) = Σ 2 -ρ 2 1 x 1 + ρ 1 y 1 m (2) = Σ 2 -ρ 2 2 x 2 + ρ 2 y 2 n (1) = Σ 2 -ρ 2 1 x 3 + ρ 1 y 1 n (2) = Σ 2 -ρ 2 2 x 4 + ρ 2 y 2 . (<label>120</label></formula><formula xml:id="formula_169">)</formula><p><s>where Σ 2 is the variance of the connectivity vectors and ρ 2 1 and ρ 2 2 quantify the overlaps along the directions y 1 and y 2 .</s></p><p><s>By rotating P ij onto the orthonormal basis that can be built from m (1) and m (2) by orthogonalizing the left vectors n (1) and n (2) , one can easily check that the two non-zero eigenvalues of P ij are given by λ 1 = ρ 2 1 and λ 2 = ρ 2 2 .</s><s>They correspond, respectively, to the two right-eigenvectors m (1) and m (2) .</s><s>In absence of external inputs, an instability is thus likely to occur in the direction of the m (k) vector which corresponds to the strongest overlap.</s></p><p><s>We specifically focus on the degenerate condition where the two overlaps are equally strong, ρ 1 = ρ 2 = ρ, and any combination of m (1) and m (2) is a right-eigenvector.</s><s>The mean-field equations for the first-order statistics read:</s></p><formula xml:id="formula_170">κ 1 = ρ 2 κ 1 [φ i ] κ 2 = ρ 2 κ 2 [φ i ] .<label>(121)</label></formula><p><s>Similarly to Eq. 89, the two equations admit a silent (κ 1 = κ 2 = 0) and a non-trivial state, determined by two identical conditions which read:</s></p><formula xml:id="formula_171">1 = ρ 2 [φ i (0, ∆ 0 )] .<label>(122)</label></formula><p><s>The equation above determines the value of ∆ 0 .</s><s>Note that the non-trivial state exists only for ρ &gt; 1.</s></p><p><s>A second condition is imposed by the equation for the second-order momentum which reads, for stationary solutions:</s></p><formula xml:id="formula_172">∆ 0 = g 2 [φ 2 i ] + Σ 2 κ 2 1 + κ 2 2 . (<label>123</label></formula><formula xml:id="formula_173">)</formula><p><s>As the value of ∆ 0 is fixed, the mean-field set of equations fixes only the sum κ 2 1 + κ 2 2 , but not each single component.</s><s>The mean-field thus returns a one-dimensional continuum of solutions, the shape of which resembles a ring of radius κ 2 1 + κ 2 2 in the m (1) -m (2) plane (see Fig. <ref type="figure" target="#fig_4">S5 D-E</ref>).</s><s>Similarly to the unit-rank case, the value of the radius can be computed explicitly by solving numerically the two mean-field equations (three in the case of chaotic regimes), and depends on the relative magnitude of ρ 2 compared to g (Fig. <ref type="figure" target="#fig_4">S5 F</ref>).</s><s>Highly disordered connectivities have the usual effect of suppressing non-trivial structured solutions in favour of homogeneous and unstructured states.</s><s>For sufficiently high g values, furthermore, structured solution can display chaotic dynamics (Fig. <ref type="figure" target="#fig_4">S5</ref> E and Fig. <ref type="figure" target="#fig_4">S5</ref> F, red).</s></p><p><s>A linear stability analysis reveals that the one-dimensional solution consists of a continuous set of marginally stable states.</s><s>Similarly to the orthogonal vectors case, the position of the outliers in the eigenspectra of S ij can be evaluated by computing the reduced stability matrix M, which reads:</s></p><formula xml:id="formula_174">M =     0 0 0 0 2g 2 [φ i φ i ] g 2 [φ 2 i ] + [φ i φ i ] 2Σ 2 m κ 0 1 2Σ 2 m κ 0 2 2b 1 g 2 [φ i φ i ] b 1 g 2 [φ 2 i ] + [φ i φ i ] 2b 1 Σ 2 m κ 0 1 + a 11 2b 1 Σ 2 m κ 0 2 2b 2 g 2 [φ i φ i ] b 2 g 2 [φ 2 i ] + [φ i φ i ] 2b 2 Σ 2 m κ 0 1 2b 2 Σ 2 m κ 0 2 + a 22     ,<label>(124)</label></formula><p><s>with:</s></p><formula xml:id="formula_175">a 11 = ρ 2 [φ i ] b 1 = 1 2 ρ 2 κ 0 1 [φ i ]<label>(125)</label></formula><p><s>and</s></p><formula xml:id="formula_176">a 22 = ρ 2 [φ i ] b 2 = 1 2 ρ 2 κ 0 2 [φ i ] .<label>(126)</label></formula><p><s>As shown in Fig. <ref type="figure" target="#fig_4">S5</ref> G, diagonalizing the stability matrix M returns the values of two distinct outlier eigenvalues.</s><s>The third non-zero eigenvalue of M lies instead systematically inside the compact component of the spectrum, and corresponds to an average measure of the time scales inherited by the random modes.</s><s>One of the two outliers is tuned exactly to the stability boundary for every value of the parameters which generate a ring solution.</s><s>This marginally stable eigenvalue is responsible for the slow dynamical time scales which are observed in numerical simulations of the network activity (Fig. <ref type="figure" target="#fig_4">S5 D-E</ref>).</s></p><p><s>The DMF predictions formally hold in the limit of infinite-size networks; in simulations of finite-size networks, the dynamics instead always converge on a small number of equilibrium spontaneous states located on the ring (see Fig. <ref type="figure" target="#fig_4">S5 D-E</ref>).</s><s>The equilibrium reached in a given situation is determined by the corresponding realization of the random part of the connectivity, and the initial conditions.</s><s>Different realizations of the random connectivity lead to different equilibrium states, which all however lie on the predicted ring (see Fig. <ref type="figure" target="#fig_4">S5 D-E</ref>).</s><s>For a given realization of the random connectivity, transient dynamics moreover show a clear signature of the ring structure.</s></p><p><s>Indeed the points on the ring are close to stable and form a slow manifold.</s><s>The convergence to the equilibrium activity is therefore very slow, and the temporal dynamics explore the ring structure.</s></p><p><s>We next examine how the structured, ring-shaped solution is perturbed by the injection of external input patterns.</s></p><p><s>We consider an input pattern I of variance Σ 2 I .</s><s>When I does not share any overlap direction with the left vectors n (1) and n (2) , the mean-field equations are affected solely by an extra term Σ I which needs to be included in the equation for the second-order statistics (Eq.</s><s>123).</s><s>As the equations for the first-order statistics do not change, the one-dimensional degeneracy of the solution persists.</s><s>The extra term Σ 2 I however decreases the value of the radius of the ring.</s></p><p><s>When the input contains a component which overlaps with one or both left vectors n (1) and n (2) , the degeneracy in the two equations for κ 1 and κ 2 is broken.</s><s>As a consequence, the one-dimensional solution collapses onto a unique stable point.</s><s>Consider for example an input pattern of the form:</s></p><formula xml:id="formula_177">I = Σ I √ 1 -α x 3 + √ α x 4 .<label>(127)</label></formula><p><s>The equations for the first order become:</s></p><formula xml:id="formula_178">κ 1 = ρ 2 κ 1 + Σ I √ 1 -α Σ 2 -ρ 2 [φ i ] κ 2 = ρ 2 κ 2 + Σ I √ α Σ 2 -ρ 2 [φ i ]<label>(128)</label></formula><p><s>or, alternatively:</s></p><formula xml:id="formula_179">κ 1 = Σ I √ 1 -α Σ 2 -ρ 2 [φ i ] 1 -ρ 2 [φ i ] κ 2 = Σ I √ α Σ 2 -ρ 2 [φ i ] 1 -ρ 2 [φ i ] .<label>(129)</label></formula><p><s>The values of κ 1 and κ 2 are thus uniquely specified, and can be computed by iterating the two equations together with the expression for the second-order statistics:</s></p><formula xml:id="formula_180">∆ 0 = g 2 [φ 2 i ] + Σ 2 κ 2 1 + κ 2 2 + Σ 2 I .<label>(130)</label></formula><p><s>In a similar way, the presence of correlated external inputs affect the values of the entries of the reduced stability matrix M:</s></p><formula xml:id="formula_181">b 1 = 1 2 ρ 2 κ 0 1 + Σ I √ 1 -α Σ 2 -ρ 2 [φ i ] b 2 = 1 2 ρ 2 κ 0 2 + Σ I √ α Σ 2 -ρ 2 [φ i ] .<label>(131)</label></formula><p><s>In Fig. <ref type="figure" target="#fig_4">S5</ref> H-I, we focus on the case of an external input pattern aligned with x 3 (and thus n (1) ) .</s><s>We fix α = 0, that implies κ 2 = 0.</s></p><p><s>Solving the mean-field equations reveals that, according to the strength of the input Σ I , one or three fixed points exist.</s><s>When the input is weak with respect to the structure overlap ρ 2 , two fixed points appear in the proximity of the ring, along the direction defined by the axis κ 2 = 0 (Fig. <ref type="figure" target="#fig_4">S5</ref> H top).</s><s>In particular, when I positively correlates with n (1) , only the fixed point with positive value of κ 1 gets stabilized.</s><s>The remaining two solutions are characterized by one outlier eigenvalue which lays above the instability boundary, and are thus unstable.</s><s>On the other hand, when the input is sufficiently strong, solely the stable fixed point survives (Fig. <ref type="figure" target="#fig_4">S5</ref> H bottom). Activity is then robustly projected in the direction defined by the right vector m (1) .</s></p><p><s>Rank-two structures for oscillations We finally consider the following configuration:</s></p><formula xml:id="formula_182">m (1) = αx 1 + ρy 1 m (2) = αx 2 + ρy 2 n (1) = αx 3 + ρy 2 + γρy 1 n (2) = αx 4 -ρy 1 ,<label>(132)</label></formula><p><s>where the right-and the left-connectivity vectors share two cross-overlap directions y 1 and y 2 .</s><s>Note that the vectors in one of the two pairs, m (1) -n (2) , are negatively correlated.</s><s>A second overlap is introduced internally to the m (1) -n (1) pair, and scales with the parameter γ.</s><s>The directions x j , with k = 1, ..., 4, represent uncorrelated terms.</s><s>Note that different values of α affect quantitatively the network statistics, but they do not change the phase diagram in Fig. <ref type="figure">S8 A</ref>.</s></p><p><s>By rotating P ij on a proper orthonormal basis, one can check that its eigenvalues are given by:</s></p><formula xml:id="formula_183">λ ± = γρ 2 2 1 ± 1 - 4 γ 2 ,<label>(133)</label></formula><p><s>and they are complex conjugate for γ &lt; 2. In this case, the internal overlap γ has the effect of returning a non-vanishing real part.</s><s>The two complex conjugate eigenvectors are given by:</s></p><formula xml:id="formula_184">e ± = - γ 2 m (1) + m (2) ± i 1 - 4 γ 2 m (1) . (<label>134</label></formula><formula xml:id="formula_185">)</formula><p><s>The eigenspectrum of J ij = gχ ij + P ij inherits the pair of non-zero eigenvalues of P ij .</s><s>When g &lt; 1 and γ &lt; 2, the trivial fixed point thus undergoes a Hopf bifurcation when the real part of λ crosses unity (Fig. <ref type="figure">S8</ref> A, blue).</s><s>When γ &gt; 2, instead, the two eigenvalues are real.</s><s>One bifurcation to bistable stationary activity occurs when the largest eigenvalue λ + crosses unity (Fig. <ref type="figure">S8 A,</ref><ref type="figure">gray</ref>).</s></p><p><s>On the boundary corresponding to the Hopf bifurcation, the frequency of instability ω H is determined by the imaginary part of Eq. 133.</s><s>At the instability, the oscillatory activity of unit i can be represented as a point on the complex plane.</s><s>Since close to the bifurcation we can write:</s></p><formula xml:id="formula_186">µ i = e + i e iω H t + c.c. ,<label>(135)</label></formula><p><s>its coordinates are given by the real and the imaginary part of the ith component of the complex eigenvector e + .</s><s>The phase of oscillation can then be computed as the angle defined by this point with respect to the real axis.</s><s>Note that the disorder in the elements of the eigenvector e + , which is inherited by the random distribution of the entries of the connectivity vectors m (1) and m (2) , tends to favor a broad distribution of phases across the population.</s></p><p><s>In the limit case where the real and the imaginary parts of the complex amplitude of the oscillators are randomly and independently distributed, the population response resembles a circular cloud in the complex plane.</s><s>In this case, the phase distribution across the population is flat.</s><s>Note that a completely flat phase distribution can be obtained for arbitrary frequency values by adopting a rank-two structure where an internal overlap of magnitude γρ 2 exists between vectors m (2) and n (2) as well.</s></p><p><s>In the present case, for every finite value of γ, the real and the imaginary part of e + i are anti-correlated through m (1) (Eq.</s><s>134).</s><s>Correlations tend to align the network response on two main and opposite phases, as shown in the phase histograms of Fig. <ref type="figure">S8 C-D</ref>.</s><s>The distribution of phases becomes sharper and sharper in the γ → 2 limit, as the distribution in the complex plane collapses on the real axis.</s></p><p><s>The phase distribution across the population is reflected in the shape of the closed orbit defined by activity on the m (1) -m (2) plane, whose components are given by κ 1 and κ 2 .</s><s>The phase of the oscillations in κ 1 (resp.</s><s>κ 2 ) can be computed by projecting the eigenvector e + on the right-connectivity vectors n (1) and n (2) :</s></p><formula xml:id="formula_187">κ 1 = |κ 1 |e i(Φ1+ω H t) + c.c. = n (1) i [φ i ] κ 2 = |κ 2 |e i(Φ2+ω H t) + c.c. = n (2) i [φ i ]<label>(136)</label></formula><p><s>By using Eqs.</s><s>134 and 135 we get, in the linear regime:</s></p><formula xml:id="formula_188">κ 1 = n (1) i m (2) i - γ 2 n (1) i m (1) i + i n (1) i m (1) i 1 - 4 γ 2 e iω H t + c.c. = ρ 2 1 - γ 2 2 + iγρ 2 1 - 4 γ 2 e iω H t + c.c.<label>(137)</label></formula><p><s>while:</s></p><formula xml:id="formula_189">κ 2 = n (2) i m (2) i - γ 2 n (2) i m (1) i + i n (2) i m (1) i 1 - 4 γ 2 e iω H t + c.c. = ρ 2 γ 2 -iρ 2 1 - 4 γ 2 e iω H t + c.c.<label>(138)</label></formula><p><s>When γ is close to 2, the complex amplitudes of κ 1 and κ 2 vanish.</s><s>However, their real parts have different signs.</s><s>We thus get: Φ 2 = 0, Φ 1 = π.</s><s>As a consequence, at large γ values, the oscillatory activity in κ 1 and κ 2 tends to be strongly in anti-phase.</s><s>Stationary solutions can be instead easily analyzed with the standard mean-field approach.</s><s>The equations for the first order statistics read:</s></p><formula xml:id="formula_190">κ 1 = (γρ 2 κ 1 + ρ 2 κ 2 ) [φ i ] κ 2 = -ρ 2 κ 1 [φ i ] .<label>(139)</label></formula><p><s>The two equations can be combined together to give the following condition on [φ i ] , which in turn determines the value of ∆ 0 :</s></p><formula xml:id="formula_191">ρ 4 [φ i ] 2 -γρ 2 [φ i ] + 1 = 0.<label>(140)</label></formula><p><s>The mean-field equations thus admit two solutions, given by:</s></p><formula xml:id="formula_192">[φ i ] ± = γ 2ρ 2 1 + ± 1 - 4 γ 2<label>(141)</label></formula><p><s>which, similarly to Eq. 133, take real values for γ &gt; 2. Because of the constraints on the sigmoidal activation function, the mean-field solutions are acceptable only if</s></p><formula xml:id="formula_193">| [φ i ] | &lt; 1.</formula><p><s>As it can be easily checked, the condition [φ i ] -&lt; 1 coincides with imposing λ + &gt; 1.</s><s>We conclude that two stationary solutions exist above the instability boundary of the trivial fixed point (Fig. <ref type="figure">S8</ref> A, gray).</s><s>A second pair of solutions appears for [φ i ] + &lt; 1, which coincide with λ -&gt; 1 (Fig. <ref type="figure">S8</ref> A, dashed), where the second outlier of J ij becomes unstable.</s><s>This second pair of solutions is however always dynamically unstable, as it can be checked by evaluating the outliers of their stability matrix through Eq. 113.</s><s>The coefficients of the reduced matrix M read:</s></p><formula xml:id="formula_194">a 11 = γρ 2 [φ i ] a 12 = ρ 2 [φ i ] b 1 = 1 2 ρ 2 (κ 20 + γκ 10 ) [φ i ]<label>(142)</label></formula><p><s>and</s></p><formula xml:id="formula_195">a 21 = -ρ 2 [φ ] a 22 = 0 b 2 = - 1 2 ρ 2 κ 10 [φ ] .<label>(143)</label></formula><p><s>On the phase diagram boundary corresponding to γ = 2, the stable and the unstable pair of stationary solutions annihilate and disappear.</s><s>At slightly smaller values of γ (γ 2), the network develops highly nonlinear and slow oscillations which can be thought of as smooth jumps between the two annihilation points (Fig. <ref type="figure">S8 D</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation of computational tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Go-Nogo discrimination</head><p><s>Here we describe and analyze the unit-rank implementation of the Go-Nogo discrimination task (Fig. <ref type="figure" target="#fig_2">3</ref>).</s></p><p><s>The network receives inputs specified by N -dimensional vectors I k .</s><s>In every trial, the input vector coincides with one among the two vectors I A and I B , representing respectively the Go and the Nogo stimuli.</s><s>The components of the two input patterns are generated independently from a Gaussian distribution of mean zero and variance Σ I .</s><s>As the components of the inputs are uncorrelated, the two vectors are mutually orthogonal in the limit of large N .</s></p><p><s>The network activity is read-out linearly through a vector w generated from a Gaussian distribution of mean zero and variance Σ 2 w .</s><s>The readout value is given by:</s></p><formula xml:id="formula_196">z = 1 N N i=1 w i φ(x i ).<label>(144)</label></formula><p><s>We fix the connectivity vectors m and n such that: (i) the readout is selective, i.e. z = 0 if the input is I A and z = 0 for the input I B ; (ii) the readout is specific to the vector w, i.e. it is zero for any readout vector uncorrelated with w.</s><s>The simplest network architecture which satisfies these requirements is given by:</s></p><formula xml:id="formula_197">m = w n = I A ,<label>(145)</label></formula><p><s>i.e. the right-connectivity vector m corresponds to the readout vector, and the left-connectivity vector corresponds to the preferred stimulus I A .</s></p><p><s>The response of the network can be analyzed by referring to the stationary and chaotic solutions of Eq. 98.</s><s>In the case analyzed here, the connectivity vectors have no overlap direction, so we set M m = M n = M I = Σ mI = 0, which implies µ = 0.</s><s>The first-order network statistics are determined by the overlap Σ nI between the leftconnectivity vector and the input vector.</s><s>As the left-connectivity is given by I A , Σ nI is the overlap between the current input pattern I and the preferred pattern I A , and it takes values Σ nI = Σ 2 I during the Go stimulus presentation and Σ nI = 0 otherwise.</s><s>From Eq. 94 we have:</s></p><formula xml:id="formula_198">κ = n i [φ i ] = I A i [φ i ] .<label>(146)</label></formula><p><s>As a consequence, when the Go stimulus is presented (I = I A ):</s></p><formula xml:id="formula_199">κ = Σ 2 I [φ i ] ,<label>(147)</label></formula><p><s>while the first-order statistics κ vanishes in response to any orthogonal pattern I B .</s><s>When activity is read out by the specific decoding vector w, the readout value is:</s></p><formula xml:id="formula_200">z = w i [φ i ] = w i Dzφ(m i κ + I i + ∆ I 0 z) = w i Dzφ(w i κ + I i + ∆ I 0 z) = κΣ 2 w [φ i ] ,<label>(148)</label></formula><p><s>while we trivially obtain z = 0 for any decoding set orthogonal to both connectivity vectors m and n.</s></p><p><s>In Fig. <ref type="figure" target="#fig_2">3</ref> C, we display the transient dynamics predicted by the mean-field theory within the m -I plane.</s><s>In order to compute the predicted trajectory, we use Eqs.</s><s>103 and 104, where the slowest time-scale of κ is computed by diagonalizing the reduced stability matrix in Eq. 99.</s></p><p><s>In Fig. <ref type="figure" target="#fig_2">3</ref> G, we test the generalization properties of a network which responds to two Go patterns I A 1 and I A 2 .</s><s>We examine the response to a normalized mixture input defined as:</s></p><formula xml:id="formula_201">I = √ αI A 1 + √ 1 -αI A 2 ,<label>(149)</label></formula><p><s>so that the variance of the total input is fixed and equal to Σ 2 I .</s><s>We set n = I A 1 + I A 2 , so that the equation for the first-order statistics reads:</s></p><formula xml:id="formula_202">κ = I A 1i [φ i ] + I A 2i [φ i ] = ( √ α + √ 1 -α)Σ 2 I [φ i ] .<label>(150)</label></formula><p><s>the modulatory component γy together with the stimulus term c(t)I, where γ is a scalar which controls the strength of the modulation.</s><s>The mean-field equation for the first-order statistics reads:</s></p><formula xml:id="formula_203">κ = (ρ m ρ n κ + ρ n γ + c Σ 2 I ) [φ i ] .<label>(153)</label></formula><p><s>Eq. 153 indicates that the modulatory component of the input acts as a constant offset to the stimulus strength.</s><s>Its net effect is to shift the response curve of the network along the x axis (Fig. <ref type="figure" target="#fig_4">5 B</ref>) by an amount directly regulated by the parameter γ.</s><s>Varying γ thus results in network models which detect variable threshold values.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rank-two structures for context-dependent computations</head><p><s>Here we provide details on the rank-two implementation of the context-dependent tasks.</s><s>The same model has been used for both tasks in Figs. <ref type="figure" target="#fig_4">5</ref> and<ref type="figure" target="#fig_5">6</ref>.</s></p><p><s>The stimuli consist of combinations of two different features A and B that correspond to inputs along two directions I A and I B , generated as Gaussian random vectors of variance Σ 2 I .</s><s>Contextual cues are represented as additional inputs along directions I ctxA and I ctxB of unit variance.</s><s>The total input pattern to the network on a given trial is therefore given by:</s></p><formula xml:id="formula_204">I(t) = c A (t)I A + c B (t)I B + γ A I ctxA + γ B I ctxB . (<label>154</label></formula><formula xml:id="formula_205">)</formula><p><s>The values c A and c B express the strength of the stimulus along the two feature directions.</s><s>They are given by the sum of stationary average values (c A , cB ), and temporary fluctuating components generated from independent realizations of white noise with standard deviation σ.</s><s>In the simple discrimination version of the task (Fig. <ref type="figure" target="#fig_4">5</ref>), inputs are noise-free (σ = 0) and consist of a single feature in each trial (c A = 1 and cB = 0 or vice versa).</s></p><p><s>In the evidence integration version of the task (Fig. <ref type="figure" target="#fig_5">6</ref>), inputs are noisy (σ &gt; 0) and include non-zero average components along both feature directions.</s><s>Finally, the parameters γ A and γ B control the two modulatory inputs which are taken in the directions defined by I ctxA and I ctxB .</s></p><p><s>In order to implement context-dependent computations, we define a unique readout signal z(t) by using a common readout set w of unit variance (Eq.</s><s>144), to which we add an offset so that the baseline Nogo output is set to zero.</s><s>The network is said to respond to the stimulus if the value of the total readout at the end of the stimulus presentation takes values larger than one half of the largest predicted value for the upper state.</s></p><p><s>The rank-two connectivity matrix we consider is given by:</s></p><formula xml:id="formula_206">m (1) = y A + ρ m I ctxA + β m w n (1) = I A + ρ n I ctxA + β n w m (2) = y B + ρ m I ctxB + β m w n (2) = I B + ρ n I ctxB + β n w,<label>(155)</label></formula><p><s>where vectors y A and y B represent the orthogonal components of the right-connectivity vectors and are generated as Gaussian vectors of fixed variance (for simplicity, we set Σ y = Σ I ).</s></p><p><s>For our choice of the parameters, the network solves the two different tasks by relying on the strongly non-linear responses generated by the interplay between the recurrent connectivity and the feed-forward inputs (details given below).</s></p><p><s>For weak input values, the network dynamics is characterized by two stable attractors (Fig. <ref type="figure" target="#fig_5">6 F</ref>).</s><s>As in Fig. <ref type="figure" target="#fig_3">4</ref>, we initialize the network in the state characterized by negative κ 1 and κ 2 values before the stimulus presentation.</s><s>This dynamical attractor corresponds to the Nogo state.</s><s>For strong input strengths, the network can jump to the Go state, defined as the stable attractor characterized by positive κ 1 and κ 2 values.</s></p><p><s>The rank-two connectivity matrix has been designed as an extension of the unit-rank recurrent connectivity employed in Fig. <ref type="figure" target="#fig_3">4</ref>. We started by setting:</s></p><formula xml:id="formula_207">m (1) = y A + ρ m I ctxA n (1) = I A + ρ n I ctxA m (2) = y B + ρ m I ctxB n (2) = I B + ρ n I ctxB .</formula><p><s>(156) Note that, because the only overlap directions (I ctxA and I ctxB ) are internal to the m (1) -n (1) and m (1) -n (1) pairs, Eq. 156 describes a rank-two structure which generates a continuous ring attractor as in Fig. <ref type="figure" target="#fig_4">S5 D-I</ref> (gray circles in Fig. <ref type="figure" target="#fig_5">6 F</ref>).</s></p><p><s>The readout z(t) should detect the presence of both stimuli directions.</s><s>As a consequence, it should be sensitive to both overlap values κ 1 and κ 2 .</s><s>For this reason, we introduce a common term in the four connectivity vectors that is aligned to the common readout (Eq.</s><s>155).</s></p><p><s>Introducing a common overlap direction has the effect of destabilizing the continuous attractor dynamics along the direction κ 1 = κ 2 (dashed line in Fig. <ref type="figure" target="#fig_5">6</ref> F), where two stable and symmetric fixed points are generated.</s><s>The equations for the first-order spontaneous dynamics read indeed:</s></p><formula xml:id="formula_208">κ 1 = n (1) [φ i ] = ρ m ρ n κ 1 [φ i ] + β m β n (κ 1 + κ 2 ) [φ i ] κ 2 = n (2) [φ i ] = ρ m ρ n κ 2 [φ i ] + β m β n (κ 1 + κ 2 ) [φ i ]<label>(157)</label></formula><p><s>from which the value of κ 1 = κ 2 = κ can be derived by dividing and multiplying together the two equations.</s></p><p><s>The final readout signal contains a contribution from both first-order statistics:</s></p><formula xml:id="formula_209">z(t) = w i [φ i ] = β m (κ 1 + κ 2 ) [φ i ] .<label>(158)</label></formula><p><s>The input-driven dynamics of the network are determined by the interplay between the structure strength and the contextual and stimulus inputs.</s><s>Crucially, the modulatory inputs along I ctxA and I ctxB are used to gate a context-dependent response.</s><s>Similarly to Fig. <ref type="figure" target="#fig_4">5</ref> B, a strong and negative gating variable along I ctxA can completely suppress the response to stimulus I A , so that the readout signal is left free to respond to I B .</s></p><p><s>The overall effects of the inputs on the dynamics can be quantified by solving the mean-field equations.</s><s>For the first-order statistics, we obtain:</s></p><formula xml:id="formula_210">κ 1 = [φ i ] ρ m ρ n κ 1 + β m β n (κ 1 + κ 2 ) + cA Σ 2 I + ρ n γ A κ 2 = [φ i ] ρ m ρ n κ 2 + β m β n (κ 1 + κ 2 ) + cB Σ 2 I + ρ n γ B<label>(159)</label></formula><p><s>while the second-order gives, in the case of stationary regimes:</s></p><formula xml:id="formula_211">∆ 0 = g 2 [φ 2 i ] + Σ 2 w (κ 2 1 + κ 2 2 ) + β 2 m (κ 2 1 + κ 2 2 ) + Σ 2 I (c 2 A + c2 B ) + (ρ m κ 1 + γ A ) 2 + (ρ m κ 2 + γ B ) 2 . (<label>160</label></formula><formula xml:id="formula_212">)</formula><p><s>Fig. <ref type="figure" target="#fig_4">S5</ref> L-M displays the values of the first-order statistics and the readout response in the two contexts.</s><s>Note that, when the response to I A (resp.</s><s>I B ) is blocked at the level of the readout, the relative first-order statistics κ 1 (resp.</s><s>κ 2 ) does not vanish, but actively contributes to the final network response.</s></p><p><s>The average activation variable of single neurons contains entangled contributions from the main directions of the dynamics, which are inherited both from the external inputs and the recurrent architecture:</s></p><formula xml:id="formula_213">µ i = [x i ] =(y A,i + ρ m I ctxA,i + β m w i )κ 1 + (y B,i + ρ m I ctxB,i + β m w i )κ 2 + cA I A i + cB I B i + γ 1 I ctxA,i + γ 2 I ctxB,i .<label>(161)</label></formula><p><s>In Figs. 5 E and 6 D, we project the averaged activation µ i in the directions that are more salient to the task.</s><s>The projection along w, which reflects the output decision, is proportional to the readout value (Eq.</s><s>158).</s><s>The input signals affect instead the average activity through the values of κ 1 and κ 2 , but can be also read out directly along the input directions.</s><s>Note that the projection on the input direction I A (resp.</s><s>I B ) is proportional to the signal cA (resp.</s><s>cB ) regardless of the configuration of the modulatory inputs selecting one input channel or the other.</s></p><p><s>In practical terms, in order to obtain the network architecture that has been used in Figs. <ref type="figure" target="#fig_4">5</ref> and<ref type="figure" target="#fig_5">6</ref>, we fixed the parameters step by step.</s><s>We first considered input patterns only along I A (c B = 0), and we fixed two arbitrary values of β m and β n .</s><s>In particular, we considered intermediate values of β.</s><s>Large values of β tend to return large activity variance, which requires evaluating with very high precision the Gaussian integrals present in the mean-field equations.</s><s>Small values of β bring instead the network activity closer to a continuous-attractor structure, and turn into larger finite-size effects.</s><s>In a second step, we fix ρ m and ρ n such that the network detects normalized input components along I A only when they are larger than a threshold value, that is taken around 0.5.</s><s>We then looked for a pair of gating variables strengths [γ A , γ B ] which completely suppresses the response to I A by extending the range of bistable activity.</s><s>The opposite pattern can be used to block the response in I B and allow a response in I A .</s></p><p><s>Once the response in I A has been blocked, it can be verified that the network solely responds to inputs which contain a response along I B that is larger than a threshold close to 0.5.</s><s>Note that, as in Fig. <ref type="figure" target="#fig_4">S5 L-M</ref>, different values of cA only minimally affect the exact position of the threshold.</s></p><p><s>To conclude, we remark that this procedure leaves the freedom of fixing the network parameters in many different configurations.</s><s>The complex rank-two architecture leads to larger finite-size effects than the respective unit-rank setup which acts as a single detector of correlations.</s><s>In particular, the error at the level of the readout is larger but it decays with the system size, as expected for deviations induced by finite-size effects (Fig. <ref type="figure" target="#fig_4">S5</ref> N).</s><s>Finally, note that when the noise in the input stimuli becomes extremely large, the network loses its ability to respond in a totally context-dependent fashion, as strong fluctuations in the non-relevant stimulus become likely to elicit a response.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method details for Main Figures</head><p><s>Figure <ref type="figure" target="#fig_0">1</ref> In this figure, Σ m = Σ n = 1.0.</s><s>Note that the precise position of the instability to chaos depends on the value of Σ m .</s><s>The connectivity vectors m and n were generated from bivariate Gaussian distributions (means M m and M n , variances Σ m and Σ n , correlation ρ).</s><s>Here we display the case where m and n overlap only along the unitary direction (M m &gt; 0, M n &gt; 0, ρ = 0, see Methods).</s><s>As shown in Fig. <ref type="figure" target="#fig_1">S2</ref>, qualitatively similar regimes are obtained when the overlap is defined on an arbitrary direction.</s><s>C-D: Network simulations were performed starting from initial conditions centered around m and -m.</s><s>Activity is integrated up to T = 800.</s><s>In simulations, N = 5000, and statistics are averaged over 15 different connectivity realizations.</s><s>The error bars, when visible, correspond to the standard deviation of the mean (as in every other figure, if not differently specified).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p><s>In this figure, g = 0.8.</s><s>Other parameters are set as in Fig. <ref type="figure" target="#fig_0">1</ref>.</s><s>B: The asymptotic input parameters are indicated by gray dots in D (middle).</s><s>The simulation results (dark gray traces) correspond to 20 trajectories for different network realizations (different trajectories strongly overlap).</s><s>We simulated N tr = 20 different networks, each consisting of N = 3500 units.</s><s>In every network realization, the random part of the connectivity χ ij is varied, while the low-rank part m i n j is kept fixed.</s><s>I (resp.</s><s>m) scale: 0.7 (resp.</s><s>0.25) units.</s><s>D: The external input is increased along n ⊥ , the component of n that is perpendicular to the overlap direction.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3</head><p><s>The input and the readout vectors are Gaussian patterns of standard deviation Σ = 2. C (right): Colored traces: 20 trajectories from different network realizations (different trajectories strongly overlap).</s><s>We simulated N tr = 20 different realizations of the network, each consisting of N = 2500 units.</s><s>In every network realization, the random part of the connectivity χ ij is generated independently, while the low-rank part m i n j is kept fixed.</s><s>I A , I B and m scale: 1.5 units.</s><s>D: Here, and in every plot if not differently stated, ρ indicates the Pearson correlation coefficient.</s><s>F: The PC axis are determined by analyzing separately the trials corresponding to the Go (top) and the Nogo (bottom) stimuli.</s><s>Connectivity is measured as the average reciprocal synaptic strength; it includes both the random and the unit-rank components and it is averaged across network realizations.</s><s>Note that the value of the correlation coefficient ρ increases with the number of realizations N tr and the structure strength.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p><s>The input and the readout vectors are Gaussian patterns of standard deviation Σ = 1.2.</s><s>The overlap between the connectivity vectors m and n leading to non-linear responses is quantified by ρ m = ρ n = 2.0.</s><s>B: The input is generated as white noise of mean c = 0.6 and standard deviation σ = 0.4 (the noise trace in the figure is only for illustration purposes).</s><s>The red dashed line indicates the threshold in the implemented network.</s><s>C: The gray bar indicates the time point at which the network output is measured.</s><s>Here and in the following figures, the readout includes an offset, so that the baseline value is set to zero.</s><s>D: We simulated many input noise traces for N tr = 4 different realizations of the network, each consisting of N = 2500 units.</s><s>In every network realization, the random part of the connectivity χ ij is varied, while the low-rank part m i n j is kept fixed.</s><s>Trajectories are smoothed with a Gaussian filter of standard deviation equal to one normalized time unit.</s><s>I (resp.</s><s>m) scale: 0.5 (resp.</s><s>3.5) units.</s><s>F: The structure strength corresponds to the overlap ρ m ρ n .</s><s>The effective time scale is measured as the inverse of the value of the outlier eigenvalue of the stability matrix for c = 0. G: The psychometric curve was measured across N tr = 100 different realizations.</s><s>The network produces an output to the stimulus if at the end of the stimulus presentation (vertical gray line in B) the value of the readout z is larger than one half of the largest readout value predicted by the theory.</s><s>H: Details as in Fig. <ref type="figure" target="#fig_2">3</ref> F.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5</head><p><s>The stimuli vectors are Gaussian patterns of standard deviation Σ = 1.2.</s><s>We furthermore set: g = 0.8, β m = 0.6, β n = 1, ρ m = 3, ρ n = 1.6.</s><s>The amplitudes of the two context directions are fixed to [0.08, -0.14] (resp.</s><s>[-0.14, 0.08]) during the Context A (resp.</s><s>Context B) trials.</s><s>B: We consider in this case a unit-rank network as in Fig. <ref type="figure" target="#fig_1">2</ref> D, and we show in the two panels the network response for two different values of the input strength along the overlap axis (we set, respectively, M I = -0.3 and 0.6).</s><s>Details on the effect of contextual modulation on the full rank-two model are further illustrated in Fig. <ref type="figure" target="#fig_4">S5 L-N</ref>.</s><s>E: We simulated N tr = 4 different realizations of the network, each consisting of N = 3000 units.</s><s>In every network realization, the random part of the connectivity χ ij is varied, while the low-rank part m i n j is kept fixed.</s><s>I A and I B (resp.</s><s>w) scale: 1.0 (resp.</s><s>2.0) units.</s><s>F: The network performance was measured across N tr = 50 different network realizations of size N = 7500.</s><s>The network produces an output to the stimulus if at the end of the stimulus presentation (vertical gray line in D) the value of the readout z is larger than one half of the largest readout value predicted by the theory.</s><s>G: Details as in Fig. <ref type="figure" target="#fig_2">3</ref> F.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p><s>The stimuli vectors are Gaussian patterns of standard deviation Σ = 1.2.</s><s>We furthermore set: g = 0.8, β m = 0.6, β n = 1, ρ m = 3, ρ n = 1.38.</s><s>The amplitudes of the two context directions are fixed to [0.08, -0.18] (resp.</s><s>[-0.18, 0.08]) during the Context A (resp.</s><s>Context B) trials.</s><s>B: Here cA = 0.6 and cB = 0.1, while the standard deviation of the noise in the input is σ = 0.3 (the noise trace in the figure is only for illustration purposes).</s><s>D: We simulated many noisy input traces for N tr = 5 different realizations of the network, each consisting of N = 4000 units.</s><s>In every network realization, the random part of the connectivity χ ij is varied, while the low-rank part m i n j is kept fixed.</s><s>For the sake of clarity, only correct trials have been included.</s><s>I A and I B (resp.</s><s>w) scale: 1 (resp.</s><s>1.5) units.</s><s>E: Network performance was measured across N tr = 50 different network realizations of size N = 7500.</s><s>matrix X. Applying the PCA analysis to one of the two data formats impacts the results from a quantitative point of view, but does not change their general validity.</s></p><p><s>The principal components (PC) are computed as the normalized eigenvectors {e l } l=1,...,N of the correlation matrix C = X T X.</s><s>The PC are sorted in decreasing order according to the corresponding real eigenvalue λ l .</s><s>The activation matrix X can be projected on the orthonormal basis generated by the PC vectors by computing: X = XE, where E is the N × N matrix containing the PC eigenvectors ordered as columns.</s><s>The variance explained by the l-th PC mode e l can be computed as the l-th entry on the diagonal of the rotated correlation matrix C = X T X .</s></p><p><s>While in our network models the low-rank part of the connectivity determines a purely low-dimensional dynamics (Fig. <ref type="figure" target="#fig_2">S3</ref> A), the random part of the connectivity generates a continuum of components whose amplitude is determined by strength of the random connectivity g with respect to the connectivity and input vectors.</s><s>In Fig. <ref type="figure" target="#fig_1">2</ref>, where g = 0.8, the low-dimensional nature of the dynamics is revealed by considering averages across several (N tr = 20) realizations of the random connectivity.</s><s>In Fig. <ref type="figure" target="#fig_2">S3</ref> B, we illustrate the result of performing PCA on the activity generated by a single network.</s><s>In this case, even if more PC components contribute to the total variance, the two first axis bear a strong resemblance with the directions predicted with the theory.</s><s>In Fig. <ref type="figure" target="#fig_2">S3</ref> C we show that, in the same spirit, a PCA analysis can be used to extract the relevant geometry of the network model also when activity is strongly chaotic.</s></p><p><s>In order to more easily connect with the theoretical predictions, we systematically applied dimensionality reduction on datasets constructed from the activation variable x i .</s><s>We verified that our results still hold, from a qualitative point of view, when the analysis is performed on the non-linearly transformed variables φ(x i ).</s><s>In the network models we considered, the activation variables φ(x i ) indeed form a non-linear but dominantly lowdimensional manifold in the phase space.</s><s>The axes predicted by the mean-field theory determine the dominant linear geometry of this manifold, and can be still captured (although less precisely) by looking at the first PC components.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear regression</head><p><s>In order to estimate how single units in the network are tuned to different task variables (such as input stimuli or decision variables), we used a multi-variate linear regression analysis.</s></p><p><s>To this end, we considered the full population response x k i (t), where k = 1, ..., N tr indicates the trial number.</s><s>Following <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>, our aim was to describe the network activation variables as linear combinations of the M relevant task variables.</s><s>In Fig. <ref type="figure" target="#fig_2">3</ref>, the two variables we considered were the strength of the Go and of the Nogo inputs, that we indicate here with c Go and c Nogo :</s></p><formula xml:id="formula_214">x k i (t) = β Go i,t c Go (k) + β Nogo i,t c Nogo (k).<label>(162)</label></formula><p><s>In a Go, or in a Nogo trial, only one of the two strength coefficients is non-zero.</s><s>In Fig. <ref type="figure" target="#fig_3">4</ref>, the two relevant task variables are assumed to be the input strength along I, quantified by c, and the network output, quantified as the value of the readout z at the end of the stimulus presentation:</s></p><formula xml:id="formula_215">x k i (t) = β input i,t c(k) + β choice i,t z(k).<label>(163)</label></formula><p><s>In Figs. <ref type="figure" target="#fig_4">5</ref> and<ref type="figure" target="#fig_5">6</ref>, the relevant variables are four: the strength of stimuli A and B, the trial context and the network output.</s><s>We thus have:</s></p><formula xml:id="formula_216">x k i (t) = β A i,t c A (k) + β B i,t c B (k) + +β ctx i,t y(k) + β choice i,t z(k). (<label>164</label></formula><formula xml:id="formula_217">)</formula><p><s>where the context variable is represented by a unique symbolic variable y, which takes value y = 1 in Context A and y = -1 in Context B.</s></p><p><s>More generally, we indicate with β ν i,t the regression coefficient of unit i with respect to the task feature ν at time t.</s><s>The vector β i,t = {β ν i,t } ν=1,..,M indicates the collection of the M variables regressors for a given unit at the time point t.</s><s>We compute the regression coefficients by defining a matrix F of size M × N tr , where every row contains the value of the M relevant task variables across trials.</s><s>The regression coefficient vectors are then estimated by least-square inversion:</s></p><formula xml:id="formula_218">β i,t = (F F T ) -1 F x i,t<label>(165)</label></formula><p><s>where the vector x i,t is constructed by collecting across trials the value the activation variable of unit i at time t.</s></p><p><s>In order to get rid of the time dependence of our result, we simply consider the coefficients β i,t at the time point where the two-dimensional array β i,t for every i has maximal norm <ref type="bibr" target="#b26">(Mante et al., 2013)</ref>.</s><s>The resulting set of M -dimensional vectors β i contains the regression coefficients of unit i with respect to the M relevant task variables.</s><s>The N -dimensional regression axis for a given task variable ν is finally constructed by collecting the ν-th components of β i across different population units: {β ν i } i=1,..,N .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Software Availability</head><p><s>Software was written in the Python (http://python.org)</s><s>programming languages.</s><s>Implementations of algorithms used to compute quantities presented in this study are available at: https://github.com/fmastrogiuseppe/lowrank/.</s><s>(A-B-C) Eigenspectrum of the partially structured connectivity matrix J ij , related to the stability matrix S ij of the homogeneous fixed points through: S ij = φ (x)J ij .</s><s>A. Eigenspectrum of J ij in the complex plane.</s><s>Red dots: eigenspectrum of a single realization J ij of size N = 1000.</s><s>In black: theoretical prediction.</s><s>Every matrix J ij consists of a sum of a random and of a fixed unit-rank structure.</s><s>In the large N limit, the spectrum of the full matrix is given by the sum of the eigenspectra of the two parts.</s><s>The black circle has radius equal to the total random strength g, and the black star indicates the position of the non-zero eigenvalue of the rank-one structure P ij .</s><s>B. Mismatch between the statistics measured in finite-size networks (x sim ) and the theoretical prediction (x th ) as the network size N is increased.</s><s>The error is normalized: |x sim -x th |/x th .</s><s>Averages over 100 realizations.</s><s>The error bars (as in every other figure, if not differently specified) correspond to the standard deviation of the mean.</s><s>Dashed lines: power-law best fit (y ∝ N γ ).</s><s>The values of γ are indicated in the legend.</s><s>C. Pearson correlation coefficient between the connectivity eigenvector m and the eigenvector ê which corresponds to the outlier eigenvalue.</s><s>Choice of the parameters: ρ = 0, M m M n = 1.43,</s><s>Σ m = 0.33, Σ n = 1.</s><s>In A and B, g = 0.7.</s></p><formula xml:id="formula_219">A B C D E F G g &gt; 1 g &lt; 1 M m M n &gt; 1 M m M n &lt; 1</formula><p><s>(D-E-F) Analysis of the eigenspectrum of the linear stability matrix S ij = φ (x)J ij for heterogeneous stationary solutions.</s><s>D. Eigenspectrum of S ij in the complex plane.</s><s>Red dots: eigenspectrum of a single, finite-size realization of S ij , N = 2500.</s><s>The radius of the black circle corresponds to the theoretical prediction r = g [φ <ref type="formula" target="#formula_1">2</ref>i ] .</s><s>The black star indicates the position of the non-zero eigenvalue of the rank-one structure m i φ (x 0 j )n j /N , which deviates significantly from the position of the outlier eigenvalue.</s><s>We thus address the problem of evaluating the position of the outlier eigenvalue through a mean-field stability analysis (Eq.</s><s>71), the prediction of which is indicated by the blue star.</s><s>E. Mismatch between the results from simulations and mean-field predictions for the radius and the outlier position.</s><s>The error is measured as an average over N tr = 30 finite size matrices, and decays as the system size is increased.</s><s>Details as in B. F. Radius and outlier of the stability eigenspectrum for increasing random strength values.</s><s>The dots indicate the results of numerical simulations of networks with N = 2500 units, averaged over N tr = 30 realizations of the random and structured connectivities.</s><s>In grey: radius of the compact bulk (continuous line: mean-field prediction r).</s><s>In blue: position of the outlier eigenvalue (continuous dark and light lines: first and second eigenvalue of matrix M given in Eq. 71).</s><s>In black: position of the outlier when χ ij is shuffled (continuous line: mean-field prediction for the outlier of the structured part m i φ (x 0 j )n j /N ).</s><s>Choice of the parameters: ρ = 0, M m M n = 2.2, Σ m = 0.4, Σ n = 1.</s><s>In D and E, g = 0.5.</s></p><p><s>(G) Graphical analysis of stationary solutions.</s><s>Large figures: nullcline plots for the population-averaged DMF equations in Eq. 83.</s><s>Black dots indicate the solutions that are stable with respect to the outlier eigenvalue.</s><s>Four set of parameters (two values for M m M n , two for g) have been selected.</s><s>Note that the shapes of the µ and the ∆ 0 nullcline depend only on the structure strength M m M n and the disorder strength g.</s><s>For the figures in the first (resp.</s><s>second) row, the structure strength M m M n = 0.55 (resp.</s><s>M m M n = 2.0) is weak (resp.</s><s>strong).</s><s>For the figures in the first (resp.</s><s>second) column: the random strength g = 0.7 (resp g = 2.0) is weak (resp.</s><s>strong).</s><s>Note that the stationary states at large g values (right column) are always unstable with respect to the continuous component of their stability eigenspectra (Fig. <ref type="figure" target="#fig_0">1 C-D</ref>).</s><s>The small side figures associated to every row and column show how the µ (for the rows) and ∆ 0 (for the columns) nullclines have been built.</s><s>We solve µ = F (µ) (resp.</s><s>∆ 0 = G(∆ 0 )) for different initial values of ∆ 0 (resp.</s><s>µ).</s><s>Different initial conditions are displayed in gray scale.</s><s>Dark grey refers to ∆ 0 = 0 (resp.</s><s>µ = 0).</s><s>The dots indicate the solutions for different initial values, which together generate the nullcline curves.</s><s>Choice of the parameters: (A) Graphical analysis of stationary solutions.</s><s>Large figures: nullcline plots for the population-averaged DMF equations in Eq. 89.</s><s>Black dots indicate the solutions that are stable with respect to the outlier eigenvalue.</s><s>Four set of parameters (two values for ρΣ m Σ n , two for g) have been selected.</s><s>Note that the shapes of the κ and the ∆ 0 nullcline depend only on the structure strength ρΣ m Σ n and the disorder strength g.</s><s>For the figures in the first (resp.</s><s>second) row, the structure strength ρΣ m Σ n (resp.</s><s>ρΣ m Σ n ) is weak (resp.</s><s>strong).</s><s>For the figures in the first (resp.</s><s>second) column: the random strength g = 0.5 (resp.</s><s>g = 1.7) is weak (resp.</s><s>strong).</s><s>Note that the stationary states at large g values (right column) are always unstable with respect to the continuous circular component of their stability eigenspectra (see B-C-D).</s><s>The small figures associated to every row and column show how the κ (for the rows) and ∆ 0 (for the columns) nullclines have been built.</s><s>We solve κ = F (κ) (resp.</s><s>∆ 0 = G(∆ 0 )) for different initial values of ∆ 0 (resp.</s><s>κ).</s><s>Different initial conditions are displayed in gray scale.</s><s>Dark grey refers to ∆ 0 = 0 (resp.</s><s>κ = 0).</s><s>The dots indicate the solutions for different initial values, which together generate the nullcline curves.</s><s>Individual second order statistics.</s><s>The DMF solutions are displayed as continuous (resp.</s><s>dashed) lines if they correspond to a stable (resp.</s><s>unstable) state.</s><s>In C-D, top panels display statistics for stationary solutions and bottom panels display statistics for chaotic solutions.</s><s>Dots: we measured activity statistics in finite-size networks, starting from globally positive and negative initial conditions.</s><s>Activity is integrated up to T = 400.</s><s>N = 3500, average over 8 different network realizations.</s><s>Choice of the parameters:</s></p><formula xml:id="formula_220">Σ m = 1. A ρΣ m Σ n &lt; 1 g &gt; 1 g &lt; 1 ρΣ m Σ n &gt; 1 C B Stationary</formula><formula xml:id="formula_221">Σ m = Σ n = 1.5, ρ = 2.0/Σ m Σ n .</formula><p><s>Figure <ref type="figure" target="#fig_2">S3</ref>: Two-dimensional dynamics in networks with unit-rank structure and external inputs.</s><s>Related to Figure <ref type="figure" target="#fig_1">2</ref>.</s></p><p><s>We consider a unit-rank network as in Fig. <ref type="figure" target="#fig_1">2 B-C</ref>.</s><s>The connectivity vectors m and n are orthogonal, but the external input vector contains a component along n, whose strength (quantified by Σ nI , see Methods) undergoes a step increase from 0.2 to 2.0.</s><s>We simulate data from networks of size N = 3500.</s><s>We analyze the dimensionality of the dynamics by comparing the relevant low-dimensional trajectory predicted by the mean-field theory with the strongest modes extracted through dimensionality reduction (Principal Component analysis, see Methods).</s><s>A. Analysis for a purely structured network (g = 0).</s><s>Left top: the mean-field theory predicts that the lowdimensional network dynamics x = {x i } lies in the plane defined by the right-connectivity vector m and the external input I.</s><s>We thus projected the high-dimensional population activity (dark grey trajectory) on this plane.</s><s>Left bottom: we projected the network dynamics (continuous), along with the two vectors m and I (dashed), on the plane defined by the first two PC axis e 1 and e 2 .</s><s>Right top: Pearson correlation coefficient between vectors m and I and the first eight PC.</s><s>Right bottom: strength of the first eight PC, measured as the fraction of the standard deviation of activity that they explain (see Methods).</s><s>Note that when the network connectivity is fully structured (g = 0) as in this case, activity is exactly two-dimensional.</s><s>The first two PC axis span the m -I plane, but they define a rotated set of basis vectors.</s><s>B. Analysis for a network which includes a random term in the connectivity matrix (g = 0.8).</s><s>While in Fig. <ref type="figure" target="#fig_1">2</ref> we performed the PC decomposition on trial-averaged data (N tr = 20), here we considered a single trial, defined as a single realization of the random connectivity matrix.</s><s>Details as in A. Note that the random component of the connectivity adds noisy contributions in a continuum of PC directions, whose strength depends on the value of g with respect to the amplitude of input and connectivity vectors, and becomes weaker and weaker when averaging with respect to different realizations of χ ij .</s><s>When g &gt; 0, vectors m and I are not fully contained in the e 1 -e 2 plane, so their projections on the PC plane are not orthogonal.</s><s>C. Analysis for a network which includes a strong random term in the connectivity matrix (g = 1.8), such that spontaneous activity is chaotic.</s><s>In the left-most column, similarly to Fig. <ref type="figure" target="#fig_1">2</ref>, we plot the time trajectories of four randomly selected units.</s><s>The center and the right columns are as in A and B, with PCA performed on trial-averaged activity (N tr = 20).</s><s>The scale of the projections panels is here set arbitrarily.</s><s>and the strength of the input along the direction of n that is perpendicular to the structure overlap, n ⊥ (again quantified by Σ nI ).</s><s>Similarly to Fig. <ref type="figure" target="#fig_0">1</ref>, strong structure overlaps can lead to the appearance of two bistable solutions.</s><s>In presence of non trivial external inputs, however, such solutions are not symmetric, and can loose stability on different parameter boundaries.</s><s>In particular, we observe that external inputs tend to suppress bistable regimes, by favouring one solution over the other.</s><s>In C, finally, the network configuration is similar to B, but we consider external inputs which include a second component along the direction of n that is shared with m, n (quantified by M I ).</s><s>We observe that both input directions play similar roles in reducing the extent of the bistable regime.</s><s>Choice of parameters: g = 2.2, Σ m = Σ n = 1.0,</s><s>Σ mI = 0.</s></p><p><s>(D) Graphical analysis of stationary solutions.</s><s>In this example, the external input vector overlaps with n on the unitary overlap direction n (M I = 0.13), and includes orthogonal components quantified by Σ I = 0.3.</s><s>Large figures: nullcline plots for the stationary form of the population-averaged DMF equations in Eq. 98. Black dots indicate the solutions that are stable with respect to the outlier eigenvalue.</s><s>Four set of parameters (two values for M m M n , two for g) have been selected.</s><s>Note that the shape of the µ and the ∆ 0 nullcline depends only, respectively, on the structure strength M m M n and the disorder g together with the input statistics.</s><s>For the figures in the first (resp.</s><s>second) row, the structure strength M m M n = 0.55 (resp.</s><s>M m M n = 2.0) is weak (resp.</s><s>strong).</s><s>For the figures in the first (resp.</s><s>second) column: the random strength g = 0.7 (resp.</s><s>g = 2.0) is weak (resp.</s><s>strong).</s><s>The small figures associated to every row and column show how the µ (for the rows) and ∆ 0 (for the columns) nullclines have been built.</s><s>We solve µ = F (µ) (resp.</s><s>(A-B-C) Rank-one networks can robustly perform computations also when their dynamics is chaotic due to large random connectivities.</s><s>Here, we show an example from the Go-Nogo task (Fig. <ref type="figure" target="#fig_2">3</ref>).</s><s>We focus on large random strength values (g = 2.5), so that spontaneous network dynamics is chaotic.</s><s>A. Left: response of three randomly selected units to the Go pattern I A (top, blue) and to the Nogo pattern I B (bottom, green).</s><s>Right: time trace of the readout z(t) for the Go (blue) and the Nogo (green) stimulus.</s><s>B. Absolute, normalized distance between the theoretical prediction and the value of the readout z obtained from finite-size realizations.</s><s>As expected, the magnitude of the average normalized error decays with the network size as ∼ 1/ √ N .</s><s>In grey: g = 0.8, in black: g = 2.5.</s><s>Averages over 200 network realizations.</s><s>Details as in Fig. <ref type="figure" target="#fig_7">S1 B</ref>. C. As in Fig. <ref type="figure" target="#fig_2">3</ref> F, we consider pairs of units and we compute the correlation coefficient between their weights onto the first PC axis and their average reciprocal connectivity strength.</s><s>The PC axis is computed separately for data corresponding to Go (blue) or the Nogo (green) trials.</s><s>The correlation coefficient for the Go trials decreases with the amplitude of the random connectivity, although the error in the readout is only weakly affected (panel B.).</s><s>For every entry of the connectivity matrix J ij , indeed, the random part gχ ij has larger amplitude then the structured one P ij .</s><s>As a consequence, the random noise can hide a fraction of the strong correlations existing between the PC weights and the rank-one connectivity P ij .</s><s>Note that the absolute value of the correlation coefficient depends on the variance of the rank-one connectivity.</s><s>Finally, the correlation coefficient increases as the connectivity gets averaged on more and more realizations of the random part.</s><s>Choice of the parameters as in Fig. <ref type="figure" target="#fig_2">3</ref>.</s></p><p><s>(D-E-F-G-H-I) Ring attractor from rank-two connectivity structures with connectivity vectors characterized by strong internal overlaps (see Methods).</s><s>D. Sample of activity from a finite-size realization (N = 4000) of the rank-two network.</s><s>Activity is initialized in two different initial conditions (light and dark blue), indicated by the small arrows.</s><s>Left: time traces of the activation variables for three randomly selected network units.</s><s>Note the long time range on the x axis.</s><s>Right: population activation x = {x i } projected on the plane spanned by the right vectors m (1) and m (2) .</s><s>The ring attractor predicted by the mean-field theory is displayed in light gray.</s><s>The strength of the disorder is g = 0.5, so that the network is in a stationary regime.</s><s>In the small inset, we reproduce the theoretical prediction together with the final state of additional N tr = 20 networks realizations, that are displayed as grey dots.</s><s>E. Sample of activity for two finite-size realizations (N = 4000) of the structured connectivity matrix (dark and light red).</s><s>Details as in D. The strength of random connections is g = 2.1, so that the network is in a chaotic regime.</s><s>Chaotic fluctuations can occur together with a slow exploration of the ring (dark red).</s><s>If two specific states on the ring appear to be more stable, chaotic fluctuations can induce jumps between the two of them (light red).</s><s>F-G.</s><s>Mean-field characterization of the ring structure: radius of the ring attractor and stability eigenvalues.</s><s>Details as in Fig. <ref type="figure" target="#fig_0">1</ref>.</s><s>Dots: numerical results from finite-size (N = 4000) networks, averaged over 6 realizations of the connectivity matrix.</s><s>H-I.</s><s>Input patterns which correlate with the left vector n (1) reduce the ring attractor to a single stable state.</s><s>Activity is thus projected in the direction spanned by the right vector m (1) .</s><s>In H, we show the input response for two finite-size networks.</s><s>The grey ring displays the mean-field solution in absence of external inputs (g = 0.5, as in D).</s><s>In the top panel, the input is weak (Σ I = 0.2, see Methods).</s><s>The transient dynamics as well as the equilibrium state lie close to the ring structure.</s><s>In the bottom panel, the input is strong (Σ I = 0.6), and the ring structure is not anymore clearly apparent.</s><s>In I, we plot the values of the overlaps κ 1 (blue) and κ 2 (azure) as a function of the structure strength parameter ρ, for fixed input strength.</s><s>Stable solutions are plotted as continuous lines, unstable ones as dashed.</s><s>Solid (resp.</s><s>transparent) lines refer to weak (resp.</s><s>strong) external inputs: Σ I = 0.2 (resp.</s><s>0.6).</s><s>The vertical gray line indicate the value of ρ that has been used in H. Dots: numerical results as in F-G.</s><s>Choice of the parameters (see Methods): Σ = 2.0, ρ 1 = ρ 2 = 1.6.</s></p><p><s>(L-M-N) Rank-two structures for implementing non-linear stimuli detection in a context-dependent fashion (Fig. <ref type="figure" target="#fig_5">6</ref>): theoretical mean-field predictions.</s><s>L. Values of the first-order statistics κ 1 (continuous) and κ 2 (dashed) as a function of the overlap strength along the stimulus I A .</s><s>Results are shown for four increasing values of the overlap strength along the second stimulus I B .</s><s>Top (resp.</s><s>bottom): the contextual gating inputs are such that a response to I A (resp.</s><s>I B ) is selected.</s><s>M. Readout value, built by summing the values of κ 1 and κ 2 (Eq.</s><s>158).</s><s>Note that although κ 1 and κ 2 vary with input strength, on each branch their sum is approximately constant.</s><s>Details as in L. N. Average normalized error between the DMF predictions and the simulated readout, in the two gating conditions as a function of the network size N .</s><s>Average over 60 network realizations, details as in Fig. <ref type="figure" target="#fig_7">S1</ref> B. Parameters as in Fig. <ref type="figure" target="#fig_5">6</ref>.</s><s>In Fig. <ref type="figure" target="#fig_0">1</ref> we have shown that, when the structure strength is large, the DMF theory predicts the existence of two bistable states, which can display chaotic activity.</s><s>For those states, the population-averaged statistics of the activation variable x i are stationary.</s><s>In the chaotic regime, indeed, irregular temporal fluctuations are decorrelated from one unit to the other, so that the central limit theorem applies at every time step, and the network statistics are constant in time.</s><s>In finite-size networks, however, the network statistics are not stationary: their dynamics display instead two different time-scales.</s><s>The instantaneous population-averaged activity undergoes small fluctuations of amplitude O(1/ √ N ), whose time-scale is given by the relaxation decay of chaotic activity.</s><s>Because of bistability, furthermore, the first-order statistics displays also sharp transitions from positive to negative values and viceversa, which are made possible by the self-sustained temporal fluctuations.</s><s>In the following, we focus on rank-one structures where the overlap direction is defined along the unitary vector.</s><s>As a consequence, the relevant first-order statistics is simply the population-average of the activation vector µ (see Methods). A. Sample from a finite-size network: activation time traces for randomly chosen units displaying attractors jumps.</s><s>Dashed blue line: time-dependent population average.</s><s>B. Time-dependent population average in a longer trial.</s><s>C-D.</s><s>We consider transition events as point processes, and we measure the average transition rate.</s><s>We arbitrarily define a transition point as the time step at which the populationaveraged activation crosses zero (grey points in B).</s><s>In C, we show that the transition rate decays to zero as the network size N is increased.</s><s>Details as in Fig. <ref type="figure" target="#fig_7">S1 B</ref>. Note that the transition rate depends on the amplitude of finite-size fluctuations measured with respect to the average phase space distance between the two attractors.</s><s>As a consequence, the transition rate depends on the architecture parameters and on the network size, but also varies strongly from one realization of the connectivity matrix to the other.</s><s>D. Fano factor of the point process for different values of the network size N , which noisily oscillates around 1. For every realization of the network, the jumps count is measured in different windows of the total integration time T = 15.000.</s><s>The Fano factor is measured for every realization and then averaged over N tr = 30 different networks.</s><s>E-F.</s><s>Analysis of the two time-scales displayed by the network dynamics.</s><s>The first time-scale is measured as the relaxation time constant τ r , which can be derived within the DMF framework by computing the time decay of the full autocorrelation function ∆(τ ).</s><s>The persistence time scale, indicated by τ p , coincides instead with the average time interval which separates two attractors transitions.</s><s>In E, we show that both time scales depend on the network architecture parameters.</s><s>Here, we fix the random strength g = 3 and we increase the structure strength.</s><s>When the structure is weak (left), the network is in the classical homogeneous chaotic state.</s><s>The persistence time scale coincides here with the relaxation time constant of chaotic fluctuations.</s><s>When the structured and the random components have comparable strengths, instead, two heterogeneous chaotic phases co-exist (center).</s><s>In this regime, the average persistence time increases monotonically with the structure strength, and reaches arbitrarily large values.</s><s>Note that the relaxation time undergoes a very slow increase before sharply diverging at the boundary with stationary states, but the increase takes place on a much smaller scale.</s><s>Finally, if the structure is too strong (right), the two bistable states become stationary.</s><s>In this region, τ r is formally infinite, while τ p coincides with the total duration of our simulations.</s><s>Pink continuous line: DMF prediction, measured as the full width half maximum of the auto-correlation function ∆(τ ).</s><s>Pink dots: a rough estimate of τ r from finite size networks is obtained by rectifying the population average signal and we computing the full width half maximum of its auto-correlation function.</s><s>F. We compare the average transition rate with the average overlap between the two attractors in the phase space.</s><s>For every unit, the typical overlap between its positive and its negative trajectories is given by π i = 2(-µ -√ ∆ ∞ z + √ ∆ 0 -∆ ∞ ).</s><s>We average across the population, yielding: π = 2(-µ+ √ ∆ 0 -∆ ∞ ).</s><s>We then normalize π through dividing by its value in the unstructured chaotic regimes (2∆ 0 ).</s><s>When positive, π returns an overlap; when negative, it measures a distance between the two orbits.</s><s>For every set of the architecture parameters, the theoretical expected value of the overlap can be computed within the DMF framework.</s><s>We show that, in finite-size networks, the transition probability between the two chaotic attractors monotonically increases with the attractors overlap in the phase space.</s><s>In the figure, the points returned by simulations are fitted with an error function of which we evaluate numerically the amplitude, the offsets and the gain: f (x) = p 0 + p 1 erf(p 2 (xp 3 )).</s><s>Choice of the parameters: ρ = 0, g = 3.0, Σ m = 0.</s><s>In the main text, we performed our analysis of low-rank networks by adopting a completely symmetric network model, whose input-free solutions are invariant under the sign transformation x i (t) → -x i (t).</s><s>Such symmetry is broken when a more biologically-plausible, positively-defined activation function φ(x) is adopted.</s><s>Here, we investigate the effect of changing the transfer function to: φ(x) = 1 + tanh(c(xγ)).</s><s>Note that adding a shift γ is equivalent to including an external and constant negative input.</s><s>The parameter c, instead, rescales the slope of φ(x) at the inflection point.</s><s>For simplicity, we fix γ = 1 and c = 1.5.</s><s>We furthermore restrict the analysis to the case of unit-rank structures whose right-and left-connectivity vectors solely overlap on the unitary direction (ρ = 0, see Methods).</s><s>The Dynamical Mean Field (DMF) sets of equations were derived for an arbitrary activation function, so they can directly be adapted to the present scenario.</s><s>A. We start by graphically analysing the stationary solutions (Eq.</s><s>83), and we plot the two nullclines of the system for different values of the architecture parameters.</s><s>The top panel displays the µ nullclines for different M m M n values.</s><s>At M m M n = 1, the unstable branch coincides with µ = 1, and the stable ones are symmetric.</s><s>Around M m M n = 1, the perfect pitchfork is broken in one or the other direction, generating a first stable continuous branch and a second one, where one unstable and one stable solution merge at low or high firing rate.</s><s>For extremely low (resp.</s><s>high) M m M n values, finally, there's just one nullcline at low (resp.</s><s>high) µ values.</s><s>The ∆ 0 nullcline (bottom panel) displays a more complex behaviour compared to the symmetric φ(x) = tanh(x) case.</s><s>When g is sufficiently large, indeed, it can become a non-monotonic function of the mean input µ, transforming into a S -shaped nullcline.</s><s>As it is shown in the following, this more complex shape is able to induce bistable activity even when the µ nullcline is reduced to a single continuous branch.</s><s>This situation is reminiscent of the fluctuations driven bistable regime in <ref type="bibr">[Renart et al, 2007]</ref>.</s><s>B. Stationary stable solutions plotted as color maps on the parameter space defined by the random and the structure strengths.</s><s>The mean-field system admits two classes of stable solutions.</s><s>The first one, illustrated in the top row, takes large mean and variance values.</s><s>It suddenly disappears on the leftmost grey boundary of the plot, in a parameter region which co-exists with the second solution.</s><s>The second solution, plotted in the bottom row, takes typically small values of µ and ∆ 0 , and disappears on the right-most boundary with a first-order transition as well.</s><s>C-D-E.</s><s>In order to dissect more systematically the nature of those solutions, we fix the value of the structure strength (dashed lines in in B), and we gradually increase the random strength g.</s><s>In C, we fix the structure strength to high values:  , where dynamics include a chaotic component.</s><s>F. When oscillations are strongly non-linear, their spectrum includes a large variety of frequencies that can be used to reproduce highly non-linear periodic patterns.</s><s>We designed three random readout vectors and we linearly decoded activity from the dynamical regime in D to generate periodic non-linear outputs, which are displayed in grey.</s></p><formula xml:id="formula_222">M m M n =</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc><div><p><s>Figure1: Spontaneous activity in random networks with unit-rank connectivity structure.</s><s>A. The recurrent network model, whose connectivity matrix consists of the sum of a random (gray) and of a structured unitrank (colored) component.</s><s>B. Left: dynamical regimes of the network activity as function of the structure connectivity strength m T n/N and the random strength g.</s><s>Gray areas: bistable activity; red: chaotic activity.</s><s>Side panels: samples of dynamics from finite networks simulations (parameters indicated by colored dots in the phase diagram).</s><s>C-D.</s><s>Activity statistics as the random strength g is increased and the structure strength is fixed to 2.2 (dashed line in B).</s><s>C: Activity along the vector m, as quantified by κ = n i [φ i ] .</s><s>Blue (resp.</s><s>red) lines: theoretical prediction for stationary (resp.</s><s>chaotic) dynamics.</s><s>D: Activity variance due to random connectivity.</s><s>Blue and pink lines: static heterogeneity, red: temporal variance that quantifies chaotic activity.</s><s>Dots: simulations of finite-size networks.</s><s>See Methods for details.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc><div><p><s>Figure 2: External inputs generate two-dimensional activity in random networks with unit-rank structure.</s><s>A. The pattern of external inputs can be represented by an N -dimensional vector I = {I i }, where I i is the input to unit i. B. Transient dynamics in response to a step input along I in a sample network of N = 3500 units.</s><s>Left: activity traces for five units.</s><s>Right: projections of the population trajectory onto the plane defined by the right-connectivity vector m and the input vector I.</s><s>Light trace: theoretical prediction.</s><s>Dark traces: simulations.</s><s>C. Principal components (PC) analysis of the average activity trajectory.</s><s>Bottom: fraction of standard deviation explained by successive PCs.</s><s>Top: correlation between PCs and the vectors m and I.</s><s>The direction of the projections onto the m -I plane of the two top PCs e 1 and e 2 are represented in B. See also Fig. S3.</s><s>D. The activity κ along m is determined by the geometrical arrangement of the vector I and the connectivity vectors m and n.</s><s>Three different cases are illustrated: (left) I, m and n mutually orthogonal; (center) m and n mutually orthogonal, but I has a non-zero overlap with n; (right) m and n have non-zero overlap, leading to bistable activity in absence of inputs.</s><s>Increasing the external input along n suppresses one of the two stable states.</s><s>Continuous lines: theoretical predictions.</s><s>Dots: simulations.</s><s>See Methods for details.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc><div><p><s>Figure 3: Implementing a simple Go-Nogo discrimination task with a unit-rank connectivity structure.</s><s>A. A linear readout is added to the network, with randomly chosen weights w i .</s><s>The stimuli are represented by random input patterns I A and I B .</s><s>The task consists in producing an output in response to stimulus A, but not B. The simplest unit-rank structure that implements the task is given by m = w and n = I A .</s><s>B. Response of a sample network to the Go (blue) and Nogo (green) inputs.</s><s>Activity traces for five units.</s><s>C. Projections of the population trajectories onto the planes predicted to contain the dominant part of the dynamics.</s><s>Gray: predicted trajectory.</s><s>Colored traces: simulations.</s><s>D. Linear regression coefficients for the Go and the Nogo stimuli.</s><s>Every dot corresponds to a network unit.</s><s>E. Readout dynamics for the Go (blue) and the Nogo (green) stimulus.</s><s>F. Average connectivity strength as a function of the product between the coefficients of the first PC.</s><s>Every dot corresponds to a pair of units.</s><s>G. Generalization properties of the network.</s><s>We select two Go stimuli I A 1 and I A 2 , and we set n = I A 1 + I A 2 .</s><s>We build the input pattern as a normalized mixture of the two preferred patterns, and we gradually increase the component along I A 1 .</s><s>Continuous lines: theoretical predictions.</s><s>Dots: simulations.</s><s>See Methods for details.</s></p></div></figDesc><graphic coords="8,57.20,277.64,118.80,111.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc><div><p><s>Figure 4: Implementing a noisy detection task with a unit-rank connectivity structure.</s><s>A. The network is given a noisy input c(t) along a fixed, random pattern of inputs I.</s><s>The task consists in producing an output if the average input c is larger than a threshold θ.</s><s>B. Dynamics in a sample network.</s><s>Top: noisy input and threshold.</s><s>Bottom: activity traces for four units and two different noise realizations in the stimulus, leading to a Go (dark blue) and a Nogo (light blue) output.</s><s>C. Readout dynamics for the two stimuli.</s><s>D. Projections of the population trajectory onto the plane defined by the right-connectivity vector m and the input vector I. Left: single-trial trajectories corresponding to B. Right: trial-averaged trajectories, for Go (top) and Nogo (bottom) outputs, and different values of the mean input c.</s><s>Stars indicate correct responses.</s><s>E. Left: linear regression coefficients for the input amplitude and the decision outcome.</s><s>Every dot corresponds to a network unit.</s><s>Right: correlation coefficients between the vectors m and I and the input and choice regression axes (see Methods).</s><s>Projection directions of the two input and choice regression axes onto the m -I plane are shown in D. F. Detection threshold (dashed), and time scale of the effective exponential filter (full line) for increasing values of the structure strength.</s><s>G. Psychometric curve.</s><s>The shaded area indicates the bistable region.</s><s>H. Average connectivity strength as a function of the product of the linear regression coefficients for the choice variable.</s><s>Every dot corresponds to a pair of network units.</s><s>See Methods for details.</s></p></div></figDesc><graphic coords="10,200.42,322.96,104.40,97.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc><div><p><s>Figure 5: Implementing a context-dependent Go-Nogo discrimination task with a rank-two connectivity structure.</s><s>A. As in Fig. 3, two stimuli A and B are presented to the network.</s><s>The task consists in producing an output in response to the Go stimulus, which is determined by the contextual cue (A in Context A, B in Context B), modeled as inputs along random directions I ctxA and I ctxB .</s><s>B. Inputs along the overlap direction between the left-and the right-connectivity vectors modulate the response threshold of the network (see also Fig. S5).</s><s>C. Dynamics in a sample network in response to the stimulus A. Top: stimulus and contextual input.</s><s>Bottom: activity for five units in contexts A (crimson) and B (pink).</s><s>D. Readout dynamics in the two contexts.</s><s>E. Projections of the average population trajectories onto the planes spanned by vectors w, I A and I B .</s><s>F. Network performance in the two contexts.</s><s>G. Average connectivity strength between pairs of units as a function of the product between the regression coefficients for context.</s><s>Every dot corresponds to a pair of network units.</s><s>See Methods for details.</s></p></div></figDesc><graphic coords="12,379.68,303.42,146.16,55.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc><div><p><s>Figure6: Implementing a context-dependent evidence accumulation task using rank-two connectivity structure.</s><s>A. The stimuli consist of a superposition of two features c A and c B which fluctuate in time around mean values cA and cB .</s><s>In every trial, a pair of contextual inputs determines the relevant input feature.</s><s>The task consists in producing an output if the average strength of the relevant feature is larger than a threshold.</s><s>B. Dynamics in a sample network.</s><s>Top: stimulus and contextual inputs.</s><s>Bottom: activity of four units in contexts A (crimson) and B (pink).</s><s>C. Readout dynamics in the two contexts.</s><s>D. Average population trajectories projected onto the planes spanned by vectors w, I A and I B .</s><s>Blue (resp.</s><s>green) trajectories have been sorted according to the value of the strength of stimulus A (resp.</s><s>B), and averaged across stimulus B (resp.</s><s>A).</s><s>E. Network performance.</s><s>Top row: probability of response as function of input strengths cA and cB (simulated data).</s><s>Bottom: probability of response averaged over cB .</s><s>Continuous line: theoretical prediction; dots: simulations.</s><s>F. Projection of the population activity onto the plane defined by the orthogonal components of the vectors m (1) and m (2) , and comparison with the underlying circular attractor (see Methods).</s><s>Trajectories are sorted by the strength of the relevant stimulus, and averaged across the non-relevant one.</s><s>The direction of the projections of the regression axes for choice and context are indicated in gray.</s><s>See Methods for details.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc><div><p><s>Within a geometrical interpretation, M m and M n are the projections of N -dimensional vectors m and n onto the unitary vector u = (1, 1, ...1)/N , Σ m √ ρ and Σ n √ ρ are the projections onto a direction orthogonal to u and common to m and n, and Σ m √ 1 -ρ and Σ n √ 1 -ρ scale the parts of m and n that are mutually orthogonal.</s><s>The expression for κ becomes:</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure S1 (</head><label>S1</label><figDesc><div><p><s>Figure S1 (previous page): Dynamical Mean-Field description of rank-one networks whose right-and leftconnectivity vectors overlap solely on the unitary direction (ρ = 0, see Methods).</s><s>Related to Figure 1.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>ChaoticDFigure</head><label></label><figDesc><div><p><s>Figure S2 (previous page): Dynamical Mean-Field description of rank-one networks whose right-and leftconnectivity vectors overlap onto an arbitrary direction y (M m = M n = 0, ρ = 0, see Methods).</s><s>Related to Figure 1.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>(</head><label></label><figDesc><div><p><s>B-C-D) Bifurcation diagram of the activity statistics as the random strength g is increased.</s><s>Details as in Fig. 1 C-D.</s><s>B. Stability eigenspectrum of stationary solutions, mean-field prediction for the radius of the compact part and the outlier position.</s><s>C. Overlap κ = n i [φ i ] .</s><s>D.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure</head><label></label><figDesc><div><p><s>FigureS4(previous page): Dynamical Mean-Field description of input-driven dynamics for rank-one networks whose right-and left-connectivity vectors overlap solely on the unitary direction (ρ = 0, see Methods).</s><s>Related to Figure2.(A-B-C)</s><s>Dynamical regimes of the network activity as function of the structure connectivity strength m T n/N , the random strength g and the input strength.</s><s>Grey shaded areas indicate the parameter regions where the network activity is bistable.</s><s>Red shaded areas indicate the phase space regions where network dynamics are chaotic.</s><s>When two stable solutions exist, the yellow and the red letter indicate whether each of them is stationary (S) or chaotic (C).</s><s>Note that stationary and chaotic dynamics can coexist (SC region).</s><s>In A, as in Fig.2D center, the two connectivity vectors m and n are orthogonal.</s><s>We varied the external input strength by increasing the amplitude of the component along n (quantified by Σ nI , see Methods) and of the orthogonal one (quantified by Σ ⊥ ).</s><s>Note that inputs along both directions contribute to suppressing the amplitude of chaotic fluctuations.</s><s>In B, as in Fig.2D right, the two connectivity vectors m and n are not orthogonal, but they share an overlap component along the unitary direction.</s><s>We varied the structure strength (quantified by M m M n ) and the strength of the input along the direction of n that is perpendicular to the structure overlap, n ⊥ (again quantified by Σ nI ).</s><s>Similarly to Fig.1, strong structure overlaps can lead to the appearance of two bistable solutions.</s><s>In presence of non trivial external inputs, however, such solutions are not symmetric, and can loose stability on different parameter boundaries.</s><s>In particular, we observe that external inputs tend to suppress bistable regimes, by favouring one solution over the other.</s><s>In C, finally, the network configuration is similar to B, but we consider external inputs which include a second component along the direction of n that is shared with m, n (quantified by M I ).</s><s>We observe that both input directions play similar roles in reducing the extent of the bistable regime.</s><s>Choice of parameters: g = 2.2, Σ m = Σ n = 1.0,</s><s>Σ mI = 0.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure</head><label></label><figDesc><div><p><s>Figure S5 (previous page): Dynamical Mean-Field description of low-rank networks designed for solving computational tasks.</s><s>Related to Figures 3, 5 and 6.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure S6 (</head><label>S6</label><figDesc><div><p><s>Figure S6 (previous page): Dynamics of unit-rank networks of finite-size are characterized by two distinct time-scales.</s><s>Related to Figure 1.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure</head><label></label><figDesc><div><p><s>Figure S7 (previous page): Dynamics of unit-rank networks with positively-defined activation functions.</s><s>Related to Figure 1.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>F</head><label></label><figDesc><div><p><s>FigureS8(previous page): Oscillatory activity from rank-two structures that include a cross overlap between left-and right-connectivity vectors.A. Top: phase diagram for the rank-two structure with negative cross-overlap (see Methods).</s><s>For different values of the internal and the cross overlaps, the trivial fixed point can lose stability and give rise to oscillatory or stationary structured activity.</s><s>The Hopf bifurcation is indicated in blue, the instability to stationary activity in grey.</s><s>The light-blue parameter region corresponds to sustained non-linear oscillations.</s><s>Bottom: frequency of oscillations along the Hopf bifurcation boundary, in units defined by the implicit time scale of the network dynamics.</s><s>B-C-D-E.</s><s>Samples of activity for different connectivity parameters.</s><s>From left to right: stability eigenspectrum of the trivial fixed point (theory and simulations), sample of activation trajectories (the population average is indicated in dashed black), and population dynamics obtained by projecting the population activation x on the right-connectivity vectors m (1) and m(2) .</s><s>The parameters that have been used for every sample are indicated in A. B: Oscillatory transients in the fixed point regime.</s><s>C: Stable oscillations above the Hopf instability.</s><s>The elongated shape of the closed trajectory on the m (1) -m (2) plane is inherited by the phase distribution across the population, and can be tuned by slightly modifying the parameters of the rank-two structure (see Methods).</s><s>D: Highly non-linear oscillations close to the boundary with bistable activity.</s><s>E: Oscillatory activity at high g values (g = 1.35),</s><s>where dynamics include a chaotic component.</s><s>F. When oscillations are strongly non-linear, their spectrum includes a large variety of frequencies that can be used to reproduce highly non-linear periodic patterns.</s><s>We designed three random readout vectors and we linearly decoded activity from the dynamical regime in D to generate periodic non-linear outputs, which are displayed in grey.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc><div><p><s>1.2.</s><s>The bifurcation pattern occurring in this case resembles what we observed in the original case with φ(x) = tanh(x).</s><s>At low values of g, two stable fixed points are built, respectively, on the high and on the low branches of the µ nullcline.</s><s>For that reason, we call this state LH (cfr with F).</s><s>When the random connectivity is too strong, the low firing rate fixed point annihilates, and only one high firing solution survives (H state).</s><s>In D, M m M n is exactly equal to unity.</s><s>At small g values, similarly to the previous case, network activity is bistable and admits one L and one H stationary state.</s><s>As g increases, the ∆ 0 intersect the high firing rate branch at smaller and smaller values of µ.</s><s>Finally, the H state is lost, and the second stable fixed point is realized on the intermediate branch at µ = 1.</s><s>This bistable state is thus formally a LI state.</s><s>Finally, at large g values, the two intersections on the low rate branch collapse together and disappear.</s><s>Bistability is lost and only one intermediate (I) state exists.</s><s>In E, we consider slightly smaller values of M m M n .</s><s>A classical LH state exists at small g values, the bistable state at large random strengths involves two stable solutions which originate both a low firing rates (LL state).</s><s>The two states strongly differ in the value of their variance.</s><s>When g is sufficiently large, one unique low firing rate, high variance state (L) survives.</s></p></div></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We are grateful to <rs type="person">Alexis Dubreuil</rs>, <rs type="person">Vincent Hakim</rs> and <rs type="person">Kishore Kuchibhotla</rs> for discussions and feedback on the manuscript.This work was funded by the <rs type="funder">Programme Emergences of City of Paris</rs>, and the program "<rs type="programName">Investissements d'Avenir</rs>" launched by the <rs type="funder">French Government</rs> and implemented by the <rs type="funder">ANR</rs>, with the references <rs type="grantNumber">ANR-10-LABX-0087 IEC</rs> and <rs type="grantNumber">ANR-11-IDEX-0001-02</rs> <rs type="funder">PSL* Research University</rs>.The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uXXnCDb">
					<orgName type="program" subtype="full">Investissements d&apos;Avenir</orgName>
				</org>
				<org type="funding" xml:id="_VsTkNSw">
					<idno type="grant-number">ANR-10-LABX-0087 IEC</idno>
				</org>
				<org type="funding" xml:id="_FT2wYn3">
					<idno type="grant-number">ANR-11-IDEX-0001-02</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p><s>F.M. and S.O.</s><s>designed the study and wrote the manuscript.</s><s>F.M. performed model analyses and simulations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Interests</head><p><s>The authors declare no competing interests.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detection of a continuous noisy stimulus</head><p><s>In Fig. <ref type="figure">4</ref>, we construct a network model which performs a Go-Nogo detection task on a one-dimensional continuous stimulus.</s></p><p><s>The stimulus consists of an input of time-varying amplitude c(t)I.</s><s>As in Fig. <ref type="figure">3</ref>, the input direction I is a centered Gaussian vector of variance Σ 2 I .</s><s>The strength value c(t) includes a stationary component c together with additive white noise of standard deviation σ.</s><s>Less importantly, we include in the input an orthogonal component of quenched noise of unitary variance.</s><s>The network output is defined at the level of an orthogonal readout as in Eq. 144, and the task consists in responding to the stimulus when the strength of the input c is larger than a given threshold.</s></p><p><s>We obtain highly non-linear readout responses by considering non-vanishing overlaps between the connectivity vectors m and n.</s><s>The simplest setup consists of taking:</s></p><p><s>where y is a standard gaussian vector which defines a direction common to m and n, but orthogonal both to w and I.</s></p><p><s>For this configuration, as in Eq. 94, the mean-field equation for the first-order statistics includes two terms, generated respectively by the input and the rank-one structure:</s></p><p><s>Before the stimulus presentation (c = 0, σ = 0), the structure overlap ρ m ρ n is strong enough to generate two bistable solutions (Fig. <ref type="figure">1</ref>).</s><s>We set the negative κ solution to represent the Nogo condition, and we initialize the network in this state.</s><s>To have a zero output in this condition, we add an offset to the readout.</s></p><p><s>When an input along the preferred direction is presented (c &gt; 0), two asymmetric solutions exist only when the strength of the input c is not too large (Fig. <ref type="figure">2</ref> D right).</s><s>When the correlation c is large, instead, only the positive branch of the solution is retrieved (Fig. <ref type="figure">2</ref> D right).</s><s>As a consequence, the average value of κ (and thus the readout signal) jumps to positive values, which define the Go output condition.</s></p><p><s>More generally, in order to compute the network performance (Fig. <ref type="figure">4</ref> G), the network is said to respond to the stimulus if the readout z at the end of the stimulus presentation takes values larger than one half of the readout value expected for the upper state.</s></p><p><s>The threshold value for c at which the bistability disappears is mostly determined by the strength of the structure overlap, but depends also the input and readout parameters Σ I and Σ w .</s><s>For practical purposes, in order to obtain the model implementation illustrated in Fig. <ref type="figure">4</ref>, we first fix the values of Σ I = 1.2, Σ w = 1.2 and ρ n = 2.</s><s>We then tune the value of ρ m in order to obtain a threshold value for c close to 0.5.</s><s>This leads to ρ m = 2.</s></p><p><s>In Fig. <ref type="figure">4</ref> F we vary ρ m and we show that the value of the threshold decreases to zero as the structure strength ρ m ρ n decreases from its original value (ρ m ρ n = 4).</s><s>Rank-one structures characterized by different strengths thus correspond to different thresholds, but also induce different dynamical time-scales in the network.</s><s>As a rough estimate of this time-scale, we compute the inverse of the outlier eigenvalue from the stability matrix of the fixed point corresponding to the Go resting state (c = 0).</s><s>The value of the outlier can be computed from the linearized mean-field equations (Eq.</s><s>71).</s><s>We show that arbitrarily large time-scales are only obtained by decreasing the value of the structure strength to the critical point where the two bistable branches of the solution emerge from the trivial fixed point.</s><s>In this configuration, the threshold detected by the network is arbitrarily small.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contextual modulation of threshold value</head><p><s>Here we briefly illustrate how the threshold of detection can be controlled by an additional modulatory input (Fig. <ref type="figure">5 B</ref>).</s><s>Modulatory inputs are used in Figs. 5 and 6 to implement more complex tasks which require contextdependent responses to stimuli.</s><s>Any input direction which overlaps with the left-connectivity vector n and is orthogonal to the stimulus axis I can serve as modulatory input.</s><s>For simplicity, we consider modulatory inputs which are aligned with the overlap direction y (see Eq. 151).</s><s>The total external input to the network contains</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantification and Statistical Analysis</head><p><s>In this section, we briefly describe the analysis techniques that have been applied to the datasets generated from direct simulations of activity in finite-size networks <ref type="bibr">(Figs. 2,</ref><ref type="bibr">3,</ref><ref type="bibr">4,</ref><ref type="bibr">5 and 6)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dimensionality reduction</head><p><s>In order to extract from the high-dimensional population activity the low-dimensional subspace which contains most of the relevant dynamics, we performed dimensionality reduction via a standard Principal Component (PC) analysis.</s></p><p><s>To begin with, we constructed the activation matrix X.</s><s>In X, every column corresponds to the time trace of the activation variable x i (t) for unit i, averaged across trials.</s><s>We indicate as trials different network simulations, where different noisy inputs, or different quenched noise in the random connectivity matrix have been generated (details are specified in the figure captions).</s><s>The activation matrix X is normalized through Z-scoring: to every column, we subtract its average over time, and we divide by its standard deviation.</s><s>Note that Z-scoring distorts the shape of the population trajectory in the phase space.</s><s>For this reason, in order to facilitate the comparison with the trajectory predicted by the mean-field theory, in Fig. <ref type="figure">S3</ref> we more simply consider the mean-subtracted</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Properties of networks with partially structured and partially random connectivity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ahmadian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fumarola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page">12820</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transition to chaos in random networks with cell-type-specific connectivity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aljadeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sharpee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page">88101</biblScope>
			<date type="published" when="2015">2015b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brunel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="252" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Storing infinite numbers of patterns in a spin-glass model of neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1530" to="1533" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recurrent neural networks as versatile tools of neuroscience research</title>
		<author>
			<persName><forename type="first">O</forename><surname>Barak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Theory of orientation tuning in visual cortex</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ben-Yishai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bar-Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3844" to="3848" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predictive coding of dynamical variables in balanced spiking networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boerlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Machens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deneve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brunel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="183" to="208" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stimulus onset quenches neural variability: a widespread cortical phenomenon</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Churchland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="369" to="378" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Churchland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4235" to="4257" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dimensionality reduction for large-scale neural recordings</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1500" to="1509" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Balanced neural architecture and the idling brain</title>
		<author>
			<persName><forename type="first">B</forename><surname>Doiron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Litwin-Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Comput. Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">56</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Neural Engineering -Computation, Representation, and Dynamics in Neurobiological Systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eliasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Why neurons mix: high dimensionality for higher cognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="66" to="74" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On simplicity and complexity in the brave new world of large-scale neuroscience</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="148" to="155" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Circular law</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Girko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Probab. Appl</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="694" to="706" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Asynchronous rate chaos in spiking neuronal circuits</title>
		<author>
			<persName><forename type="first">O</forename><surname>Harish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hansel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cortical connectivity and sensory coding</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Mrsic-Flogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">503</biblScope>
			<biblScope unit="issue">7474</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Haas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">304</biblScope>
			<biblScope unit="issue">5667</biblScope>
			<biblScope unit="page" from="78" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transition to chaos in random neuronal networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kadmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. X</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">41030</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kanerva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="159" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Functional specificity of local synaptic connections in neocortical networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pichler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Buchanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Sjostrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Mrsic-Flogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">473</biblScope>
			<biblScope unit="issue">7345</biblScope>
			<biblScope unit="page" from="87" to="91" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Slow dynamics and high variability in balanced cortical networks with clustered connections</title>
		<author>
			<persName><forename type="first">A</forename><surname>Litwin-Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Doiron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1498" to="1505" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Computational aspects of feedback in neural circuits</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Functional, but not anatomical, separation of &quot;what&quot; and &quot;when&quot; in prefrontal cortex</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Machens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Romo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Brody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="350" to="360" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Context-dependent computation by recurrent dynamics in prefrontal cortex</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">503</biblScope>
			<biblScope unit="issue">7474</biblScope>
			<biblScope unit="page" from="78" to="84" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Low Rank Approximation -Algorithms, Implementations, Applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Markovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning recurrent neural networks with hessian-free optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1033" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Intrinsically-generated fluctuating activity in excitatory-inhibitory networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mastrogiuseppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ostojic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computat. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neuronal correlates of a perceptual decision</title>
		<author>
			<persName><forename type="first">W</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Britten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Movshon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="page">341</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Two types of asynchronous activity in networks of excitatory and inhibitory spiking neurons</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ostojic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="600" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>III-1310-III-1318</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Eigenvalue spectra of random matrices for neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page">188104</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stimulus-dependent suppression of chaos in recurrent neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">11903</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Flexible sensorimotor computations through rapid reconfiguration of cortical dynamics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Remington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jazayeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1005" to="1019" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Internal representation of task rules by recurrent dynamics: The importance of the diversity of neural responses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Comput. Neurosci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The importance of mixed selectivity in complex cognitive tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<biblScope unit="issue">7451</biblScope>
			<biblScope unit="page" from="585" to="590" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Local dynamics in trained recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rivkind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Barak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">258101</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A balanced memory network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Roudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Abstract context representations in primate amygdala and prefrontal cortex</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ostojic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Salzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="869" to="881" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The variable discharge of cortical neurons: Implications for connectivity, computation, and information coding</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3870" to="3896" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Self-consistent signal-to-noise analysis of the statistical behavior of analog neural networks and enhancement of the storage capacity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shiino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fukai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="867" to="897" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Chaos in random neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Crisanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Sommers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="259" to="262" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Neural circuits as computational dynamical systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sussillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="156" to="163" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Generating coherent patterns of activity from chaotic neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="544" to="557" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Opening the black box: Low-dimensional dynamics in high-dimensional recurrent neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Barak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computat</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="649" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Outliers in the spectrum of iid matrices with bounded rank perturbations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probab. Theory Relat. Fields</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="231" to="263" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning universal computations with spikes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thalmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Uhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kappen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Memmesheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Chaos in highly diluted neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tirozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tsodyks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EPL</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">727</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Chaos in neuronal networks with balanced excitatory and inhibitory activity</title>
		<author>
			<persName><forename type="first">C</forename><surname>Van Vreeswijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="issue">5293</biblScope>
			<biblScope unit="page" from="1724" to="1726" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Flexible timing by temporal scaling of cortical responses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jazayeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="102" to="110" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Probabilistic decision making by slow reverberation in cortical circuits</title>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="955" to="968" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scaling properties of dimensionality reduction for neural populations and network models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Cowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Litwin-Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Doiron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
