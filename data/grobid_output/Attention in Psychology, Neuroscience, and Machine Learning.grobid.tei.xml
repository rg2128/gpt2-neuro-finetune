<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attention in Psychology, Neuroscience, and Machine Learning</title>
				<funder ref="#_xG5fAxQ #_Kd4E3Y2">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Frontiers Media SA</publisher>
				<availability status="unknown"><p>Copyright Frontiers Media SA</p>
				</availability>
				<date type="published" when="2020-04-16">16 April 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mariya</forename><surname>Toneva</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Grace</forename><forename type="middle">W</forename><surname>Lindsay</surname></persName>
							<email>gracewlindsay@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">H. Steven Scholte</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Sainsbury Wellcome Centre</orgName>
								<orgName type="laboratory">Gatsby Computational Neuroscience Unit</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Attention in Psychology, Neuroscience, and Machine Learning</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Frontiers in Computational Neuroscience</title>
						<title level="j" type="abbrev">Front. Comput. Neurosci.</title>
						<idno type="eISSN">1662-5188</idno>
						<imprint>
							<publisher>Frontiers Media SA</publisher>
							<biblScope unit="volume">14</biblScope>
							<date type="published" when="2020-04-16">16 April 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">FA6CC7DA29D94568DC8217C8F9932D1D</idno>
					<idno type="DOI">10.3389/fncom.2020.00029</idno>
					<note type="submission">Received: 02 December 2019 Accepted: 23 April 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-04-21T20:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>attention</term>
					<term>artificial neural networks</term>
					<term>machine learning</term>
					<term>vision</term>
					<term>memory</term>
					<term>awareness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>Attention is the important ability to flexibly control limited computational resources.</s><s>It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning.</s><s>It has also recently been applied in several domains in machine learning.</s><s>The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear.</s><s>This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature.</s><s>It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist.</s><s>Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p><s>Attention is a topic widely discussed publicly and widely studied scientifically.</s><s>It has many definitions within and across multiple fields including psychology, neuroscience, and, most recently, machine learning <ref type="bibr" target="#b35">(Chun et al., 2011;</ref><ref type="bibr" target="#b34">Cho et al., 2015)</ref>.</s><s>As William James wrote at the dawn of experimental psychology, "Everyone knows what attention is.</s><s>It is the taking possession by the mind, in clear, and vivid form, of one out of what seems several simultaneously possible objects or trains of thought."</s><s>Since James wrote this, many attempts have been made to more precisely define and quantify this process while also identifying the underlying mental and neural architectures that give rise to it.</s><s>The glut of different experimental approaches and conceptualizations to study what is spoken of as a single concept, however, has led to something of a backlash amongst researchers.</s><s>As was claimed in the title of a recent article arguing for a more evolution-informed approach to the concept, "No one knows what attention is" <ref type="bibr" target="#b64">(Hommel et al., 2019)</ref>.</s></p><p><s>Attention is certainly far from a clear or unified concept.</s><s>Yet despite its many, vague, and sometimes conflicting definitions, there is a core quality of attention that is demonstrably of high importance to information processing in the brain and, increasingly, artificial systems.</s><s>Attention is the flexible control of limited computational resources.</s><s>Why those resources are limited and how they can best be controlled will vary across use cases, but the ability to dynamically alter and route the flow of information has clear benefits for the adaptiveness of any system.</s></p><p><s>The realization that attention plays many roles in the brain makes its addition to artificial neural networks unsurprising.</s><s>Artificial neural networks are parallel processing systems comprised of individual units designed to mimic the basic input-output function of neurons.</s><s>These models are currently dominating the machine learning and artificial intelligence (AI) literature.</s><s>Initially constructed without attention, various mechanisms for dynamically re-configuring the representations or structures of these networks have now been added.</s></p><p><s>The following section, section 2, will cover broadly the different uses of the word attention in neuroscience and psychology, along with its connection to other common neuroscientific topics.</s><s>Throughout, the conceptualization of attention as a way to control limited resources will be highlighted.</s><s>Behavioral studies will be used to demonstrate the abilities and limits of attention while neural mechanisms point to the physical means through which these behavioral effects are manifested.</s><s>In section 3, the state of attention research in machine learning will be summarized and relationships between artificial and biological attention will be indicated where they exist.</s><s>And in section 4 additional ways in which findings from biological attention can influence its artificial counterpart will be presented.</s></p><p><s>The primary aim of this review is to give researchers in the field of AI or machine learning an understanding of how attention is conceptualized and studied in neuroscience and psychology in order to facilitate further inspiration where fruitful.</s><s>A secondary aim is to inform those who study biological attention how these processes are being operationalized in artificial systems as it may influence thinking about the functional implications of biological findings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ATTENTION IN NEUROSCIENCE AND PSYCHOLOGY</head><p><s>The scientific study of attention began in psychology, where careful behavioral experimentation can give rise to precise demonstrations of the tendencies and abilities of attention in different circumstances.</s><s>Cognitive science and cognitive psychology aim to turn these observations into models of how mental processes could create such behavioral patterns.</s><s>Many word models and computational models have been created that posit different underlying mechanisms <ref type="bibr" target="#b46">(Driver, 2001;</ref><ref type="bibr" target="#b17">Borji and Itti, 2012)</ref>.</s></p><p><s>The influence of single-cell neurophysiology in non-human primates along with non-invasive means of monitoring human brain activity such as EEG, fMRI, and MEG have made direct observation of the underlying neural processes possible.</s><s>From this, computational models of neural circuits have been built that can replicate certain features of the neural responses that relate to attention <ref type="bibr" target="#b136">(Shipp, 2004)</ref>.</s></p><p><s>In the following sub-sections, the behavioral and neural findings of several different broad classes of attention will be discussed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Attention as Arousal, Alertness, or Vigilance</head><p><s>In its most generic form, attention could be described as merely an overall level of alertness or ability to engage with surroundings.</s><s>In this way it interacts with arousal and the sleepwake spectrum.</s><s>Vigilance in psychology refers to the ability to sustain attention and is therefore related as well.</s><s>Note, while the use of these words clusters around the same meaning, they are sometimes used more specifically in different niche literature <ref type="bibr" target="#b110">(Oken et al., 2006)</ref>.</s></p><p><s>Studying subjects in different phases of the sleep-wake cycle, under sleep deprivation, or while on sedatives offers a view of how this form of attention can vary and what the behavioral consequences are.</s><s>By giving subjects repetitive tasks that require a level of sustained attention-such as keeping a ball within a certain region on a screen-researchers have observed extended periods of poor performance in drowsy patients that correlate with changes in EEG signals <ref type="bibr" target="#b94">(Makeig et al., 2000)</ref>.</s><s>Yet, there are ways in which tasks can be made more engaging that can lead to higher performance even in drowsy or sedated states.</s><s>This includes increasing the promise of reward for performing the task, adding novelty or irregularity, or introducing stress <ref type="bibr" target="#b110">(Oken et al., 2006)</ref>.</s><s>Therefore, general attention appears to have limited reserves that won't be deployed in the case of a mundane or insufficiently rewarding task but can be called upon for more promising or interesting work.</s></p><p><s>Interestingly, more arousal is not always beneficial.</s><s>The Yerkes-Dodson curve (Figure <ref type="figure" target="#fig_0">1B</ref>) is an inverted-U that represents performance as a function of alertness on sufficiently challenging tasks: at low levels of alertness performance is poor, at medium levels it is good, and at high levels it becomes poor again.</s><s>The original study used electric shocks in mice to vary the level of alertness, but the finding has been repeated with other measures <ref type="bibr" target="#b45">(Diamond, 2005)</ref>.</s><s>It may explain why psychostimulants such as Adderall or caffeine can work to increase focus in some people at some doses but become detrimental for others <ref type="bibr" target="#b158">(Wood et al., 2014)</ref>.</s></p><p><s>The neural circuits underlying the sleep-wake cycle are primarily in the brain stem <ref type="bibr" target="#b38">(Coenen, 1998)</ref>.</s><s>These circuits control the flow of information into the thalamus and then onto cortex.</s><s>Additionally, neuromodulatory systems play a large role in the control of generalized attention.</s><s>Norepinephrine, acetylcholine, and dopamine are believed to influence alertnesss, orienting to important information, and executive control of attention, respectively <ref type="bibr" target="#b117">(Posner, 2008)</ref>.</s><s>The anatomy of neuromodulators matches their function as well.</s><s>Neurons that release norepinephrine, for example, have their cell bodies in the brain stem but project very broadly across the brain, allowing them to control information processing broadly (Figure <ref type="figure" target="#fig_0">1A</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Sensory Attention</head><p><s>In addition to overall levels of arousal and alertness, attention can also be selectively deployed by an awake subject to specific sensory inputs.</s><s>Studying attention within the context of a specific sensory system allows for tight control over both stimuli and the locus of attention.</s><s>Generally, to look for this type of attention the task used needs to be quite challenging.</s><s>For example, in a change detection task, the to-be-detected difference between two stimuli may be very slight.</s><s>More generally, task difficulty can be achieved by presenting the stimulus for only a very short period of time or only very weakly.</s></p><p><s>A large portion of the study of attention in systems neuroscience and psychology centers on visual attention in particular <ref type="bibr" target="#b73">(Kanwisher and Wojciulik, 2000)</ref>.</s><s>This may reflect the general trend in these fields to emphasis the study of visual processing over other sensory systems <ref type="bibr" target="#b66">(Hutmacher, 2019)</ref>, along with the dominant role vision plays in the primate brain.</s><s><ref type="bibr" target="#b131">(Samuels and Szabadi, 2008)</ref>.</s><s>Colors here represent different divisions of the brain: forebrain (green), diencephalon (yellow), and brainstem (blue).</s><s>(B) The Yerkes-Dodson curve describes the nonlinear relationship between arousal and performance on challenging tasks.</s></p><p><s>Furthermore, visual stimuli are frequently used in studies meant to address more general, cognitive aspects of attention as well.</s></p><p><s>Visual attention can be broken down broadly into spatial and feature-based attention.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Visual Spatial Attention</head><p><s>Saccades are small and rapid eye movements made several times each second.</s><s>As the fovea offers the highest visual resolution on the retina, choosing where to place it is essentially a choice about where to deploy limited computational resources.</s><s>In this way, eye movements indicate the locus of attention.</s><s>As this shift of attention is outwardly visible it is known as overt visual attention.</s></p><p><s>By tracking eye movements as subjects are presented with different images, researchers have identified image patterns that automatically attract attention.</s><s>Such patterns are defined by oriented edges, spatial frequency, color contrast, intensity, or motion <ref type="bibr" target="#b68">(Itti and Koch, 2001)</ref>.</s><s>Image regions that attract attention are considered "salient" and are computed in a "bottomup" fashion.</s><s>That is, they don't require conscious or effortful processing to identify and are likely the result of built-in feature detectors in the visual system.</s><s>As such, saliency can be computed very quickly.</s><s>Furthermore, different subjects tend to agree on which regions are salient, especially those identified in the first few saccades <ref type="bibr" target="#b144">(Tatler et al., 2005)</ref>.</s></p><p><s>Salient regions can be studied in "free-viewing" situations, that is, when the subject is not given any specific instructions about how to view the image.</s><s>When a particular task is assigned, the interplay between bottom-up and "top-down" attention becomes clear.</s><s>For example, when instructed to saccade to a specific visual target out of an array, subjects may incorrectly saccade to a particularly salient distractor instead <ref type="bibr" target="#b150">(van Zoest and Donk, 2005)</ref>.</s><s>More generally, task instructions can have a significant effect on the pattern of saccades generated when subjects are viewing a complex natural image and given high-level tasks (e.g., asked to assess the age of a person or guess their socio-economic status).</s><s>Furthermore, the natural pattern of eye movements when subjects perform real world tasks, like sandwich making, can provide insights to underlying cognitive processes <ref type="bibr" target="#b61">(Hayhoe and Ballard, 2005)</ref>.</s></p><p><s>When subjects need to make multiple saccades in a row they tend not to return to locations they have recently attended and may be slow to respond if something relevant occurs there.</s><s>This phenomenon is known as inhibition of return <ref type="bibr" target="#b68">(Itti and Koch, 2001)</ref>.</s><s>Such behavior pushes the visual system to not just exploit image regions originally deemed most salient but to explore other areas as well.</s><s>It also means the saccade generating system needs to have a form of memory; this is believed to be implemented by short-term inhibition of the representation of recently-attended locations.</s></p><p><s>While eye movements are an effective means of controlling visual attention, they are not the only option.</s><s>"Covert" spatial attention is a way of emphasizing processing of different spatial locations without an overt shift in fovea location.</s><s>Generally, in the study of covert spatial attention, subjects must fixate on a central point throughout the task.</s><s>They are cued to covertly attend to a location in their peripheral vision where stimuli relevant for their visual task will likely appear.</s><s>For example, in an orientation discrimination task, after the spatial cue is provided an oriented grating will flash in the cued location and the subject will need to indicate its orientation.</s><s>On invalidly-cued trials (when the stimulus appears in an uncued location), subjects perform worse than on validly-cued (or uncued) trials <ref type="bibr">(Anton-Erxleben and Carrasco, 2013)</ref>.</s><s>This indicates that covert spatial attention is a limited resource that can be flexibly deployed and aids in the processing of visual information.</s></p><p><s>Covert spatial attention is selective in the sense that certain regions are selected for further processing at the expense of others.</s><s>This has been referred to as the "spotlight" of attention.</s><s>Importantly, for covert-as opposed to overt-attention the input to the visual system can be identical while the processing of that input is flexibly selective.</s></p><p><s>Covert spatial attention can be impacted by bottom-up saliency as well.</s><s>If an irrelevant but salient object is flashed at a location that then goes on to have a task relevant stimulus, the exogenous spatial attention drawn by the irrelevant stimulus can get applied to the task relevant stimulus, possibly providing a performance benefit.</s><s>If it is flashed at an irrelevant location, however, it will not help, and can harm performance <ref type="bibr" target="#b13">(Berger et al., 2005)</ref>.</s><s>Bottom-up/exogenous attention has a quick time course, impacting covert attention for 80-130 ms after the distractor appears <ref type="bibr">(Anton-Erxleben and Carrasco, 2013)</ref>.</s></p><p><s>In some theories of attention, covert spatial attention exists to help guide overt attention.</s><s>Particularly, the pre-motor theory of attention posits that the same neural circuits plan saccades and control covert spatial attention <ref type="bibr" target="#b124">(Rizzolatti et al., 1987)</ref>.</s><s>The frontal eye field (FEF) is known to be involved in the control of eye movements.</s><s>Stimulating the neurons in FEF at levels too low to evoke eye movements has been shown to create effects similar to covert attention <ref type="bibr" target="#b104">(Moore et al., 2003)</ref>.</s><s>In this way, covert attention may be a means of deciding where to overtly look.</s><s>The ability to covertly attend may additionally be helpful in social species, as eye movements convey information about knowledge and intent that may best be kept secret <ref type="bibr" target="#b78">(Klein et al., 2009)</ref>.</s></p><p><s>To study the neural correlates of covert spatial attention, researchers identify which aspects of neural activity differ based only on differences in the attentional cue (and not on differences in bottom-up features of the stimuli).</s><s>On trials where attention is cued toward the receptive field of a recorded neuron, many changes in the neural activity have been observed <ref type="bibr" target="#b108">(Noudoost et al., 2010;</ref><ref type="bibr" target="#b99">Maunsell, 2015)</ref>.</s><s>A commonly reported finding is an increase in firing rates, typically of 20-30% <ref type="bibr" target="#b102">(Mitchell et al., 2007)</ref>.</s><s>However, the exact magnitude of the change depends on the cortical area studied, with later areas showing stronger changes <ref type="bibr" target="#b91">(Luck et al., 1997;</ref><ref type="bibr" target="#b108">Noudoost et al., 2010)</ref>.</s><s>Attention is also known to impact the variability of neural firing.</s><s>In particular, it decreases trial-to-trial variability as measured via the Fano Factor and decreases noise correlations between pairs of neurons.</s><s>Attention has even been found to impact the electrophysiological properties of neurons in a way that reduces their likelihood of firing in bursts and also decreases the height of individual action potentials <ref type="bibr" target="#b2">(Anderson et al., 2013)</ref>.</s></p><p><s>In general, the changes associated with attention are believed to increase the signal-to-noise ratio of the neurons that represent the attended stimulus, however they can also impact communication between brain areas.</s><s>To this end, attention's effect on neural synchrony is important.</s><s>Within a visual area, attention has been shown to increase spiking coherence in the gamma band-that is at frequencies between 30 and 70 Hz <ref type="bibr" target="#b50">(Fries et al., 2008)</ref>.</s><s>When a group of neurons fires synchronously, their ability to influence shared downstream areas is enhanced.</s><s>Furthermore, attention may also be working to directly coordinate communication across areas.</s><s>Synchronous activity between two visual areas can be a sign of increased communication and attention has been shown to increase synchrony between the neurons that represent the attended stimulus in areas V1 and V4, for example <ref type="bibr" target="#b19">(Bosman et al., 2012)</ref>.</s><s>Control of this cross-area synchronization appears to be carried out by the pulvinar <ref type="bibr" target="#b128">(Saalmann et al., 2012)</ref>.</s></p><p><s>In addition to investigating how attention impacts neurons in the visual pathways, studies have also searched for the source of top-down attention <ref type="bibr" target="#b108">(Noudoost et al., 2010;</ref><ref type="bibr" target="#b100">Miller and Buschman, 2014)</ref>.</s><s>The processing of bottom-up attention appears to culminate with a saliency map produced in the lateral intraparietal area (LIP).</s><s>The cells here respond when salient stimuli are in their receptive field, including task-irrelevant but salient distractors.</s><s>Prefrontal areas such as FEF, on the other hand, appear to house the signals needed for top-down control of spatial attention and are less responsive to distractors.</s></p><p><s>While much of the work on the neural correlates of sensory attention focuses on the cortex, subcortical areas appear to play a strong role in the control and performance benefits of attention as well.</s><s>In particular, the superior colliculus assists in both covert and overt spatial attention and inactivation of this region can impair attention <ref type="bibr" target="#b79">(Krauzlis et al., 2013)</ref>.</s><s>And, as mentioned above, the pulvinar plays a role in attention, particularly with respect to gating effects on cortex <ref type="bibr" target="#b167">(Zhou et al., 2016)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Visual Feature Attention</head><p><s>Feature attention is another form of covert selective attention.</s><s>In the study of feature attention, instead of being cued to attend to a particular location, subjects are cued on each trial to attend to a particular visual feature such as a specific color, a particular shape, or a certain orientation.</s><s>The goal of the task may be to detect if the cued feature is present on the screen or readout another one of its qualities (e.g., to answer "what color is the square?"</s><s>should result in attention first deployed to squares).</s><s>Valid cueing about the attended feature enhances performance.</s><s>For example, when attention was directed toward a particular orientation, subjects were better able to detect faint gratings of that orientation than of any other orientation <ref type="bibr" target="#b127">(Rossi and Paradiso, 1995)</ref>.</s><s>While the overall task (e.g., detection of an oriented grating) remains the same, the specific instructions (detection of 90 • grating vs. 60 • vs. 30 • ) will be cued on each individual trial, or possibly blockwise.</s><s>Successful trialwise cueing indicates that this form of attention can be flexibly deployed on fast timescales.</s><s>Then a search array appears with many non-targets.</s><s>Top-down feature attention to cells that represent the color blue and the shape X will increase their firing throughout the visual field but firing will be strongest where blue or Xs actually occur.</s><s>These neural response will play a role in generating a map of covert spatial attention which can be used to explore visual space before saccading.</s><s>After the shift in overt attention with the first saccade, the covert attention map is remade.</s><s>Finally, the target is located and successfully saccaded to.</s><s>If the visual array contained a pop-out stimulus (for example a green O) it may have captured covert spatial attention in a bottom-up way and led to an additional incorrect saccade.</s></p><p><s>Visual search tasks are also believed to activate feature-based attention (Figure <ref type="figure" target="#fig_1">2</ref>).</s><s>In these tasks, an array of stimuli appears on a screen and subjects need to indicate-frequently with an eye movement-the location of the cued stimulus.</s><s>As subjects are usually allowed to make saccades throughout the task as they search for the cued stimulus, this task combines covert featurebased attention with overt attention.</s><s>In fact, signals of topdown feature-based attention have been found in FEF, the area involved in saccade choice <ref type="bibr" target="#b166">(Zhou and Desimone, 2011)</ref>.</s><s>Because certain features can create a pop-out effect-for example, a single red shape amongst several black ones will immediately draw attention-visual search tasks also engage bottom-up attention which, depending on the task, may need to be suppressed <ref type="bibr" target="#b157">(Wolfe and Horowitz, 2004)</ref>.</s></p><p><s>Neural effects of feature-based attention in the visual system are generally similar to those of spatial attention.</s><s>Neurons that represent the attended feature, for example, have increased firing rates, and those that represent very different features have suppressed rates <ref type="bibr" target="#b147">(Treue and Trujillo, 1999)</ref>.</s><s>As opposed to spatial attention, however, feature-based attention is spatiallyglobal.</s><s>This means that when deploying attention to a particular feature the activity of the neurons that represent that feature anywhere in visual space are modulated <ref type="bibr" target="#b129">(Saenz et al., 2002)</ref>.</s><s>Another difference between spatial and feature attention is the question of how sources of top-down attention target the correct neurons in the visual system.</s><s>The retinotopic map, wherein nearby cells represent nearby spatial locations, makes spatial targeting straightforward, but cells are not as neatly organized according to preferred visual features.</s></p><p><s>The effects of spatial and feature attention appear to be additive <ref type="bibr" target="#b60">(Hayden and Gallant, 2009)</ref>.</s><s>Furthermore, both feature and spatial attention are believed to create their effects by acting on the local neural circuits that implement divisive normalization in visual cortex <ref type="bibr" target="#b123">(Reynolds and Heeger, 2009)</ref>.</s><s>Modeling work has shown that many of the neural effects of selective attention can be captured by assuming that top-down connections provide targeted synaptic inputs to cells in these circuits <ref type="bibr" target="#b87">(Lindsay et al., 2019)</ref>.</s><s>However, models that rely on effects of the neuromodulator acetylcholine can also replicate neural correlates of attention <ref type="bibr" target="#b130">(Sajedin et al., 2019)</ref>.</s></p><p><s>Potential sources of top-down feature-based attention have been found in prefrontal cortex where sustained activity encodes the attended feature <ref type="bibr" target="#b15">(Bichot et al., 2015;</ref><ref type="bibr" target="#b112">Paneri and Gregoriou, 2017)</ref>.</s><s>Inactivating the ventral prearcuate area impairs performance on search tasks.</s><s>From prefrontal areas, attention signals are believed to travel in a reverse hierarchical way wherein higher visual areas send inputs to those below them <ref type="bibr" target="#b0">(Ahissar and Hochstein, 2000)</ref>.</s></p><p><s>A closely related topic to feature attention is object attention.</s><s>Here, attention is not deployed to an abstract feature in advance of a visual stimulus, but rather it is applied to a particular object in the visual scene <ref type="bibr" target="#b31">(Chen, 2012)</ref>.</s><s>The initial feedforward pass of activity through the visual hierarchy is able to preattentively segregate objects from their backgrounds in parallel across the visual field, provided these objects have stark and salient differences from the background.</s><s>In more crowded or complex visual scenes, recurrent and serial processing is needed in order to identify different objects <ref type="bibr" target="#b80">(Lamme and Roelfsema, 2000)</ref>.</s><s>Serial processing involves moving limited attentional resources from one location in the image to another; it can take the form of shifts in either covert or overt spatial attention <ref type="bibr" target="#b24">(Buschman and Miller, 2009)</ref>.</s><s>Recurrent connections in the visual system-that is, both horizontal connections from nearby neurons in the same visual area and feedback connections from those in higher visual areas-aid in figure-ground segregation and object identification.</s><s>The question of how the brain performs perceptual grouping of low-level features into a coherent object identity has been studied for nearly a century.</s><s>It is believed that attention may be required for grouping, particularly for novel or complex objects <ref type="bibr" target="#b125">(Roelfsema and Houtkamp, 2011)</ref>.</s><s>This may be especially important in visual search tasks that require locating an object that is defined by a conjunction of several features.</s></p><p><s>Neurally, the effects of object-based attention can spread slowly through space as parts of an object are mentally traced <ref type="bibr" target="#b126">(Roelfsema et al., 1998)</ref>.</s><s>Switching attention to a location outside an object appears to incur a greater cost than switching to the same distance away but within the object <ref type="bibr" target="#b22">(Brown and Denney, 2007)</ref>.</s><s>In addition, once attention is applied to a visual object, it is believed to activate feature-based attention for the different features of that object across the visual field <ref type="bibr" target="#b109">(O'Craven et al., 1999)</ref>.</s></p><p><s>Another form of attention sometimes referred to as feature attention involves attending to an entire feature dimension.</s><s>An example of this is the Stroop test, wherein the names of colors are written in different colored ink and subjects either need to read the word itself or say the color of the ink.</s><s>Here attention cannot be deployed to a specific feature in advance, only to the dimensions word or color.</s><s>Neurally, the switch between dimensions appears to impact sensory coding in the visual stream and is controlled by frontal areas <ref type="bibr" target="#b89">(Liu et al., 2003)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Computational Models of Visual Attention</head><p><s>Visual attention, being one of the most heavily-studied topics in the neuroscience of attention, has inspired many computational models of how attention works.</s><s>In general, these models synthesize various neurophysiological findings in order to help explain how the behavioral impacts of attention arise <ref type="bibr" target="#b63">(Heinke and Humphreys, 2005)</ref>.</s></p><p><s>Several computational models meant to calculate saliency have been devised <ref type="bibr" target="#b68">(Itti and Koch, 2001)</ref>.</s><s>These models use lowlevel visual feature detectors-usually designed to match those in the visual system-to create an image-specific saliency map that can predict the saccade patterns of humans in response to the same image.</s><s>Another approach to calculating saliency based on information theoretic first principles has also been explored and was able to account for certain visual search behaviors <ref type="bibr" target="#b23">(Bruce and Tsotsos, 2009)</ref>.</s></p><p><s>Some of the behavioral and neural correlates of attention are similar whether the attention is bottom-up or top-down.</s><s>In the Biased Competition Model of attention, stimuli compete against each other to dominate the neural response <ref type="bibr" target="#b43">(Desimone, 1998)</ref>.</s><s>Attention (bottom-up or top-down) can thus work by biasing this competition toward the stimulus that is the target of attention.</s><s>While the Biased Competition Model is sometimes used simply as a "word model" to guide intuition, explicit computational instantiations of it have also been built.</s><s>A hierarchical model of the visual pathway that included top-down biasing as well as local competition mediated through horizontal connections was able to replicate multiple neural effects of attention <ref type="bibr" target="#b41">(Deco and Rolls, 2004)</ref>.</s><s>A model embodying similar principles but using spiking neurons was also implemented <ref type="bibr" target="#b42">(Deco and Rolls, 2005)</ref>.</s></p><p><s>Similar models have been constructed explicitly to deal with attribute naming tasks such as the Stroop test described above.</s><s>The Selective Attention Model (SLAM), for example, has local competition in both the sensory encoding and motor output modules and can mimic known properties of response times in easier and more challenging Stroop-like tests <ref type="bibr" target="#b115">(Phaf et al., 1990)</ref>.</s></p><p><s>Visual perception has been framed and modeled as a problem of Bayesian inference <ref type="bibr" target="#b82">(Lee and Mumford, 2003)</ref>.</s><s>Within this context, attention can help resolve uncertainty under settings where inference is more challenging, typically by modulating priors <ref type="bibr" target="#b119">(Rao, 2005)</ref>.</s><s>For example, in <ref type="bibr" target="#b33">Chikkerur et al. (2010)</ref> spatial attention functions to reduce uncertainty about object identity and feature attention reduces spatial uncertainty.</s><s>These principles can capture both behavioral and neural features of attention and can be implemented in a biologically-inspired neural model.</s></p><p><s>The feature similarity gain model of attention (FSGM) is a description of the neural effects of top-down attention that can be applied in both the feature and spatial domain <ref type="bibr" target="#b147">(Treue and Trujillo, 1999)</ref>.</s><s>It says that the way in which a neuron's response is modulated by attention depends on that neuron's tuning.</s><s>Tuning is a description of how a neuron responds to different stimuli, so according to the FSGM a neuron that prefers (that is, responds strongly to), e.g., the color blue, will have its activity enhanced by top-down attention to blue.</s><s>The FSGM also says attention to non-preferred stimuli will cause a decrease in firing and that, whether increased or decreased, activity is scaled multiplicatively by attention.</s><s>Though not initially defined as a computational model, this form of neural modulation has since been shown through modeling to be effective at enhancing performance on challenging visual tasks <ref type="bibr" target="#b86">(Lindsay and Miller, 2018)</ref>.</s></p><p><s>Other models conceptualize attention as a dynamic routing of information through a network.</s><s>An implementation of this form of attention can be found in the Selective Attention for Identification Model (SAIM) <ref type="bibr" target="#b62">(Heinke and Humphreys, 2003)</ref>.</s><s>Here, attention routes information from the retina to a representation deemed the "focus of attention"; depending on the current task, different parts of the retinal representation will be mapped to the focus of attention.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4.">Attention in Other Sensory Modalities</head><p><s>A famous example of the need for selective attention in audition is the "cocktail party problem": the difficulty of focusing on the speech from one speaker in a crowded room of multiple speakers and other noises <ref type="bibr" target="#b21">(Bronkhorst, 2015)</ref>.</s><s>Solving the problem is believed to involve "early" selection wherein low level features of a voice such as pitch are used to determine which auditory information is passed on for further linguistic processing.</s><s>Interestingly, selective auditory attention has the ability to control neural activity at even the earliest level of auditory processing, the cochlea <ref type="bibr" target="#b52">(Fritz et al., 2007)</ref>.</s></p><p><s>Spatial and feature attention have also been explored in the somatosensory system.</s><s>Subjects cued to expect a tap at different parts on their body are better able to detect the sensation when that cue is valid.</s><s>However, these effects seem weaker than they are in the visual system <ref type="bibr" target="#b71">(Johansen-Berg and Lloyd, 2000)</ref>.</s><s>Reaction times are faster in a detection task when subjects are cued about the orientation of a stimulus on their finger <ref type="bibr" target="#b132">(Schweisfurth et al., 2014)</ref>.</s></p><p><s>In a study that tested subjects' ability to detect a taste they had been cued for it was shown that validly-cued tastes can be detected at lower concentrations than invalidlycued ones <ref type="bibr" target="#b98">(Marks and Wheeler, 1998)</ref>.</s><s>This mimics the behavioral effects found with feature-based visual attention.</s><s>Attention to olfactory features has not been thoroughly explored, though visually-induced expectations about a scent can aid its detection <ref type="bibr" target="#b57">(Gottfried and Dolan, 2003;</ref><ref type="bibr" target="#b75">Keller, 2011)</ref>.</s></p><p><s>Attention can also be spread across modalities to perform tasks that require integration of multiple sensory signals.</s><s>In general, the use of multiple congruent sensory signals aids detection of objects when compared to relying only on a single modality.</s><s>Interestingly, some studies suggest that humans may have a bias for the visual domain, even when the signal from another domain is equally valid <ref type="bibr" target="#b139">(Spence, 2009)</ref>.</s><s>Specifically, the visual domain appears to dominate most in tasks that require identifying the spatial location of a cue <ref type="bibr" target="#b14">(Bertelson and Aschersleben, 1998)</ref>.</s><s>This can be seen most readily in ventriloquism, where the visual cue of the dummy's mouth moving overrides auditory evidence about the true location of the vocal source.</s><s>Visual evidence can also override tactile evidence, for example, in the context of the rubber arm illusion <ref type="bibr" target="#b20">(Botvinick and Cohen, 1998)</ref>.</s></p><p><s>Another effect of the cross-modal nature of sensory processing is that an attentional cue in one modality can cause an orienting of attention in another modality <ref type="bibr" target="#b140">(Spence and Driver, 2004)</ref>.</s><s>Generally, the attention effects in the non-cued modality are weaker.</s><s>This cross-modal interaction can occur in the context of both endogenous ("top-down") and exogenous ("bottomup") attention.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Attention and Executive Control</head><p><s>With multiple simultaneous competing tasks, a central controller is needed to decide which to engage in and when.</s><s>What's more, how to best execute tasks can depend on history and context.</s><s>Combining sensory inputs with past knowledge in order to coordinate multiple systems for the job of efficient task selection and execution is the role of executive control, and this control is usually associated with the prefrontal cortex <ref type="bibr" target="#b100">(Miller and Buschman, 2014)</ref>.</s><s>As mentioned above, sources of top-down visual attention have also been located in prefrontal regions.</s><s>Attention can reasonably be thought of as the output of executive control.</s><s>The executive control system must thus select the targets of attention and communicate that to the systems responsible for implementing it.</s><s>According to the reverse hierarchy theory described above, higher areas signal to those from which they get input which send the signal on to those below them and so on <ref type="bibr" target="#b0">(Ahissar and Hochstein, 2000)</ref>.</s><s>This means that, at each point, the instructions for attention must be transformed into a representation that makes sense for the targeted region.</s><s>Through this process, the high level goals of the executive control region can lead to very specific changes, for example, in early sensory processing.</s></p><p><s>Executive control and working memory are also intertwined, as the ability to make use of past information as well as to keep a current goal in mind requires working memory.</s><s>Furthermore, working memory is frequently identified as sustained activity in prefrontal areas.</s><s>A consequence of the three-way relationship between executive control, working memory, and attention is that the contents of working memory can impact attention, even when not desirable for the task <ref type="bibr" target="#b138">(Soto et al., 2008)</ref>.</s><s>For example, if a subject has to keep an object in working memory while simultaneously performing a visual search for a separate object, the presence of the stored object in the search array can negatively interfere with the search <ref type="bibr" target="#b137">(Soto et al., 2005)</ref>.</s><s>This suggests that working memory can interfere with the executive control of attention.</s><s>However, there still appears to be additional elements of that control that working memory alone does not disrupt.</s><s>This can be seen in studies wherein visual search performance is even worse when subjects believe they will need to report the memorized item but are shown a search array for the attended item instead <ref type="bibr" target="#b111">(Olivers and Eimer, 2011)</ref>.</s><s>This suggests that, while all objects in working memory may have some influence over attention, the executive controller can choose which will have the most.</s></p><p><s>Beyond the flexible control of attention within a sensory modality, attention can also be shifted between modalities.</s><s>Behavioral experiments indicate that switching attention either between two different tasks within a sensory modality (for example, going from locating a visual object to identifying it) or between sensory modalities (switching from an auditory task to a visual one) incurs a computational cost <ref type="bibr" target="#b113">(Pashler, 2000)</ref>.</s><s>This cost is usually measured as the extent to which performance is worse on trials just after the task has been switched vs. those where the same task is being repeated.</s><s>Interestingly, task switching within a modality seems to incur a larger cost than switching between modalities <ref type="bibr" target="#b105">(Murray et al., 2009)</ref>.</s><s>A similar result is found when switching between or across modes of response (for example, pressing a bottom vs. verbal report), suggesting this is not specific to sensory processing <ref type="bibr" target="#b6">(Arrington et al., 2003)</ref>.</s><s>Such findings are believed to stem from the fact that switching within a modality requires a reconfiguration of the same neural circuits, which is more difficult than merely engaging the circuitry of a different sensory system.</s><s>An efficient executive controller would need to be aware of these costs when deciding to shift attention and ideally try to minimize them; it has been shown that switch costs can be reduced with training <ref type="bibr" target="#b56">(Gopher, 1996)</ref>.</s></p><p><s>The final question regarding the executive control of attention is how it evolves with learning.</s><s>Eye movement studies indicate that searched-for items can be detected more rapidly in familiar settings rather than novel ones, suggesting that previouslylearned associations guide overt attention <ref type="bibr" target="#b36">(Chun and Jiang, 1998)</ref>.</s><s>Such benefits are believed to rely on the hippocampus <ref type="bibr" target="#b1">(Aly and Turk-Browne, 2017)</ref>.</s><s>In general, however, learning how to direct attention is not as studied as other aspects of the attention process.</s><s>Some studies have shown that subjects can enhance their ability to suppress irrelevant task information, and the generality of that suppression depends on the training procedure <ref type="bibr" target="#b76">(Kelley and Yantis, 2009)</ref>.</s><s>Looking at the neural correlates of attention learning, imaging results suggest that the neural changes associated with learning do not occur in the sensory pathways themselves but rather in areas more associated with attentional control <ref type="bibr" target="#b77">(Kelley and Yantis, 2010)</ref>.</s><s>Though not always easy to study, the development of attentional systems in infancy and childhood may provide further clues as to how attention can be learned <ref type="bibr" target="#b122">(Reynolds and Romano, 2016)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Attention and Memory</head><p><s>Attention and memory have many possible forms of interaction.</s><s>If memory has a limited capacity, for example, it makes sense for the brain to be selective about what is allowed to enter it.</s><s>In this way, the ability of attention to dynamically select a subset of total information is well-matched to the needs of the memory system.</s><s>In the other direction, deciding to recall a specific memory is a choice about how to deploy limited resources.</s><s>Therefore, both memory encoding and retrieval can rely on attention.</s></p><p><s>The role of attention in memory encoding appears quite strong <ref type="bibr" target="#b1">(Aly and Turk-Browne, 2017)</ref>.</s><s>For information to be properly encoded into memory, it is best for it be the target of attention.</s><s>When subjects are asked to memorize a list of words while simultaneously engaging in a secondary task that divides their attention, their ability to consciously recall those words later is impaired (though their ability to recognize the words as familiar is not so affected) <ref type="bibr" target="#b55">(Gardiner and Parkin, 1990)</ref>.</s><s>Imaging studies have shown that increasing the difficulty of the secondary task weakens the pattern of activity related to memory encoding in the left ventral inferior frontal gyrus and anterior hippocampus and increases the representation of secondary task information in dorsolateral prefrontal and superior parietal regions <ref type="bibr" target="#b149">(Uncapher and Rugg, 2005)</ref>.</s><s>Therefore, without the limited neural processing power placed on the task of encoding, memory suffers.</s><s>Attention has also been implicated in the encoding of spatially-defined memories and appears to stabilize the representations of place cells <ref type="bibr" target="#b106">(Muzzio et al., 2009)</ref>.</s></p><p><s>Implicit statistical learning can also be biased by attention.</s><s>For example, in <ref type="bibr" target="#b148">Turk-Browne et al. (2005)</ref> subjects watched a stream of stimuli comprised of red and green shapes.</s><s>The task was to detect when a shape of the attended color appeared twice in a row.</s><s>Unbeknownst to the subjects, certain statistical regularities existed in the stream such that there were triplets of shapes likely to occur close together.</s><s>When shown two sets of three shapesone an actual co-occurring triplet and another a random selection of shapes of the same color-subjects recognized the real triplet as more familiar, but only if the triplets were from the attended color.</s><s>The statistical regularities of the unattended shapes were not learned.</s></p><p><s>Yet some learning can occur even without conscious attention.</s><s>For example, in <ref type="bibr" target="#b154">Watanabe (2003)</ref> patients engaged in a letter detection task located centrally in their visual field while random dot motion was shown in the background at sub-threshold contrast.</s><s>The motion had 10% coherence in a direction that was correlated with the currently-presented letter.</s><s>Before and after learning this task, subjects performed an above-threshold direction classification task.</s><s>After learning the task, direction classification improved only for the direction associated with the targeted letters.</s><s>This suggests a reward-related signal activated by the target led to learning about a non-attended component of the stimulus.</s></p><p><s>Many behavioral studies have explored the extent to which attention is needed for memory retrieval.</s><s>For example, by asking subjects to simultaneously recall a list of previouslymemorized words and engage in a secondary task like card sorting, researchers can determine if memory retrieval pulls from the same limited pool of attentional resources as the task.</s><s>Some such studies have found that retrieval is impaired by the co-occurrence of an attention-demanding task, suggesting it is an attention-dependent process.</s><s>The exact findings, however, depend on the details of the memory and non-memory tasks used <ref type="bibr" target="#b90">(Lozito and Mulligan, 2006)</ref>.</s></p><p><s>Even if memory retrieval does not pull from shared attentional resources, it is still clear that some memories are selected for more vivid retrieval at any given moment than others.</s><s>Therefore, a selection process must occur.</s><s>An examination of neuroimaging results suggests that the same parietal brain regions responsible for the top-down allocation and bottom-up capture of attention may play analogous roles during memory retrieval <ref type="bibr" target="#b152">(Wagner et al., 2005;</ref><ref type="bibr" target="#b37">Ciaramelli et al., 2008)</ref>.</s></p><p><s>Studies of memory retrieval usually look at medium to longterm memory but a mechanism for attention to items in working memory has also been proposed <ref type="bibr" target="#b97">(Manohar et al., 2019)</ref>.</s><s>It relies on two different mechanisms of working memory: synaptic traces for non-attended items and sustained activity for the attended one.</s><s>Some forms of memory occur automatically and within the sensory processing stream itself.</s><s>Priming is a well-known phenomenon in psychology wherein the presence of a stimulus at one point in time impacts how later stimuli are processed or interpreted.</s><s>For example, the word "doctor" may be recognized more quickly following the word "hospital" than the word "school."</s><s>In this way, priming requires a form of implicit memory to allow previous stimuli to impact current ones.</s><s>Several studies on conceptual or semantic priming indicate that attention to the first stimulus is required for priming effects to occur <ref type="bibr" target="#b10">(Ballesteros and Mayas, 2015)</ref>; this mirrors findings that attention is required for memory encoding more generally.</s></p><p><s>Most priming is positive, meaning that the presence of a stimulus at one time makes the detection and processing of it or a related stimulus more likely at a later time.</s><s>In this way, priming can be thought of as biasing bottom-up attention.</s><s>However, topdown attention can also create negative priming.</s><s>In negative priming, when stimuli that functioned as a distractor on the previous trial serve as the target of attention on the current trial, performance suffers <ref type="bibr" target="#b51">(Frings et al., 2015)</ref>.</s><s>This may stem from a holdover effect wherein the mechanisms of distractor suppression are still activated for the now-target stimulus.</s></p><p><s>Adaptation can also be considered a form of implicit memory.</s><s>Here, neural responses decrease after repeated exposure to the same stimulus.</s><s>By reducing the response to repetition, changes in the stimulus become more salient.</s><s>Attention-by increasing the neural response to attended stimuli-counters the effects of adaptation <ref type="bibr" target="#b114">(Pestilli et al., 2007;</ref><ref type="bibr">Anton-Erxleben et al., 2013)</ref>.</s><s>Thus, both with priming and adaptation, top-down attention can overcome automatic processes that occur at lower levels which may be guiding bottom-up attention.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ATTENTION IN MACHINE LEARNING</head><p><s>While the concept of artificial attention has come up prior to the current resurgence of artificial neural networks, many of its popular uses today center on ANNs <ref type="bibr" target="#b95">(Mancas et al., 2016)</ref>.</s><s>The use of attention mechanisms in artificial neural networks came about-much like the apparent need for attention in the brainas a means of making neural systems more flexible.</s><s>Attention mechanisms in machine learning allow a single trained artificial neural network to perform well on multiple tasks or tasks with inputs of variable length, size, or structure.</s><s>While the spirit of attention in machine learning is certainly inspired by psychology, its implementations do not always track with what is known about biological attention, as will be noted below.</s></p><p><s>In the form of attention originally developed for ANNs, attention mechanisms worked within an encoder-decoder framework and in the context of sequence models <ref type="bibr" target="#b34">(Cho et al., 2015;</ref><ref type="bibr" target="#b28">Chaudhari et al., 2019)</ref>.</s><s>Specifically, an input sequence will be passed through an encoder (likely a recurrent neural network) and the job of the decoder (also likely a recurrent neural network) will be to output another sequence.</s><s>Connecting the encoder and decoder is an attention mechanism.</s></p><p><s>Commonly, the output of the encoder is a set of a vectors, one for each element in the input sequence.</s><s>Attention helps determine which of these vectors should be used to generate the output.</s><s>Because the output sequence is dynamically generated one element at a time, attention can dynamically highlight different encoded vectors at each time point.</s><s>This allows the decoder to flexibly utilize the most relevant parts of the input sequence.</s></p><p><s>The specific job of the attention mechanism is to produce a set of scalar weightings, α i t , one for each of the encoded vectors (v i ).</s><s>At each step t, the attention mechanism (φ) will take in information about the decoder's previous hidden state (h t-1 ) and the encoded vectors to produce unnormalized weightings:</s></p><formula xml:id="formula_0">αt = φ(h t-1 , v)<label>(1)</label></formula><p><s>Because attention is a limited resource, these weightings need to represent relative importance.</s><s>To ensure that the α values sum to one, the unnormalized weightings are passed through a softmax:</s></p><formula xml:id="formula_1">α i t = exp( αi t ) j exp( αj t )<label>(2)</label></formula><p><s>These attention values scale the encoded vectors to create a single context vector on which the decoder can be conditioned:</s></p><formula xml:id="formula_2">c t = j α j t v j<label>(3)</label></formula><p><s>This form of attention can be made entirely differentiable and so the whole network can be trained end-to-end with simple gradient descent.</s><s>This type of artificial attention is thus a form of iterative re-weighting.</s><s>Specifically, it dynamically highlights different components of a pre-processed input as they are needed for output generation.</s><s>This makes it flexible and context dependent, like biological attention.</s><s>As such it is also inherently dynamic.</s><s>While sequence modeling already has an implied temporal component, this form of attention can also be applied to static inputs and outputs (as will be discussed below in the context of image processing) and will thus introduce dynamics into the model.</s></p><p><s>In the traditional encoder-decoder framework without attention, the encoder produced a fixed-length vector that was independent of the length or features of the input and static during the course of decoding.</s><s>This forced long sequences or sequences with complex structure to be represented with the same dimensionality as shorter or simpler ones and didn't allow the decoder to interrogate different parts of the input during the decoding process.</s><s>But encoding the input as a set of vectors equal in length to the input sequence makes it possible for the decoder to selectively attend to the portion of the input sequence relevant at each time point of the decoding.</s><s>Again, as in interpretations of attention in the brain, attention in artificial systems is helpful as a way to flexibly wield limited resources.</s><s>The decoder can't reasonably be conditioned on the entirety of the input so at some point a bottleneck must be introduced.</s><s>In the system without attention, the fixed-length encoding vector was a bottleneck.</s><s>When an attention mechanism is added, the encoding can be larger because the bottleneck (in the form of the context vector) will be produced dynamically as the decoder determines which part of the input to attend to.</s></p><p><s>The motivation for adding such attention mechanisms to artificial systems is of course to improve their performance.</s><s>But another claimed benefit of attention is interpretability.</s><s>By identifying on which portions of the input attention is placed (that is, which α i values are high) during the decoding process, it may be possible to gain an understanding of why the decoder produced the output that it did.</s><s>However, caution should be applied when interpreting the outputs of attention as they may not always explain the behavior of the model as expected <ref type="bibr" target="#b70">(Jain and Wallace, 2019;</ref><ref type="bibr" target="#b155">Wiegreffe and Pinter, 2019)</ref>.</s></p><p><s>In the following subsections, specific applications of this general attention concept will be discussed, along with some that don't fit neatly into this framework.</s><s>Further analogies to the biology will also be highlighted.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Attention for Natural Language Processing</head><p><s>As described above, attention mechanisms have frequently been added to models charged with processing sequences.</s><s>Natural language processing (NLP) is one of the most common areas of application for sequence modeling.</s><s>And, though it was not the original domain of attention in machine learning-nor does it have the most in common with biology-NLP is also one of the most common areas of application for attention <ref type="bibr" target="#b54">(Galassi et al., 2019)</ref>.</s></p><p><s>An early application of the this form of attention in artificial neural networks was to the task of translation <ref type="bibr" target="#b9">(Bahdanau et al., 2014)</ref> (Figure <ref type="figure" target="#fig_2">3</ref>).</s><s>In this work, a recurrent neural network encodes the input sentence as a set of "annotation" vectors, one for each word in the sentence.</s><s>The output, a sentence in the target language, is generated one word at a time by a recurrent neural network.</s><s>The probability of each generated word is a function of the previously generated word, the hidden state of the recurrent neural network and a context vector generated by the attention mechanism.</s><s>Here, the attention mechanism is a small feedforward neural network that takes in the hidden state of the output network as well as the current annotation vector to create the weighting over all annotation vectors.</s></p><p><s>Blending information from all the words in the sentence this way allows the network to pull from earlier or later parts when generating an output word.</s><s>This can be especially useful for translating between languages with different standard word orders.</s><s>By visualizing the locations in the input sentence to which attention was applied the authors observed attention helping with this problem.</s></p><p><s>Since this initial application, many variants of attention networks for language translation have been developed.</s><s>In <ref type="bibr" target="#b48">Firat et al. (2016)</ref>, the attention mechanism was adapted so it could be used to translate between multiple pairs of languages rather than just one.</s><s>In <ref type="bibr" target="#b93">Luong et al. (2015)</ref>, the authors explore different structures of attention to determine if the ability to access all input words at once is necessary.</s><s>And in <ref type="bibr" target="#b32">Cheng et al. (2016)</ref>, attention mechanisms were added to the recurrent neural networks that perform the sentence encoding and decoding in order to more flexibly create sentence representations.</s></p><p><s>In 2017, the influential "Attention is All You Need" paper utilized a very different style of architecture for machine translation <ref type="bibr" target="#b151">(Vaswani et al., 2017)</ref>.</s><s>This model doesn't have any recurrence, making it simpler to train.</s><s>Instead, words in the sentence are encoded in parallel and these encodings generate key and query representations that are combined to create attention weightings.</s><s>These weightings scale the word encodings themselves to create the next layer in the model, a process known as "self-attention."</s><s>This process repeats, and eventually interacts with the autoregressive decoder which also has attention mechanisms that allow it to flexibly focus on the encoded input (as in the standard form of attention) and on the previously generated output.</s><s>The Transformer-the name given to this new attention architecture-outperformed many previous models and quickly became the standard for machine translation as well as other tasks <ref type="bibr" target="#b44">(Devlin et al., 2018)</ref>.</s></p><p><s>Interestingly, self-attention has less in common with biological attention than the recurrent attention models originally used for machine translation.</s><s>First, it reduces the role of recurrence and dynamics, whereas the brain necessarily relies on recurrence in sequential processing tasks, including language processing and attentional selection.</s><s>Second, self-attention provides a form of horizontal interaction between words-which allows for words in the encoded sentence to be processed in the context of those around them-but this mechanism does not include an obvious top-down component driven by the needs of the decoder.</s><s>In fact, self-attention has been shown under certain circumstances to simply implement a convolution, a standard feedforward computation frequently used in image processing <ref type="bibr" target="#b3">(Andreoli, 2019;</ref><ref type="bibr" target="#b39">Cordonnier et al., 2019)</ref>.</s><s>In this way, self-attention is more about creating a good encoding than performing a task-specific attention-like selection based on limited resources.</s><s>In the context of a temporal task, its closest analogue in psychology may be priming because priming alters the encoding of subsequent stimuli based on those that came before.</s><s>It is of course not the direct goal of machine learning engineers to replicate the brain, but rather to create networks that can be easily trained to perform well on tasks.</s><s>These different constraints mean that even large advances in machine learning do not necessarily create more brain-like models.</s></p><p><s>While the study of attention in human language processing is not as large as other areas of neuroscience research, some work has been done to track eye movements while reading <ref type="bibr" target="#b107">(Myachykov and Posner, 2005)</ref>.</s><s>They find that people will look back at previous sections of text in order to clarify what they are currently reading, particularly in the context of finding the antecedent of a pronoun.</s><s>Such shifts in overt attention indicate what previous information is most relevant for the current processing demands.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Attention for Visual Tasks</head><p><s>As in neuroscience and psychology, a large portion of studies in machine learning are done on visual tasks.</s><s>One of the original attention-inspired tools of computer vision is the saliency map, which identifies which regions in an image are most salient based on a set of low-level visual features such as edges, color, or depth and how they differ from their surround <ref type="bibr" target="#b68">(Itti and Koch, 2001)</ref>.</s><s>In this way, saliency maps indicate which regions would be captured by "bottom-up" attention in humans and animals.</s><s>Computer scientists have used saliency maps as part of their image processing pipeline to identify regions for further processing.</s></p><p><s>In more recent years, computer vision models have been dominated by deep learning.</s><s>And since their success in the 2012 ImageNet Challenge <ref type="bibr" target="#b127">(Russakovsky et al., 2015)</ref>, convolutional neural networks have become the default architecture for visual tasks in machine learning.</s></p><p><s>The architecture of convolutional neural networks is loosely based on the mammalian visual system <ref type="bibr" target="#b85">(Lindsay, 2020)</ref>.</s><s>At each layer, a bank of filters is applied to the activity of the layer below (in the first layer this is the image).</s><s>This creates a H × W × C tensor of neural activity with the number of channels, C equal to the number of filters applied and H and W representing the height and width of the 2-D feature maps that result from the application of a filter.</s></p><p><s>Attention in convolutional neural networks has been used to enhance performance on a variety of tasks including classification, segmentation, and image-inspired natural language processing.</s><s>Also, as in the neuroscience literature, these attentional processes can be divided into spatial and feature-based attention.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Spatial Attention</head><p><s>Building off of the structures used for attention in NLP tasks, visual attention has been applied to image captioning.</s><s>In <ref type="bibr" target="#b161">Xu et al. (2015)</ref>, the encoding model is a convolutional neural network.</s><s>The attention mechanism works over the activity at the fourth convolutional layer.</s><s>As each word of the caption is generated, a different pattern of weighting across spatial locations of the image representation is created.</s><s>In this way, attention for caption generation replaces the set of encoded word vectors in a translation task with a set of encoded image locations.</s><s>Visualizing the locations with high weights, the model appears to attend to the object most relevant to the current word being generated for the caption.</s></p><p><s>This style of attention is referred to as "soft" because it produces a weighted combination of the visual features over spatial locations (Figure <ref type="figure" target="#fig_3">4B</ref>).</s><s>"Hard" attention is an alternative form that chooses a single spatial location to be passed into the decoder at the expense of all others (Figure <ref type="figure" target="#fig_3">4A</ref>).</s><s><ref type="bibr">In Xu et al. (2015)</ref>, to decide which location should receive this hard attention, the attention weights generated for each spatial location were treated as probabilities.</s><s>One location is chosen according to these probabilities.</s><s>Adding this stochastic element to the network makes training more difficult, yet it was found to perform somewhat better than soft attention.</s></p><p><s>A 2014 study used reinforcement learning to train a hard attention network to perform object recognition in challenging conditions <ref type="bibr" target="#b103">(Mnih et al., 2014)</ref>.</s><s>The core of this model is a recurrent neural network that both keeps track of information taken in over multiple "glimpses" made by the network and outputs the location of the next glimpse.</s><s>For each glimpse, the network receives a fovea-like input (central areas are represented with high resolution and peripheral with lower) from a small patch of the image.</s><s>The network has to integrate the information gained from these glimpses to find and classify the object in the image.</s><s>This is similar to the hard attention described above, except the selection of a location here determines which part of the image is sampled next (whereas in the case above it determined which of the already-processed image locations would be passed to the decoder).</s><s>With the use of these glimpses, the network is not required to process all of the image, saving computational resources.</s><s>It can also help when multiple objects are present in the image and the network must classify each <ref type="bibr" target="#b7">(Ba et al., 2014)</ref>.</s><s>Recent work has shown that adding a pretraining step enhances the performance of hard attention applied to complex images <ref type="bibr" target="#b47">(Elsayed et al., 2019)</ref>.</s></p><p><s>In many ways, the correspondence between biological and artificial attention is strongest when it comes to visual spatial attention.</s><s>For example, this form of hard attention-where different locations of the image are sequentially-sampled for further processing-replicates the process of saccading and is therefore akin to overt visual attention in the neuroscience and psychology literature.</s><s>Insofar as soft attention dynamically reweights different regions of the network's representation of the image without any change in the input to the network, it is akin to covert spatial attention.</s><s>Also, as the mode of application for soft attention involves multiplicative scaling of the activity of all units at a specific location, it replicates neural findings about covert spatial attention.</s></p><p><s>Soft spatial attention has been used for other tasks, including visual question and answering <ref type="bibr" target="#b29">(Chen et al., 2015;</ref><ref type="bibr" target="#b160">Xu and Saenko, 2016;</ref><ref type="bibr" target="#b162">Yang et al., 2016)</ref> and action recognition in videos <ref type="bibr" target="#b134">(Sharma et al., 2015)</ref>.</s><s>Hard attention has also been used for instance segmentation <ref type="bibr" target="#b121">(Ren and Zemel, 2017)</ref> and for finegrained classification when applied using different levels of image resolution <ref type="bibr" target="#b53">(Fu et al., 2017)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Feature Attention</head><p><s>In the case of soft spatial attention, weights are different in different spatial locations of the image representation yet they are the same across all feature channels at that location.</s><s>That is, the activity of units in the network representing different visual features will all be modified the same way if they represent the same location in image space.</s><s>Feature attention makes it possible to dynamically re-weight individual feature maps, creating a spatially global change in feature processing.</s></p><p><s>In <ref type="bibr" target="#b142">Stollenga et al. (2014)</ref>, a convolutional neural network is equipped with a feature-based attention mechanism.</s><s>After an image is passed through the standard feedforward architecture, the activity of the network is passed into a policy that determines how the different feature maps at different layers should be weighted.</s><s>This re-weighting leads to different network activity which leads to different re-weightings.</s><s>After the network has run for several timesteps the activity at the final layer is used to classify the object in the image.</s><s>The policy that determines the weighting values is learned through reinforcement learning, and can be added to any pre-trained convolutional neural network.</s></p><p><s>The model in <ref type="bibr" target="#b30">Chen et al. (2017)</ref> combines feature and spatial attention to aid in image captioning.</s><s>The activity of the feedforward pass of the convolutional network is passed into the attention mechanism along with the previously generated word to create attention weightings for different channels at each layer in the CNN.</s><s>These weights are used to scale activity and then a separate attention mechanism does the same procedure for generating spatial weightings.</s><s>Both spatial and feature attention weights are generated and applied to the network at each time point.</s></p><p><s>In the model in De Vries et al. ( <ref type="formula">2017</ref>), the content of a question is used to control how a CNN processes an image for the task of visual question and answering.</s><s>Specifically, the activity of a language embedding network is passed through a multi-layer perceptron to produce the additive and multiplicative parameters for batch normalization of each channel in the CNN.</s><s>This procedure, termed conditional batch normalization, functions as a form of question-dependent feature attention.</s></p><p><s>A different form of dynamic feature re-weighting appears in "squeeze-and-excitation" networks <ref type="bibr" target="#b65">(Hu et al., 2018)</ref>.</s><s>In this architecture, the weightings applied to different channels are a nonlinear function of the activity of the other channels at the same layer.</s><s>As with "self-attention" described above, this differs in spirit from more "top-down" approaches where weightings are a function of activity later in the network and/or biased by the needs of the output generator.</s><s>Biologically speaking, this form of interaction is most similar to horizontal connections within a visual area, which are known to carry out computations such as divisive normalization <ref type="bibr" target="#b27">(Carandini and Heeger, 2012)</ref>.</s></p><p><s>In the study of the biology of feature-based attention, subjects are usually cued to attend to or search for specific visual features.</s><s>In this way, the to-be-attended features are known in advance and relate to the specific sub-task at hand (e.g., detection of a specific shape on a given trial of a general shape detection task).</s><s>This differs from the above instances of artificial feature attention, wherein no external cue biases the network processing before knowledge about the specific image is available.</s><s>Rather, the feature re-weighting is a function of the image itself and meant to enhance the performance of the network on a constant task (note this was also the case for the forms of artificial spatial attention described).</s></p><p><s>The reason for using a cueing paradigm in studies of biological attention is that it allows the experimenter to control (and thus know) where attention is placed.</s><s>Yet, it is clear that even without explicit cueing, our brains make decisions about where to place attention constantly; these are likely mediated by local and longrange feedback connections to the visual system <ref type="bibr" target="#b159">(Wyatte et al., 2014)</ref>.</s><s>Therefore, while the task structure differs between the study of biological feature attention and its use in artificial systems, this difference may only be superficial.</s><s>Essentially, the artificial systems are using feedforward image information to internally generate top-down attentional signals rather than being given the top-down information in the form of a cue.</s></p><p><s>That being said, some artificial systems do allow for externallycued feature attention.</s><s>For example setting a prior over categories in the network in <ref type="bibr" target="#b26">Cao et al. (2015)</ref> makes it better at localizing the specific category.</s><s>The network in <ref type="bibr" target="#b153">Wang et al. (2014)</ref>, though not convolutional, has a means of biasing the detection of specific object categories as well.</s><s>And in <ref type="bibr" target="#b86">Lindsay and Miller (2018)</ref>, several performance and neural aspects of biological feature attention during a cued object detection task were replicated using a CNN.</s><s>In <ref type="bibr" target="#b92">Luo et al. (2020)</ref>, the costs and benefits of using a form of cued attention in CNNs were explored.</s></p><p><s>As mentioned above, the use of multiplicative scaling of activity is in line with certain findings from biological visual attention.</s><s>Furthermore, modulating entire feature maps by the same scalar value is aligned with the finding mentioned above that feature attention acts in a spatially global way in the visual system.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Multi-Task Attention</head><p><s>Multi-task learning is a challenging topic in machine learning.</s><s>When one network is asked to perform several different tasksfor example, a CNN that must classify objects, detect edges, and identify salient regions-training can be difficult as the weights needed to do each individual task may contradict each other.</s><s>One option is have a set of task-specific parameters that modulate the activity of the shared network differently for each task.</s></p><p><s>While not always called it, this can reasonably be considered a form of attention, as it flexibly alters the functioning of the network.</s></p><p><s>In <ref type="bibr" target="#b96">Maninis et al. (2019)</ref>, a shared feedforward network is trained on all of multiple tasks, while task specific skip connections and squeeze-and-excitation blocks are trained to modulate this activity only on their specific task.</s><s>This lets the network benefit from sharing processing that is common to all tasks while still specializing somewhat to each.</s></p><p><s>A similar procedure was used in <ref type="bibr" target="#b120">Rebuffi et al. (2017)</ref> to create a network that performs classification on multiple different image domains.</s><s>There, the domain could be identified from the input image making it possible to select the set of task-specific parameters automatically at run-time.</s></p><p><s>In <ref type="bibr" target="#b165">Zhao et al. (2018)</ref>, the same image can be passed into the network and be classified along different dimensions (e.g.</s><s>whether the person in the picture is smiling or not, young or old).</s><s>Task-specific re-weighting of feature channels is used to execute these different classifications.</s></p><p><s>The model in <ref type="bibr" target="#b143">Strezoski et al. (2019)</ref> uses what could be interpreted as a form of hard feature attention to route information differently in different tasks.</s><s>Binary masks over feature channels are chosen randomly for each task.</s><s>These masks are applied in a task-specific way during training on all tasks and at run-time.</s><s>Note that in this network no task-specific attentional parameters are learned, as these masks are predetermined and fixed during training.</s><s>Instead, the network learns to use the different resulting information pathways to perform different tasks.</s></p><p><s>In a recent work, the notion of task-specific parameters was done away with entirely <ref type="bibr" target="#b83">(Levi and Ullman, 2020)</ref>.</s><s>Instead, the activations of a feedforward CNN are combined with a task input and passed through a second CNN to generate a full set of modulatory weights.</s><s>These weights then scale the activity of the original network in a unit-specific way (thus implementing both spatial and feature attention).</s><s>The result is a single set of feedforward weights capable of flexibly engaging in multiple visual tasks.</s></p><p><s>When the same input is processed differently according to many different tasks, these networks are essentially implementing a form of within-modality task switching that relies on feature attention.</s><s>In this way, it is perhaps most similar to the Stroop test described previously.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Attention to Memory</head><p><s>Deep neural networks tend not to have explicit memory, and therefore attention to memory is not studied.</s><s>Neural Turing Machines, however, are a hybrid neural architecture that includes external memory stores <ref type="bibr" target="#b59">(Graves et al., 2014)</ref>.</s><s>The network, through training, learns how to effectively interact with these stores to perform tasks such as sorting and repetition of stored sequences.</s><s>Facilitating this interaction is a form of attention.</s><s>Memories are stored as a set of vectors.</s><s>To retrieve information from this store, the network generates a weight for each vector and calculates a weighted sum of the memories.</s><s>To determine these weights, a recurrent neural network (which receives external and task-relevant input) outputs a vector and memories are weighted in accordance to their similarity to this vector.</s><s>Thus, at each point in time, the network is able to access contextrelevant memories.</s></p><p><s>As described previously, how the brain chooses what memories to attend to and then attends to them is not entirely clear.</s><s>The use of a similarity metric in this model means that memories are retrieved based on their overlap with a produced activity vector, similar to associative memory models in the neuroscience literature.</s><s>This offers a mechanism for the latter question-that is, how attention to memory could be implemented in the brain.</s><s>The activity vector that the model produces controls what memories get attended and the relationship with biology is less clear here.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">IDEAS FOR FUTURE INTERACTION BETWEEN ARTIFICIAL AND BIOLOGICAL ATTENTION</head><p><s>As has been shown, some amount of inspiration from biology has already led to several instances of attention in artificial neural networks (summarized in Figure <ref type="figure" target="#fig_4">5</ref>).</s><s>While the addition of such attention mechanisms has led to appreciable increases in performance in these systems, there are clearly still many ways in which they fall short and additional opportunities for further inspiration exist.</s><s>In the near term, this inspiration will likely be in the form of incremental improvements to specialized artificial systems as exist now.</s><s>However, the true promise of brain-inspired AI should deliver a more integrated, multiple-purpose agent that can engage flexibly in many tasks.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">How to Enhance Performance</head><p><s>There are two components to the study of how attention works in the brain that can be considered flip sides of the same coin.</s><s>The first is the question of how attention enhances performance in the way that it does-that is, how do the neural changes associated with attention make the brain better at performing tasks.</s><s>The second is how and why attention is deployed in the way that it is-what factors lead to the selection of certain items or tasks for attention and not others.</s></p><p><s>Neuroscientists have spent a lot of time investigating the former question.</s><s>In large part, the applicability of these findings to artificial neural systems, however, may not be straightforward.</s><s>Multiplicative scaling of activity appears in both biological and artificial systems and is an effective means of implementing attention.</s><s>However, many of the observed effects of attention in the brain make sense mainly as a means of increasing the signal carried by noisy, spiking neurons.</s><s>This includes increased synchronization across neurons and decreased firing variability.</s><s>Without analogs for these changes in deep neural networks, it is hard to take inspiration from them.</s><s>What's more, the training procedures for neural networks can automatically determine the changes in activity needed to enhance performance on a welldefined task and so lessons from biological changes may not be as relevant.</s></p><p><s>On the other hand, the observation that attention can impact spiking-specific features such as action potential height, burstiness, and precise spike times may indicate the usefulness of spiking networks.</s><s>Specifically, spiking models offer more degrees of freedom for attention to control and thus allow attention to possibly have larger and/or more nuanced impacts.</s></p><p><s>Looking at the anatomy of attention may provide usable insights to people designing architectures for artificial systems.</s><s>For example, visual attention appears to modulate activity more strongly in later visual areas like V4 <ref type="bibr" target="#b108">(Noudoost et al., 2010)</ref>, whereas auditory attention can modulate activity much earlier in the processing stream.</s><s>The level at which attention should act could thus be a relevant architectural variable.</s><s>In this vein, recent work has shown that removing self-attention from the early layers of a Transformer model enhances its performance on certain natural language processing tasks and also makes the model a better predictor of human fMRI signals during language processing <ref type="bibr" target="#b145">(Toneva and Wehbe, 2019)</ref>.</s></p><p><s>The existence of cross-modal cueing-wherein attention cued in one sensory modality can cause attention to be deployed to the same object or location in another modalityindicates some amount of direct interaction between different sensory systems.</s><s>Whereas many multi-modal models in machine learning use entirely separate processing streams that are only combined at the end, allowing some horizontal connections between different input streams may help coordinate their processing.</s></p><p><s>Attention also interacts with the kind of adaptation that normally occurs in sensory processing.</s><s>Generally, neural network models do not have mechanisms for adaptation-that is, neurons have no means of reducing their activity if given the same input for multiple time steps.</s><s>Given that adaptation helps make changes and anomalies stand out, it may be useful to include.</s><s>In a model with adaption, attention mechanisms should work to reactivate adapted neurons if the repeated stimulus is deemed important.</s></p><p><s>Finally, some forms of attention appear to act in multiple ways on the same system.</s><s>For example, visual attention is believed to both: (1) enhance the sensitivity of visual neurons in the cortex by modulating their activity and (2) change subcortical activity such that sensory information is readout differently <ref type="bibr" target="#b16">(Birman and Gardner, 2019;</ref><ref type="bibr" target="#b141">Sreenivasan and Sridharan, 2019)</ref>.</s><s>In this way, attention uses two different mechanisms, in different parts of the brain, to create its effect.</s><s>Allowing attention to modulate multiple components of a model architecture in complementary ways may allow it to have more robust and effective impacts.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">How to Deploy Attention</head><p><s>The question of how to deploy attention is likely the more relevant challenge for producing complex and integrated artificial intelligence.</s><s>Choosing the relevant information in a stream of incoming stimuli, picking the best task to engage in, or deciding whether to engage in anything at all requires that an agent have an integrative understanding of its state, environment, and needs.</s></p><p><s>The most direct way to take influence from biological attention is to mimic it directly.</s><s>Scanpath models, for example, have existed in the study of saliency for many years.</s><s>They attempt to predict the series of fixations that humans make while viewing images <ref type="bibr" target="#b18">(Borji and Itti, 2019)</ref>.</s><s>A more direct approach to training attention was used in <ref type="bibr" target="#b88">Linsley et al. (2018)</ref>.</s><s>Here, a large dataset of human top-down attention was collected by having subjects label the regions of images most relevant for object classification.</s><s>The task-specific saliency maps created through this method were used to train attention in a deep convolutional neural network whose main task was object recognition.</s><s>They found that influencing the activity of intermediate layers with this method could increase performance.</s><s>Another way of learning a teacher's saliency map was given in <ref type="bibr" target="#b163">Zagoruyko and Komodakis (2016)</ref>.</s></p><p><s>Combined training on tasks and neural data collected from human visual areas has also helped the performance of CNNs <ref type="bibr" target="#b49">(Fong et al., 2018)</ref>.</s><s>Using neural data collected during attention tasks in particular could help train attention models.</s><s>Such transfer could also be done for other tasks.</s><s>For example, tracking eye movements during reading could inform NLP models; thus far, eye movements have been used to help train a part-of-speech tagging model <ref type="bibr" target="#b11">(Barrett et al., 2016)</ref>.</s><s>Interestingly, infants may learn from attending to what adults around them attend to and the coordination of attention more broadly across agents may be very helpful in a social species.</s><s>Therefore, the attention of others should influence how attention is guided.</s><s>Attempts to coordinate joint attention will need to be integrated into attention systems <ref type="bibr" target="#b74">(Kaplan and Hafner, 2006;</ref><ref type="bibr" target="#b78">Klein et al., 2009)</ref>.</s></p><p><s>Activities would likely need to flexibly decide which of several possible goals should be achieved at any time and therefore where attention should be placed.</s><s>This problem clearly interacts closely with issues around reinforcement learningparticularly hierarchical reinforcement learning which involves the choosing of subtasks-as such decisions must be based on expected positive or negative outcomes.</s><s>Indeed, there is a close relationship between attention and reward as previously rewarded stimuli attract attention even in contexts where they no longer provide reward <ref type="bibr" target="#b25">(Camara et al., 2013)</ref>.</s><s>A better understanding of how humans choose which tasks to engage in and when should allow human behavior to inform the design of a multi-task AI.</s></p><p><s>To this end, the theory put forth in <ref type="bibr" target="#b135">Shenhav et al. (2013)</ref>, which says that allocation of the brain's limited ability to control different processes is based on the expected value of that control, may be of use.</s><s>In this framework, the dorsal anterior cingulate cortex is responsible for integrating diverse informationincluding the cognitive costs of control-in order to calculate the expected value of control and thus direct processes like attention.</s></p><p><s>Another approach for understanding human executive control in complex tasks is inverse reinforcement learning.</s><s>This method was recently applied to a dataset of eye movements during visual search in order to determine the reward functions and policies used by humans <ref type="bibr" target="#b164">(Zelinsky et al., 2020)</ref>.</s></p><p><s>An additional factor that drives biological attention but is perhaps underrepresented in artificial attention systems is curiosity <ref type="bibr" target="#b58">(Gottlieb et al., 2013)</ref>.</s><s>In biology, novel, confusing, and surprising stimuli can grab attention, and inferotemporal and perirhinal cortex are believed to signal novel visual situations via an adaptation mechanism that reduces responses to familiar inputs.</s><s>Reinforcement learning algorithms that include novelty as part of the estimate of the value of a state can encourage this kind of exploration <ref type="bibr" target="#b69">(Jaegle et al., 2019)</ref>.</s><s>How exactly to calculate surprise or novelty in different circumstances is not always clear, however.</s><s>Previous work on biological attention has understood attention selection in Bayesian terms of surprise or information gathering and these framings may be useful for artificial systems <ref type="bibr" target="#b67">(Itti and Baldi, 2006 ;</ref><ref type="bibr" target="#b101">Mirza et al., 2019)</ref>.</s></p><p><s>A final issue in the selection of attention is how conflicts are resolved.</s><s>Given the brain's multiple forms of attentionarousal, bottom-up, top-down, etc.-how do conflicts regarding the appropriate locus of attention get settled?</s><s>Looking at the visual system, it seems that the local circuits that these multiple systems target are burdened with this task.</s><s>These circuits receive neuromodulatory input along with top-down signals which they must integrate with the bottom-up input driving their activity.</s><s>Horizontal connections mediate this competition, potentially using winner-take-all mechanisms.</s><s>This can be mimicked in the architecture of artificial systems.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Attention and Learning</head><p><s>Attention, through its role in determining what enters memory, guides learning.</s><s>Most artificial systems with attention include the attention mechanism throughout training.</s><s>In this way, the attention mechanism is trained along with the base architecture; however, with the exception of the Neural Turing Machine, the model does not continue learning once the functioning attention system is in place.</s><s>Therefore, the ability of attention to control learning and memory is still not explicitly considered in these systems.</s></p><p><s>Attention could help make efficient use of data by directing learning to the relevant components and relationships in the input.</s><s>For example, saliency maps have been used as part of the pre-processing for various computer vision tasks <ref type="bibr" target="#b81">(Lee et al., 2004;</ref><ref type="bibr" target="#b156">Wolf et al., 2007;</ref><ref type="bibr">Bai and Wang, 2014)</ref>.</s><s>Focusing subsequent processing only on regions that are intrinsically salient can prevent wasteful processing on irrelevant regions and, in the context of network training, could also prevent overfitting to these regions.</s><s>Using saliency maps in this way, however, requires a definition of saliency that works for the problem at hand.</s><s>Using the features of images that capture bottom-up attention in humans has worked for some computer vision problems; looking at human data in other modalities may be useful as well.</s></p><p><s>In a related vein, studies on infants suggest that they have priors that guide their attention to relevant stimuli such as faces.</s><s>Using such priors could bootstrap learning both of how to process important stimuli and how to better attend to their relevant features <ref type="bibr" target="#b72">(Johnson, 2001)</ref>.</s></p><p><s>In addition to deciding which portions of the data to process, top-down attention can also be thought of as selecting which elements of the network should be most engaged during processing.</s><s>Insofar as learning will occur most strongly in the parts of the network that are most engaged, this is another means by which attention guides learning.</s><s>Constraining the number of parameters that will be updated in response to any given input is an effective form of regularization, as can be seen in the use of dropout and batch normalization.</s><s>Attentionrather than randomly choosing which units to engage and disengage-is constrained to choose units that will also help performance on this task.</s><s>It is therefore a more task-specific form of regularization.</s></p><p><s>In this way, attention may be particularly helpful for continual learning where the aim is to update a network to perform better on a specific task while not disrupting performance on the other tasks the network has already learned to do.</s><s>A related concept, conditional computation, has recently been applied to the problem of continual learning <ref type="bibr" target="#b84">(Lin et al., 2019)</ref>.</s><s>In conditional computation, the parameters of a network are a function of the current input (it can thus be thought of as an extreme form of the type of modulation done by attention); optimizing the network for efficient continual learning involves controlling the amount of interference between different inputs.</s><s>More generically, it may be helpful to think of attention, in part, as a means of guarding against undesirable synaptic changes.</s></p><p><s>Attention and learning also work in a loop.</s><s>Specifically, attention guides what is learned about the world and internal world models are used to guide attention.</s><s>This inter-dependency has recently been formalized in terms of a reinforcement learning framework that also incorporates cognitive Bayesian inference models that have succeeded in explaining human learning and decision making <ref type="bibr" target="#b118">(Radulescu et al., 2019)</ref>.</s><s>Interconnections between basal ganglia and prefrontal cortex are believed to support the interplay between reinforcement learning and attention selection.</s></p><p><s>At a more abstract level, the mere presence of attention in the brain's architecture can influence representation learning.</s><s>The global workspace theory of consciousness says that at any moment a limited amount of information selected from the brain's activity can enter working memory and be available for further joint processing <ref type="bibr" target="#b8">(Baars, 2005)</ref>.</s><s>Inspired by this, the 'consciousness prior' in machine learning emphasizes a neural network architecture with a low-dimensional representation that arises from attention applied to an underlying high-dimensional state representation <ref type="bibr" target="#b12">(Bengio, 2017)</ref>.</s><s>This low-D representation should efficiently represent the world at an abstract level such that it can be used to summarize and make predictions about future states.</s><s>The presence of this attention-mediated bottleneck has a trickle-down effect that encourages disentangled representations at all levels such that they can be flexibly combined to guide actions and make predictions.</s></p><p><s>Conscious attention is required for the learning of many complex skills such as playing a musical instrument.</s><s>However once fully learned, these processes can become automatic, possibly freeing attention up to focus on other things <ref type="bibr" target="#b146">(Treisman et al., 1992)</ref>.</s><s>The mechanisms of this transformation are not entirely clear but insofar as they seem to rely on moving the burden of the task to different, possibly lower/more reflexive brain areas, it may benefit artificial systems to have multiple redundant pathways that can be engaged differently by attention <ref type="bibr" target="#b116">(Poldrack et al., 2005)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Limitations of Attention: Bugs or Features?</head><p><s>Biological attention does not work perfectly.</s><s>As mentioned above, performance can suffer when switching between different kinds of attention, arousal levels need be just right in order to reach peak performance, and top-down attention can be interrupted by irrelevant but salient stimuli.</s><s>A question when transferring attention to artificial systems is are these limitations bugs to be avoided or features to be incorporated?</s><s>Distractability, in general, seems like a feature of attention rather than a bug.</s><s>Even when attempting to focus on a task it is beneficial to still be aware of-and distractable by-potentially life-threatening changes in the environment.</s><s>The problem comes only when an agent is overly distractable to inputs that do not pose a threat or provide relevant information.</s><s>Thus, artificial systems should balance the strength of top down attention such that it still allows for the processing of unexpected but informative stimuli.</s><s>For example, attentional blink refers to the phenomenon wherein a subject misses a second target in a stream of targets and distractors if it occurs quickly after a first target <ref type="bibr" target="#b133">(Shapiro et al., 1997)</ref>.</s><s>While this makes performance worse, it may be necessary to give the brain time to process and act on the first target.</s><s>In this way, it prevents distractability to ensure follow through.</s></p><p><s>Any agent, artificial or biological, will have some limitations on its energy resources.</s><s>Therefore, prudent decisions about when to engage in the world versus enter an energy-saving state such as sleep will always be of relevance.</s><s>For many animals sleep occurs according to a schedule but, as was discussed, it can also be delayed or interrupted by attentiondemanding situations.</s><s>The decision about when to enter a sleep state must thus be made based on a cost-benefit analysis of what can be gained by staying awake.</s><s>Because sleep is also known to consolidate memories and perform other vital tasks beyond just energy conservation, this decision may be a complex one.</s><s>Artificial systems will need to have an integrative understanding of their current state and future demands to make this decision.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p><s>Attention is a large and complex topic that sprawls across psychology, neuroscience, and artificial intelligence.</s><s>While many of the topics studied under this name are non-overlapping in their mechanisms, they do share a core theme of the flexible control of limited resources.</s><s>General findings about flexibility and wise uses of resources can help guide the development of AI, as can specific findings about the best means of deploying attention to specific sensory modalities or tasks.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc><div><p><s>FIGURE 1 | General attention and alertness (A) Cells in the locus coeruleus release norepinephrine (also known as noradrenaline) onto many parts of the brain with different functions, including onto other neuromodulatory systems.</s><s>This contributes to overall arousal<ref type="bibr" target="#b131">(Samuels and Szabadi, 2008)</ref>.</s><s>Colors here represent different divisions of the brain: forebrain (green), diencephalon (yellow), and brainstem (blue).</s><s>(B) The Yerkes-Dodson curve describes the nonlinear relationship between arousal and performance on challenging tasks.</s></p></div></figDesc><graphic coords="3,78.14,70.08,438.72,273.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 2 |</head><label>2</label><figDesc><div><p><s>FIGURE 2 | Visual search tasks engage many forms of visual attention.</s><s>Across the top row the progression of a visual search task is shown.</s><s>First, a cue indicates the target of the visual search, in this case a blue X.</s><s>Then a search array appears with many non-targets.</s><s>Top-down feature attention to cells that represent the color blue and the shape X will increase their firing throughout the visual field but firing will be strongest where blue or Xs actually occur.</s><s>These neural response will play a role in generating a map of covert spatial attention which can be used to explore visual space before saccading.</s><s>After the shift in overt attention with the first saccade, the covert attention map is remade.</s><s>Finally, the target is located and successfully saccaded to.</s><s>If the visual array contained a pop-out stimulus (for example a green O) it may have captured covert spatial attention in a bottom-up way and led to an additional incorrect saccade.</s></p></div></figDesc><graphic coords="5,56.14,70.00,483.12,337.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 3 |</head><label>3</label><figDesc><div><p><s>FIGURE 3 | Attention for neural machine translation.</s><s>The to-be-translated sentence is encoded to a series of vectors (v) via a recurrent neural network.</s><s>The attention mechanism (φ) uses the hidden state of the decoder (h) and these vectors to determine how the encoded vectors should be combined to produce a context vector (c), which influences the next hidden state of the decoder and thus the next word in the translated sentence.</s></p></div></figDesc><graphic coords="10,83.14,69.99,429.36,217.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 4 |</head><label>4</label><figDesc><div><p><s>FIGURE 4 | Hard vs. soft visual attention in artificial neural networks.</s><s>(A) In hard attention, the network only gets input from a small portion of the whole image.</s><s>This portion is iteratively chosen by the network through an attention selection mechanism.</s><s>If the input is foveated, the network can use the lower resolution periphery to guide this selection.</s><s>(B) Feature maps in convolutional neural networks are 2-D grids of activation created by the application of a filter to the layer below.</s><s>In soft spatial attention, different locations on these grids are weighted differently.</s><s>In soft feature attention, different feature maps are weighted differently.</s></p></div></figDesc><graphic coords="12,112.64,69.24,369.60,229.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 5 |</head><label>5</label><figDesc><div><p><s>FIGURE 5 | An incomplete summary of the different types of attention studied in neuroscience/psychology and machine learning and how they relate.</s><s>On the left are divisions of attention studied biologically, on the right are those developed for artificial intelligence and machine learning.</s><s>Topics at the same horizontal location are to some extent analogous, with the distance between them indicating how close the analogy is.</s><s>Forms of visual attention, for example, have the most overlap and are the most directly comparable across biology and machine learning.</s><s>Some forms of attention, such as overall arousal, don't have an obvious artificial analogue.</s></p></div></figDesc><graphic coords="15,85.14,69.52,425.28,248.16" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p><s>Frontiers in Computational Neuroscience | www.frontiersin.org</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p><s>April 2020 | Volume 14 | Article 29</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The author would like to thank <rs type="person">Jacqueline Gottlieb</rs> and the three reviewers for their insights and pointers to references.</p></div>
			</div>
			<div type="funding">
<div><head>FUNDING</head><p>This work was supported by a <rs type="grantName">Marie Skłodowska-Curie Individual Fellowship</rs> (No. <rs type="grantNumber">844003</rs>) and a <rs type="grantName">Sainsbury Wellcome Centre/Gatsby Computational Unit Fellowship</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_xG5fAxQ">
					<idno type="grant-number">844003</idno>
					<orgName type="grant-name">Marie Skłodowska-Curie Individual Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_Kd4E3Y2">
					<orgName type="grant-name">Sainsbury Wellcome Centre/Gatsby Computational Unit Fellowship</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p><s>GL conceived and wrote the article and generated the figures.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest:</head><p><s>The author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</s></p><p><s>The reviewer MR declared a past co-authorship with the author GL to the handling Editor.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The spread of attention and learning in feature search: effects of target distribution and task difficulty</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ahissar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochstein</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0042-6989(00)00002-X</idno>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1349" to="1364" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How hippocampal memory shapes, and is shaped by, attention</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Hippocampus From Cells to Systems</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Hannula</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Duff</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="369" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Attention-dependent reductions in burstiness and action-potential height in macaque area V4</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3463</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1125" to="1131" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Andreoli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01289</idno>
		<title level="m">Convolution, attention and structure embedding</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attentional enhancement of spatial resolution: linking behavioural and neurophysiological evidence</title>
		<author>
			<persName><forename type="first">K</forename><surname>Anton-Erxleben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3443</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="188" to="200" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Independent effects of adaptation and attention on perceived speed</title>
		<author>
			<persName><forename type="first">K</forename><surname>Anton-Erxleben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797612449178</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="150" to="159" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tasks of a feather flock together: Similarity effects in task switching</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Arrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Altmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Carr</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196116</idno>
	</analytic>
	<monogr>
		<title level="j">Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="781" to="789" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Multiple object recognition with visual attention</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7755</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Global workspace theory of consciousness: toward a cognitive neuroscience of human experience</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Baars</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0079-6123(05)50004-9</idno>
	</analytic>
	<monogr>
		<title level="j">Prog. Brain Res</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="45" to="53" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2014.01.008</idno>
		<idno type="arXiv">arXiv:1409.0473</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="243" to="255" />
			<date type="published" when="2014">2014. 2014</date>
			<pubPlace>Bai, X., and Wang</pubPlace>
		</imprint>
	</monogr>
	<note>Saliency-SVM: an automatic approach for image segmentation</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Selective attention affects conceptual object priming and recognition: a study with young and older adults</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mayas</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.01567</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1567</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weakly supervised part-of-speech tagging using eye-tracking data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="579" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.08568</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>The consciousness prior. arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Competition between endogenous and exogenous orienting of visual attention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Henik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rafal</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.134.2.207</idno>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="207" to="221" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic visual bias of perceived auditory location</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bertelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aschersleben</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03208826</idno>
	</analytic>
	<monogr>
		<title level="j">Psychon. Bull. Rev</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="482" to="489" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A source for feature-based attention in the prefrontal cortex</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Bichot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Heard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Degennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.10.001</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="832" to="844" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A flexible readout mechanism of human sensory representations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-019-11448-7</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">State-of-the-art in visual attention modeling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2012.89</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="185" to="207" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.03581</idno>
		<title level="m">Cat2000: a large scale fixation dataset for boosting saliency research</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attentional stimulus selection through selective synchronization between monkey visual areas</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Bosman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Schoffelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Oostenveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bastos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Womelsdorf</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2012.06.037</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="875" to="888" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rubber hands &apos;feel&apos; touch that eyes see</title>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1038/35784</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="page" from="756" to="756" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The cocktail-party problem revisited: early processing and selection of multi-talker speech</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Bronkhorst</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-015-0882-9</idno>
	</analytic>
	<monogr>
		<title level="j">Attent. Percept. Psychophys</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="1465" to="1487" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Shifting attention into and out of objects: evaluating the processes underlying the object advantage</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Denney</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193918</idno>
	</analytic>
	<monogr>
		<title level="j">Percept. Psychophys</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="606" to="618" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Saliency, attention, and visual search: an information theoretic approach</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
		<idno type="DOI">10.1167/9.3.5</idno>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Serial, covert shifts of attention during visual search are reflected by the frontal eye fields and correlated with population oscillations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Buschman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2009.06.020</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="386" to="396" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Past rewards capture spatial attention and action choices</title>
		<author>
			<persName><forename type="first">E</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Husain</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00221-013-3654-6</idno>
	</analytic>
	<monogr>
		<title level="j">Exp. Brain Res</title>
		<imprint>
			<biblScope unit="volume">230</biblScope>
			<biblScope unit="page" from="291" to="300" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Look and think twice: Capturing top-down visual attention with feedback convolutional neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision<address><addrLine>Santiago, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2956" to="2964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Normalization as a canonical neural computation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3136</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An attentive survey of attention models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Polatkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mithal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02874</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">ABC-CNN: an attention based convolutional neural network for visual question answering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05960</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">SCA-CNN: Spatial and channel-wise attention in convolutional networks for image captioning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.667</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Honolulu, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5659" to="5667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Object-based attention: a tutorial review</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-012-0322-z</idno>
	</analytic>
	<monogr>
		<title level="j">Attent. Percept. Psychophys</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="784" to="802" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Long short-term memory-networks for machine reading</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1053</idno>
		<idno type="arXiv">arXiv:1601.06733</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">What and where: a bayesian inference theory of attention</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chikkerur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2010.05.013</idno>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="2233" to="2247" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Describing multimedia content using attention-based encoder-decoder networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMM.2015.2477044</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimed</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1875" to="1886" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A taxonomy of external and internal attention</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Golomb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.093008.100427</idno>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="73" to="101" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Contextual cueing: implicit learning and memory of visual context guides spatial attention</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1006/cogp.1998.0681</idno>
	</analytic>
	<monogr>
		<title level="j">Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="28" to="71" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Top-down and bottom-up attention to memory: a hypothesis (atom) on the role of the posterior parietal cortex in memory retrieval</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ciaramelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2008.03.022</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1828" to="1851" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Neuronal phenomena associated with vigilance and consciousness: from cellular mechanisms to electroencephalographic patterns</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Coenen</surname></persName>
		</author>
		<idno type="DOI">10.1006/ccog.1997.0324</idno>
	</analytic>
	<monogr>
		<title level="j">Conscious. Cogn</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="42" to="53" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">On the relationship between self-attention and convolutional layers</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Cordonnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loukas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03584</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modulating early visual processing by language</title>
		<author>
			<persName><forename type="first">H</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6594" to="6604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A neurodynamical cortical model of visual attention and invariant object recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Rolls</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2003.09.037</idno>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="621" to="642" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neurodynamics of biased competition and cooperation for attention: a model with spiking neurons</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Rolls</surname></persName>
		</author>
		<idno type="DOI">10.1152/jn.01095.2004</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="295" to="313" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visual attention mediated by biased competition in extrastriate visual cortex</title>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.1998.0280</idno>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. R. Soc. Lond. Ser. B Biol. Sci</title>
		<imprint>
			<biblScope unit="volume">353</biblScope>
			<biblScope unit="page" from="1245" to="1255" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cognitive, endocrine and mechanistic perspectives on non-linear relationships between arousal and brain function</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Diamond</surname></persName>
		</author>
		<idno type="DOI">10.2201/nonlin.003.01.001</idno>
	</analytic>
	<monogr>
		<title level="j">Nonlinearity Biolo Toxicol Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A selective review of selective attention research from the past century</title>
		<author>
			<persName><forename type="first">J</forename><surname>Driver</surname></persName>
		</author>
		<idno type="DOI">10.1348/000712601162103</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Psychol</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="53" to="78" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Saccader: improving accuracy of hard attention models for vision</title>
		<author>
			<persName><forename type="first">G</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="700" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Multi-way, multilingual neural machine translation with a shared attention mechanism</title>
		<author>
			<persName><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1101</idno>
		<idno type="arXiv">arXiv:1601.01073</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Using human brain activity to guide machine learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-018-23618-6</idno>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">5397</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The effects of visual stimulation and selective visual attention on rhythmic neuronal synchronization in macaque area v4</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Womelsdorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Oostenveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.4499-07.2008</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="4823" to="4835" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The negative priming paradigm: an update and implications for selective attention</title>
		<author>
			<persName><forename type="first">C</forename><surname>Frings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-015-0841-4</idno>
	</analytic>
	<monogr>
		<title level="j">Psychon. Bull. Rev</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1577" to="1597" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Auditory attention-focusing the searchlight on sound</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elhilali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2007.07.011</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="437" to="455" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Look closer to see better: recurrent attention convolutional neural network for fine-grained image recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Honolulu, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4438" to="4446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Attention, please! a critical review of neural attention models in natural language processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torroni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.02181</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Attention and recollective experience in recognition memory</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gardiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Parkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="579" to="583" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Attention control: explorations of the work of an executive controller</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gopher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Brain Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="23" to="38" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The nose smells what the eye sees: crossmodal visual facilitation of human olfactory perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gottfried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0896-6273(03)00392-1</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="375" to="386" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Informationseeking, curiosity, and attention: computational and neural mechanisms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gottlieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baranes</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.09.001</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="585" to="593" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Combined effects of spatial and feature-based attention on responses of v4 neurons</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Hayden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Gallant</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2008.06.011</idno>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1182" to="1187" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Eye movements in natural behavior</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hayhoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ballard</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2005.02.009</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="188" to="194" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Attention, spatial representation, and visual neglect: simulating emergent attention and spatial memory in the selective attention for identification model (SAIM)</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.110.1.29</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="29" to="87" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Computational models of visual selective attention: a review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203647110</idno>
	</analytic>
	<monogr>
		<title level="j">Connect. Models Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="273" to="312" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">No one knows what attention is</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hommel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cisek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Neyedli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Welsh</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-019-01846-w</idno>
	</analytic>
	<monogr>
		<title level="j">Attent. Percept. Psychophys</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="2288" to="2303" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Salt Lake City, UT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Why is there so much more research on vision than on any other sensory modality?</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutmacher</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2019.02246</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2246</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Bayesian surprise attracts human attention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="547" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Computational modelling of visual attention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<idno type="DOI">10.1038/35058500</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="194" to="203" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Visual novelty, curiosity, and intrinsic reward in machine learning and the brain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaegle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mehrpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rust</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2019.08.004</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="167" to="174" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10186</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Attention is not explanation. arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The physiology and psychology of selective attention to touch</title>
		<author>
			<persName><forename type="first">H</forename><surname>Johansen-Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Lloyd</surname></persName>
		</author>
		<idno type="DOI">10.2741/A558</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Biosci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="894" to="D904" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Functional brain development in humans</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1038/35081509</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="475" to="483" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Visual attention: insights from brain imaging</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wojciulik</surname></persName>
		</author>
		<idno type="DOI">10.1038/35039043</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">The challenges of joint attention</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<idno type="DOI">10.1075/is.7.2.04kap</idno>
	</analytic>
	<monogr>
		<title level="j">Interact. Stud</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="135" to="169" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Attention and olfactory consciousness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Keller</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2011.00380</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">380</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Learning to attend: effects of practice on information selection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yantis</surname></persName>
		</author>
		<idno type="DOI">10.1167/9.7.16</idno>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Neural correlates of learning to attend</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yantis</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2010.00216</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Hum. Neurosci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">216</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Social attention and the brain</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Shepherd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Platt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2009.08.010</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="958" to="R962" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Superior colliculus and visual spatial attention</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Krauzlis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Lovejoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zénon</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-neuro-062012-170249</idno>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="165" to="182" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">The distinct modes of vision offered by feedforward and recurrent processing</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Lamme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0166-2236(00)01657-X</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Neurosci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="571" to="579" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Non-uniform image compression using biologically motivated saliency map model</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Intelligent Sensors, Sensor Networks and Information Processing Conference</title>
		<meeting>the 2004 Intelligent Sensors, Sensor Networks and Information Processing Conference<address><addrLine>Melbourne, VIC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="525" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Hierarchical bayesian inference in the visual cortex</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<idno type="DOI">10.1364/JOSAA.20.001434</idno>
	</analytic>
	<monogr>
		<title level="j">JOSA A</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1434" to="1448" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Multi-task learning by a top-down control network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03335</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06635</idno>
		<title level="m">Conditional computation for continual learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Convolutional neural networks as a model of the visual system: past, present, and future</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lindsay</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_01544</idno>
	</analytic>
	<monogr>
		<title level="j">J. Cogn. Neurosci</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Epub ahead of print</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">How biological attention mechanisms improve task performance in a large-scale visual system model</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.38105</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">38105</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A simple circuit model of visual cortex explains neural and behavioral aspects of attention</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1101/2019.12.13.875534</idno>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Linsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shiebler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08819</idno>
		<title level="m">Learning what and where to attend</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Cortical mechanisms of feature-based attentional control</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Slotnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Serences</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yantis</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhg080</idno>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1334" to="1343" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Exploring the role of attention during memory retrieval: effects of semantic encoding and divided attention</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lozito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Mulligan</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193246</idno>
	</analytic>
	<monogr>
		<title level="j">Mem. Cogn</title>
		<imprint>
			<biblScope unit="page" from="986" to="998" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Neural mechanisms of spatial selective attention in areas V1, V2, and V4 of macaque visual cortex</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chelazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hillyard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<idno type="DOI">10.1152/jn.1997.77.1.24</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="24" to="42" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">The costs and benefits of goaldirected attention in deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Roads</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02342</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.04025</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Awareness during drowsiness: dynamics and electrophysiological correlates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Makeig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-P</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0087346</idno>
	</analytic>
	<monogr>
		<title level="j">Can. J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="266" to="273" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Mancas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Ferrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Taylor</surname></persName>
		</author>
		<title level="m">From Human Attention to Computational Attention</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Attentive singletasking of multiple tasks</title>
		<author>
			<persName><forename type="first">K.-K</forename><surname>Maninis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2019.00195</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1851" to="1860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Neural mechanisms of attending to items in working memory</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zokaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Fallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vogels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Husain</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2019.03.017</idno>
	</analytic>
	<monogr>
		<title level="j">Neurosci. Biobehav. Rev</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Attention and the detectability of weak taste stimuli</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Wheeler</surname></persName>
		</author>
		<idno type="DOI">10.1093/chemse/23.1.19</idno>
	</analytic>
	<monogr>
		<title level="j">Chem. Senses</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Neuronal mechanisms of visual attention</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Maunsell</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-vision-082114-035431</idno>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="373" to="391" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Neural mechanisms for the executive control of attention</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Buschman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Oxford Handbook of Attention</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Nobre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Kastner</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Introducing a bayesian model of selective attention based on active inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Parr</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-019-50138-8</idno>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">13915</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Differential attentiondependent response modulation across cell classes in macaque visual area v4</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Sundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2007.06.018</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="131" to="141" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Recurrent models of visual attention</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, QC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2204" to="2212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Visuomotor origins of covert spatial attention</title>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fallah</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0896-6273(03)00716-5</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="671" to="683" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">The costs of crossing paths and switching tasks between audition and vision</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Santis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Wylie</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bandc.2008.05.004</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Cogn</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="47" to="55" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">What is remembered? Role of attention on the encoding and retrieval of hippocampal representations</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Muzzio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kentros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kandel</surname></persName>
		</author>
		<idno type="DOI">10.1113/jphysiol.2009.172445</idno>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">587</biblScope>
			<biblScope unit="page" from="2837" to="2854" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Attention in language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Myachykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiology of Attention</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Rees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="324" to="329" />
			<date type="published" when="2005">2005</date>
			<publisher>Elsevier</publisher>
			<pubPlace>Burlington, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Topdown control of visual attention</title>
		<author>
			<persName><forename type="first">B</forename><surname>Noudoost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Steinmetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2010.02.003</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">fMRI evidence for objects as the units of attentional selection</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>O'craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Downing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<idno type="DOI">10.1038/44134</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="page" from="584" to="587" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Vigilance, alertness, or sustained attention: physiological basis and measurement</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Oken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Salinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elsas</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.clinph.2006.01.017</idno>
	</analytic>
	<monogr>
		<title level="j">Clin. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="1885" to="1901" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">On the difference between working memory and attentional set</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Olivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eimer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2010.11.033</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1553" to="1558" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Top-down control of visual attention by the prefrontal cortex. Functional specialization and long-range interactions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Paneri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Gregoriou</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2017.00545</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">545</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Task switching and multitask performance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
		<idno type="DOI">10.1002/acp.849</idno>
	</analytic>
	<monogr>
		<title level="m">Control of Cognitive Processes: Attention and Performance XVIII</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Monsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Driver</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">277</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">How do attention and adaptation affect contrast sensitivity?</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pestilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Viera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
		<idno type="DOI">10.1167/7.7.9</idno>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">SLAM: a connectionist model for attention in visual selection tasks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Phaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Heijden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Hudson</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(90)90006-P</idno>
	</analytic>
	<monogr>
		<title level="j">Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="273" to="341" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">The neural correlates of motor skill automaticity</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Sabb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Foerde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Asarnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Bookheimer</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.3880-04.2005</idno>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="5356" to="5364" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Measuring alertness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Posner</surname></persName>
		</author>
		<idno type="DOI">10.1196/annals.1417.011</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. N. Y. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">1129</biblScope>
			<biblScope unit="page" from="193" to="199" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Holistic reinforcement learning: the role of structure and attention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ballard</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2019.01.010</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="278" to="292" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Bayesian inference and attentional modulation in the visual cortex</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Rao</surname></persName>
		</author>
		<idno type="DOI">10.1097/01.wnr.0000183900.92901.fc</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroreport</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1843" to="1848" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Learning multiple visual domains with residual adapters</title>
		<author>
			<persName><forename type="first">S.-A</forename><surname>Rebuffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="506" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">End-to-end instance segmentation with recurrent attention</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6656" to="6664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">The development of attention systems and working memory in infancy</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Romano</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnsys.2016.00015</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Syst. Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">The normalization model of attention</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2009.01.002</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="168" to="185" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Reorienting attention across the horizontal and vertical meridians: evidence in favor of a premotor theory of attention</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Riggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dascola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Umiltá</surname></persName>
		</author>
		<idno type="DOI">10.1016/0028-3932(87)90041-8</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Incremental grouping of image elements in vision</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Houtkamp</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-011-0200-0</idno>
	</analytic>
	<monogr>
		<title level="j">Attent. Percept. Psychophys</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="2542" to="2572" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Object-based attention in the primary visual cortex of the macaque monkey</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Lamme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Spekreijse</surname></persName>
		</author>
		<idno type="DOI">10.1038/26475</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">395</biblScope>
			<biblScope unit="page" from="376" to="381" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Feature-specific effects of selective visual attention</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Paradiso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-015-0816-y</idno>
		<idno>doi: 10.1007/s11263-015-0816-y</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="1995">1995. 2015</date>
		</imprint>
	</monogr>
	<note>Vis. Res.</note>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">The pulvinar regulates information transmission between cortical areas based on attention demands</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Saalmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pinsk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kastner</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1223082</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">337</biblScope>
			<biblScope unit="page" from="753" to="756" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Global effects of feature-based attention in human visual cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Buracas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Boynton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn876</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="631" to="632" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Cholinergic modulation promotes attentional modulation in primary visual cortex-a modeling study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sajedin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Menhaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-H</forename><surname>Vahabie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panzeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Esteky</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-019-56608-3</idno>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">20186</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Functional neuroanatomy of the noradrenergic locus coeruleus: its roles in the regulation of arousal and autonomic function part i: principles of functional organisation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Samuels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Szabadi</surname></persName>
		</author>
		<idno type="DOI">10.2174/157015908785777229</idno>
	</analytic>
	<monogr>
		<title level="j">Curr. Neuropharmacol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="235" to="253" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Feature-based attentional modulation of orientation perception in somatosensation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Schweisfurth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schweizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Treue</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2014.00519</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Hum. Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">519</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">The attentional blink</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Arnell</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1364-6613(97)01094-2</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="291" to="296" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Action recognition using visual attention</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.04119</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">The expected value of control: an integrative theory of anterior cingulate cortex function</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2013.07.007</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="217" to="240" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">The brain circuitry of attention</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shipp</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2004.03.004</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="223" to="230" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Early, involuntary top-down guidance of attention from working memory</title>
		<author>
			<persName><forename type="first">D</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Blanco</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.31.2.248</idno>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Hum. Percept. Perform</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="248" to="261" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Automatic guidance of attention from working memory</title>
		<author>
			<persName><forename type="first">D</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hodsoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rotshtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2008.05.007</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="342" to="348" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Explaining the colavita visual dominance effect</title>
		<author>
			<persName><forename type="first">C</forename><surname>Spence</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0079-6123(09)17615-X</idno>
	</analytic>
	<monogr>
		<title level="j">Prog. Brain Res</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="245" to="258" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Driver</surname></persName>
		</author>
		<title level="m">Crossmodal Space and Crossmodal Attention</title>
		<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Subcortical connectivity correlates selectively with attention&apos;s effects on spatial choice bias</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sreenivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sridharan</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1902704116</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="19711" to="19716" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Deep networks with internal selective attention through feedback connections</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Stollenga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, QC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3545" to="3553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Strezoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2019.00146</idno>
		<idno type="arXiv">arXiv:1903.12117</idno>
		<title level="m">Many task learning with task routing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Visual correlates of fixation selection: effects of scale and time</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Tatler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Baddeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Gilchrist</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2004.09.017</idno>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="643" to="659" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Toneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wehbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="14928" to="14938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Automaticity and preattentive processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hayes</surname></persName>
		</author>
		<idno type="DOI">10.2307/1423032</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Psychol</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="341" to="362" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Feature-based attention influences motion processing gain in macaque visual cortex</title>
		<author>
			<persName><forename type="first">S</forename><surname>Treue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C M</forename><surname>Trujillo</surname></persName>
		</author>
		<idno type="DOI">10.1038/21176</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">399</biblScope>
			<biblScope unit="page">575</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">The automaticity of visual statistical learning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Jungé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Scholl</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.134.4.552</idno>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="552" to="564" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Effects of divided attention on fmri correlates of memory encoding</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Uncapher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Rugg</surname></persName>
		</author>
		<idno type="DOI">10.1162/089892905775008616</idno>
	</analytic>
	<monogr>
		<title level="j">J. Cogn. Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1923" to="1935" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">The effects of salience on saccadic target selection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Van Zoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Donk</surname></persName>
		</author>
		<idno type="DOI">10.1080/13506280444000229</idno>
	</analytic>
	<monogr>
		<title level="j">Vis. Cogn</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="353" to="375" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Parietal lobe contributions to episodic memory retrieval</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Buckner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2005.07.001</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="445" to="453" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Attentional neural network: Feature selection using cognitive feedback</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, QC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2033" to="2041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Is subliminal learning really passive?</title>
		<author>
			<persName><forename type="first">W</forename><surname>Watanabe</surname></persName>
		</author>
		<idno type="DOI">10.1038/422036a</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">422</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pinter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.04626</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Attention is not not explanation. arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Non-homogeneous contentdriven video-retargeting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guttmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE 11th International Conference on Computer Vision</title>
		<meeting><address><addrLine>Rio de Janeiro</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">What attributes guide the deployment of visual attention and how do they do it?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Horowitz</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn1411</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="495" to="501" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Psychostimulants and cognition: a continuum of behavioral and cognitive activation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Anagnostaras</surname></persName>
		</author>
		<idno type="DOI">10.1124/pr.112.007054</idno>
	</analytic>
	<monogr>
		<title level="j">Pharmacol. Rev</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="193" to="221" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Early recurrent feedback facilitates visual object recognition under challenging conditions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wyatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Jilk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00674</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">674</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Ask, attend and answer: exploring question-guided spatial attention for visual question answering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="451" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Stacked attention networks for image question answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title level="m" type="main">Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Zelinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.11921</idno>
		<title level="m">Predicting goal-directed attention control using inverse-reinforcement learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>arXiv [preprint</note>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">A modulation module for multi-task learning with applications in image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV) (Munich)</title>
		<meeting>the European Conference on Computer Vision (ECCV) (Munich)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="401" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Feature-based attention in the frontal eye field and area V4 during visual search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2011.04.032</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1205" to="1217" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Pulvinar-cortex interactions in vision and attention</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.11.034</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="209" to="220" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
