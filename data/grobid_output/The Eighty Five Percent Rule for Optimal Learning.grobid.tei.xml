<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Eighty Five Percent Rule for optimal learning</title>
				<funder ref="#_9TjY3cr">
					<orgName type="full">John Templeton Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Science and Business Media LLC</publisher>
				<availability status="unknown"><p>Copyright Springer Science and Business Media LLC</p>
				</availability>
				<date type="published" when="2019-11-05">2019-11-05</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Cognitive Science Program</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amitai</forename><surname>Shenhav</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Cognitive, Linguistic, &amp; Psychological Sciences</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Brown Institute for Brain Science</orgName>
								<orgName type="institution" key="instit2">Brown University</orgName>
								<address>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Straccia</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">UCLA</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Princeton Neuroscience Institute</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Eighty Five Percent Rule for optimal learning</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Nature Communications</title>
						<title level="j" type="abbrev">Nat Commun</title>
						<idno type="eISSN">2041-1723</idno>
						<imprint>
							<publisher>Springer Science and Business Media LLC</publisher>
							<biblScope unit="volume">10</biblScope>
							<biblScope unit="issue">1</biblScope>
							<date type="published" when="2019-11-05" />
						</imprint>
					</monogr>
					<idno type="MD5">C00DF792A8595F44BDA98E934D569E20</idno>
					<idno type="DOI">10.1038/s41467-019-12552-4</idno>
					<note type="submission">Received: 14 February 2018; Accepted: 2 September 2019;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-04-21T20:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>Researchers and educators have long wrestled with the question of how best to teach their clients be they humans, non-human animals or machines.</s><s>Here, we examine the role of a single variable, the difficulty of training, on the rate of learning.</s><s>In many situations we find that there is a sweet spot in which training is neither too easy nor too hard, and where learning progresses most quickly.</s><s>We derive conditions for this sweet spot for a broad class of learning algorithms in the context of binary classification tasks.</s><s>For all of these stochastic gradient-descent based learning algorithms, we find that the optimal error rate for training is around 15.87% or, conversely, that the optimal training accuracy is about 85%.</s><s>We demonstrate the efficacy of this 'Eighty Five Percent Rule' for artificial neural networks used in AI and biologically plausible neural networks thought to describe animal learning.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W</head><p><s>hen we learn something new, like a language or musical instrument, we often seek challenges at the edge of our competence-not so hard that we are discouraged, but not so easy that we get bored.</s><s>This simple intuition, that there is a sweet spot of difficulty, a 'Goldilocks zone' <ref type="bibr" target="#b0">1</ref> , for motivation and learning is at the heart of modern teaching methods <ref type="bibr" target="#b1">2</ref> and is thought to account for differences in infant attention between more and less learnable stimuli <ref type="bibr" target="#b0">1</ref> .</s><s>In the animal learning literature it is the intuition behind shaping <ref type="bibr" target="#b2">3</ref> and fading <ref type="bibr" target="#b3">4</ref> , whereby complex tasks are taught by steadily increasing the difficulty of a training task.</s><s>It is also observable in the nearly universal 'levels' feature in video games, in which the player is encouraged, or even forced, to a higher level of difficulty once a performance criterion has been achieved.</s><s>Similarly in machine learning, steadily increasing the difficulty of training has proven useful for teaching large scale neural networks in a variety of tasks <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6</ref> , where it is known as 'Curriculum Learning' <ref type="bibr" target="#b6">7</ref> and 'Self-Paced Learning' <ref type="bibr" target="#b7">8</ref> .</s></p><p><s>Despite this long history of empirical results, it is unclear why a particular difficulty level may be beneficial for learning nor what that optimal level might be.</s><s>In this paper we address this issue of optimal training difficulty for a broad class of learning algorithms in the context of binary classification tasks, in which ambiguous stimuli must be classified into one of two classes (e.g., cat or dog).</s></p><p><s>In particular, we focus on the class of stochastic gradientdescent based learning algorithms.</s><s>In these algorithms, parameters of the model (e.g., the weights in a neural network) are adjusted based on feedback in such a way as to reduce the average error rate over time <ref type="bibr" target="#b8">9</ref> .</s><s>That is, these algorithms descend the gradient of error rate as a function of model parameters.</s><s>Such gradient-descent learning forms the basis of many algorithms in AI, from single-layer perceptrons to deep neural networks <ref type="bibr" target="#b9">10</ref> , and provides a quantitative description of human and animal learning in a variety of situations, from perception <ref type="bibr" target="#b10">11</ref> , to motor control <ref type="bibr" target="#b11">12</ref> to reinforcement learning <ref type="bibr" target="#b12">13</ref> .</s><s>For these algorithms, we provide a general result for the optimal difficulty in terms of a target error rate for training.</s><s>Under the assumption of a Gaussian noise process underlying the errors, this optimal error rate is around 15.87%, a number that varies slightly depending on the noise in the learning process.</s><s>That is the optimal accuracy for training is around 85%.</s><s>We show theoretically that training at this optimal difficulty can lead to exponential improvements in the rate of learning.</s><s>Finally, we demonstrate the applicability of the Eighty Five Percent Rule to artificial one-and two-layer neural networks <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14</ref> , and a model from computational neuroscience that is thought to describe human and animal perceptual learning <ref type="bibr" target="#b10">11</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p><s>Optimal training difficulty for binary classification tasks.</s><s>In a standard binary classification task, an animal or machine 'agent' makes binary decisions about simple stimuli.</s><s>For example, in the classic Random Dot Motion paradigm from Psychology and Neuroscience <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16</ref> , stimuli consist of a patch of moving dotsmost moving randomly but a small fraction moving coherently either to the left or the right-and participants must decide in which direction the coherent dots are moving.</s><s>A major factor in determining the difficulty of this perceptual decision is the fraction of coherently moving dots, which can be manipulated by the experimenter to achieve a fixed error rate during training using a procedure known as 'staircasing' <ref type="bibr" target="#b16">17</ref> .</s></p><p><s>We assume that agents make their decision on the basis of a scalar, subjective decision variable, h, which is computed from a stimulus that can be represented as a vector x (e.g., the direction of motion of all dots)</s></p><formula xml:id="formula_0">h ¼ Φðx; ϕÞ ð<label>1Þ</label></formula><p><s>where Φ(⋅) is a function of the stimulus and (tunable) parameters ϕ.</s><s>We assume that this transformation of stimulus x into the subjective decision variable h yields a noisy representation of the true decision variable, Δ (e.g., the fraction of dots moving left).</s></p><p><s>That is, we write</s></p><formula xml:id="formula_1">h ¼ Δ þ n<label>ð2Þ</label></formula><p><s>where the noise, n, arises due to the imperfect representation of the decision variable.</s><s>We further assume that this noise, n, is random and sampled from a zero-mean Gaussian distribution with standard deviation σ (Fig. <ref type="figure" target="#fig_0">1a</ref>).</s></p><p><s>If the decision boundary is set to 0, such that the model chooses option A when h &gt; 0, option B when h &lt; 0 and randomly when h = 0, then the noise in the representation of the decision variable leads to errors with probability</s></p><formula xml:id="formula_2">ER ¼ Z 0 À1 pðhjΔ; σÞdh ¼ FðÀΔ=σÞ ¼ FðÀβΔÞ<label>ð3Þ</label></formula><p><s>where F(x) is the cumulative density function of the standardized noise distribution, p(x) = p(x|0, 1), and β = 1/σ quantifies the precision of the representation of Δ and the agent's skill at the task.</s><s>As shown in Fig. <ref type="figure" target="#fig_0">1b</ref>, this error rate decreases as the decision gets easier (Δ increases) and as the agent becomes more accomplished at the task (β increases).</s></p><p><s>The goal of learning is to tune the parameters ϕ such that the subjective decision variable, h, is a better reflection of the true decision variable, Δ.</s><s>That is, the model should aim to adjust the parameters ϕ so as to decrease the magnitude of the noise σ or, equivalently, increase the precision β.</s><s>One way to achieve this tuning is to adjust the parameters using gradient descent on the error rate, i.e. changing the parameters over time t according to</s></p><formula xml:id="formula_3">dϕ dt ¼ Àη∇ ϕ ER<label>ð4Þ</label></formula><p><s>where η is the learning rate and ∇ϕER is the derivative of the error rate with respect to parameters ϕ.</s><s>This gradient can be b The error rate as a function of difficulty before and after learning.</s><s>c The derivative that determines the rate of learning as a function of difficulty before and after learning showing that the optimal difficulty for learning is lower after learning than before.</s><s>d The same derivative as in c re-plotted as a function of error rate showing that the optimal error rate (at 15.87% or ~85% accuracy) is the same both before and after learning written in terms of the precision, β, as</s></p><formula xml:id="formula_4">∇ ϕ ER ¼ ∂ER ∂β ∇ ϕ β<label>ð5Þ</label></formula><p><s>Note here that only the first term on the right hand side of Eq. ( <ref type="formula" target="#formula_4">5</ref>) depends on the difficulty Δ, while the second describes how the precision changes with ϕ.</s><s>Note also that Δ itself, as the 'true' decision variable, is independent of ϕ.</s><s>This means that the optimal difficulty for training, that maximizes the change in the parameters, ϕ, at this time point, is the value of the decision variable Δ * that maximizes ∂ER/∂β.</s><s>Of course, this analysis ignores the effect of changing ϕ on the form of the noise-instead assuming that it only changes the scale factor, β, an assumption that likely holds in the relatively simple cases we consider here, although whether it holds in more complex cases will be an important question for future work.</s></p><p><s>In terms of the decision variable, the optimal difficulty changes as a function of precision (Fig. <ref type="figure" target="#fig_0">1c</ref>) meaning that the difficulty of training must be adjusted online according to the skill of the agent.</s><s>Using the monotonic relationship between Δ and ER (Fig. <ref type="figure" target="#fig_0">1b</ref>) it is possible to express the optimal difficulty in terms of the error rate, ER * (Fig. <ref type="figure" target="#fig_0">1d</ref>).</s><s>Expressed this way, the optimal difficulty is constant as a function of precision, meaning that optimal learning can be achieved by clamping the error rate during training at a fixed value, which, for Gaussian noise is</s></p><formula xml:id="formula_5">ER Ã ¼ 1 2 1 À erf 1 ffiffi ffi 2 p % 0:1587<label>ð6Þ</label></formula><p><s>That is, the optimal error rate for learning is 15.87%, and the optimal accuracy is around 85%.</s><s>We call this the Eighty Five Percent Rule for optimal learning.</s></p><p><s>Dynamics of learning.</s><s>While the previous analysis allows us to calculate the error rate that maximizes the rate of learning, it does not tell us how much faster learning occurs at this optimal error rate.</s><s>In this section we address this question by comparing learning at the optimal error rate with learning at a fixed error rate, ER f (which may be suboptimal), and, alternatively, a fixed difficulty, Δ f .</s><s>If stimuli are presented one at a time (i.e., not batch learning), in both cases, gradient-descent based updating of the parameters, ϕ, (Eq.</s><s>( <ref type="formula" target="#formula_3">4</ref>)) implies that the precision β evolves in a similar manner, i.e..</s></p><formula xml:id="formula_6">dβ dt ¼ Àη ∂ER ∂β<label>ð7Þ</label></formula><p><s>For fixed error rate, ER f , as shown in the Methods, integrating Eq. ( <ref type="formula" target="#formula_6">7</ref>) gives</s></p><formula xml:id="formula_7">βðtÞ ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi β 2 0 þ 2ηK f ðt À t 0 Þ q<label>ð8Þ</label></formula><p><s>where t 0 is the initial time point, β 0 is the initial value of β and K f is the following function of the training error rate</s></p><formula xml:id="formula_8">K f ¼ ÀF À1 ðER f ÞpðF À1 ðER f ÞÞ<label>ð9Þ</label></formula><p><s>Thus, for fixed training error rate the precision grows as the square root of time with the exact rate determined by K f which depends on both the training error rate and the noise distribution.</s></p><p><s>For fixed decision variable, Δ f , integrating Eq. ( <ref type="formula" target="#formula_6">7</ref>) is more difficult and the solution depends more strongly on the distribution of the noise.</s><s>In the case of Gaussian noise, there is no closed form solution for β.</s><s>However, as shown in the Methods, an approximate form can be derived at long times where we find that β grows as</s></p><formula xml:id="formula_9">βðtÞ / ffiffiffiffiffiffiffiffi ffi log t p<label>ð10Þ</label></formula><p><s>i.e., exponentially slower than Eq.</s><s>(38).</s></p><p><s>Simulations.</s><s>To demonstrate the applicability of the Eighty Five Percent Rule we simulated the effect of training accuracy on learning in three cases, two from AI and one from computational neuroscience.</s><s>From AI we consider how training at 85% accuracy impacts learning in the the simple case of a one-layer Perceptron <ref type="bibr" target="#b13">14</ref> with artificial stimuli, and in the more complex case of a two-layer neural network <ref type="bibr" target="#b8">9</ref> with stimuli drawn from the MNIST (Modified National Institute of Standards and Technology) dataset of handwritten digits <ref type="bibr" target="#b17">18</ref> .</s><s>From computational neuroscience we consider the model of Law and Gold <ref type="bibr" target="#b10">11</ref> , that accounts for both the behavior and neural firing properties of monkeys learning the Random Dot Motion task.</s><s>In all cases we see that learning is maximized when training occurs at 85% accuracy.</s></p><p><s>Perceptron with artificial stimuli.</s><s>The Perceptron is a classic one-layer neural network model that learns to map multidimensional stimuli x onto binary labels, y via a linear threshold process <ref type="bibr" target="#b13">14</ref> .</s><s>To implement this mapping, the Perceptron first computes the decision variable h as</s></p><formula xml:id="formula_10">h ¼ w Á x<label>ð11Þ</label></formula><p><s>where w are the weights of the network, and then assigns the label according to</s></p><formula xml:id="formula_11">y ¼ 1 h &gt; 0 0 h 0<label>ð12Þ</label></formula><p><s>The weights, w, which constitute the parameters of the model, are updated based on feedback about the true label t by a the learning rule,</s></p><formula xml:id="formula_12">w w þ ðt À yÞx<label>ð13Þ</label></formula><p><s>This learning rule implies that the Perceptron only updates its weights when the predicted label y does not match the actual label t-that is, the Perceptron only learns when it makes mistakes.</s><s>Naively then, one might expect that optimal learning would involve maximizing the error rate.</s><s>However, because Eq. ( <ref type="formula" target="#formula_12">13</ref>) is closely related (albeit not identical) to a gradient descent based rule (e.g., Chapter 39 in ref. <ref type="bibr" target="#b18">19</ref> ), the analysis of the previous sections applies and the optimal error rate for training is 15.87%.</s></p><p><s>To test this prediction we simulated the Perceptron learning rule for a range of training error rates between 0.01 and 0.5 in steps of 0.01 (1000 simulations per error rate, 1000 trials per simulation).</s><s>Error rate was kept constant by varying the difficulty, and the degree of learning was captured by the precision β (see Methods).</s><s>As predicted by the theory, the network learns most effectively when trained at the optimal error rate (Fig. <ref type="figure" target="#fig_1">2a</ref>) and the dynamics of learning are well described, up to a scale factor, by Eq. ( <ref type="formula" target="#formula_37">38</ref>) (Fig. <ref type="figure" target="#fig_1">2b</ref>).</s><s>Two-layer network with MNIST stimuli.</s><s>As a more demanding test of the Eighty Five Percent Rule, we consider the case of a twolayer neural network applied to more realistic stimuli from the Modified National Institute of Standards and Technology (MNIST) dataset of handwritten digits <ref type="bibr" target="#b17">18</ref> .</s><s>The MNIST dataset is a labeled dataset of 70,000 images of handwritten digits (0 through 9) that has been widely used as a test of image classification algorithms (see ref. <ref type="bibr" target="#b19">20</ref> for a list).</s><s>The dataset is broken down into a training set consistent of 60,000 images and a test set of 10,000 images.</s><s>To create binary classification tasks based on these images, we trained the network to classify the images according to either the parity (odd or even) or magnitude (less than 5 or not) of the number.</s></p><p><s>The network itself consisted of 1 input layer, with 400 units corresponding to the pixel values in the images, 1 hidden layer, with 50 neurons, and one output unit.</s><s>Unlike the Perceptron, activity of the output unit was graded and was determined by a sigmoid function of the decision variable, h</s></p><formula xml:id="formula_13">y ¼ 1 1 þ exp h ð Þ ¼ SðhÞ<label>ð14Þ</label></formula><p><s>where the decision variable was given by</s></p><formula xml:id="formula_14">h ¼ w 2 Á a<label>ð15Þ</label></formula><p><s>where w 2 were the weights connecting the hidden layer to the output units and a was the activity in the hidden layer.</s><s>This hidden-layer activity was also determined by a sigmoidal function</s></p><formula xml:id="formula_15">a ¼ Sðw 1 Á xÞ ð<label>16Þ</label></formula><p><s>where the inputs, x, corresponds to the pixel values in the image and w 1 were the weights from the input layer to the hidden layer.</s><s>All weights were trained using the Backpropagation algorithm 9 which takes the error,</s></p><formula xml:id="formula_16">e ¼ t À y<label>ð17Þ</label></formula><p><s>and propagates it backwards through the network, from output to input stage, as a teaching signal for the weights.</s><s>This algorithm implements stochastic gradient descent and, if our assumptions are met, should optimize learning at a training accuracy of 85%.</s></p><p><s>To test this prediction we trained the two-layer network for 5000 trials to perform either the Parity or the Magnitude Task while clamping the training error rate between 5 and 30% (Fig. <ref type="figure" target="#fig_2">3</ref>).</s><s>After training, performance was assessed on the entire test set and the whole process was repeated 1000 times for each task.</s><s>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, training error rate has a relatively large effect on test accuracy, around 10% between the best and worse training accuracies.</s><s>Moreover, for both tasks, the optimal training occurs at 85% training accuracy.</s><s>This suggests that the 85% rule holds even for learning of more realistic stimuli, by more complex multi-layered networks.</s></p><p><s>Biologically plausible model of perceptual learning.</s><s>To demonstrate how the Eighty Five Percent Rule might apply to learning in biological systems, we simulated the Law and Gold model of perceptual learning <ref type="bibr" target="#b10">11</ref> .</s><s>This model has been shown to capture the long term changes in behavior, neural firing and synaptic weights as monkeys learn to perform the Random Dot Motion task.</s></p><p><s>Specifically, the model assumes that monkeys make the perceptual decision between left and right on the basis of neural activity in area MT-an area in the dorsal visual stream that is known to represent motion information <ref type="bibr" target="#b14">15</ref> .</s><s>In the Random Dot Motion task, neurons in MT have been found to respond to both the direction θ and coherence COH of the dot motion stimulus such that each neuron responds most strongly to a particular 'preferred' direction and that the magnitude of this response increases with coherence.</s><s>This pattern of firing is well described by a simple set of equations (see "Methods") and thus the noisy population response, x, to a stimulus of arbitrary direction and coherence is easily simulated.</s></p><p><s>From this MT population response, Law and Gold proposed that animals construct a decision variable in a separate area of the brain (lateral interparietal area, LIP) as the weighted sum of activity in MT; i.e.,</s></p><formula xml:id="formula_17">h ¼ w Á x þ ϵ<label>ð18Þ</label></formula><p><s>where w are the weights between MT and LIP neurons and ϵ is random neuronal noise that cannot be reduced by learning.</s><s>The presence of this irreducible neural noise is a key difference between the Law and Gold model (Eq.</s><s>18) and the Perceptron (Eq.</s><s>11) as it means that no amount of learning can lead to perfect performance.</s><s>However, as shown in the Methods section, the presence of irreducible noise does not change the optimal accuracy for learning which is still 85%.</s><s>Another difference between the Perceptron and the Law and Gold model is the form of the learning rule.</s><s>In particular, weights are updated according to a reinforcement learning rule based on a reward prediction error</s></p><formula xml:id="formula_18">δ ¼ r À E½r ð<label>19Þ</label></formula><p><s>where r is the reward presented on the current trial (1 for a correct answer, 0 for an incorrect answer) and E[r] is the predicted reward</s></p><formula xml:id="formula_19">E½r ¼ 1 1 þ expðÀBjhjÞ<label>ð20Þ</label></formula><p><s>where B is a proportionality constant that is estimated online by the model (see "Methods").</s><s>Given the prediction error, the model updates its weights according to</s></p><formula xml:id="formula_20">w w þ ηCδx<label>ð21Þ</label></formula><p><s>where C is the choice (-1 for left, +1 for right) and η is the learning rate.</s><s>Despite the superficial differences with the Perceptron learning rule (Eq.</s><s>( <ref type="formula" target="#formula_12">13</ref>)) the Law and Gold model still implements stochastic gradient descent on the error rate <ref type="bibr" target="#b12">13</ref> and learning should be optimized at 85%.</s></p><p><s>To test this prediction we simulated the model at a variety of different target training error rates.</s><s>Each target training rate was simulated 100 times with different parameters for the MT neurons (see "Methods").</s><s>The precision, β, of the trained network was estimated by fitting simulated behavior of the network on a set of test coherences that varied logarithmically between 1 and 100%.</s><s>As shown in Fig. <ref type="figure" target="#fig_3">4a</ref> the precision after training is well described (up to a scale factor) by the theory.</s><s>In addition, in Fig. <ref type="figure" target="#fig_3">4b</ref>, we show the expected difference in behavior-in terms of psychometric choice curves-for three different training error rates.</s><s>While these differences are small, they are large enough that they could be distinguished experimentally.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p><s>In this article we considered the effect of training accuracy on learning in the case of binary classification tasks and stochastic gradient-descent-based learning rules.</s><s>We found that the rate of learning is maximized when the difficulty of training is adjusted to keep the training accuracy at around 85%.</s><s>We showed that training at the optimal accuracy proceeds exponentially faster than training at a fixed difficulty.</s><s>Finally we demonstrated the efficacy of the Eighty Five Percent Rule in the case of artificial and biologically plausible neural networks.</s></p><p><s>Our results have implications for a number of fields.</s><s>Perhaps most directly, our findings move towards a theory for identifying the optimal environmental settings in order to maximize the rate of gradient-based learning.</s><s>Thus the Eighty Five Percent Rule should hold for a wide range of machine learning algorithms including multilayered feedforward and recurrent neural networks (e.g.</s><s>including 'deep learning' networks using backpropagation <ref type="bibr" target="#b8">9</ref> , reservoir computing networks <ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> , as well as Perceptrons).</s><s>Of course, in these more complex situations, our assumptions may not always be met.</s><s>For example, as shown in the Methods, relaxing the assumption that the noise is Gaussian leads to changes in the optimal training accuracy: from 85% for Gaussian, to 82% for Laplacian noise, to 75% for Cauchy noise (Eq.</s><s>(31) in the "Methods").</s></p><p><s>More generally, extensions to this work should consider how batch-based training changes the optimal accuracy, and how the Eighty Five Percent Rule changes when there are more than two categories.</s><s>In batch learning, the optimal difficulty to select for the examples in each batch will likely depend on the rate of learning relative to the size of the batch.</s><s>If learning is slow, then selecting examples in a batch that satisfy the 85% rule may work, but if learning is fast, then mixing in more difficult examples may be best.</s><s>For multiple categories, it is likely possible to perform similar analyses, although the mapping between decision variable and categories will be more complex as will be the error rates which could be category specific (e.g., misclassifying category 1 as category 2 instead of category 3).</s></p><p><s>In Psychology and Cognitive Science, the Eighty Five Percent Rule accords with the informal intuition of many experimentalists that participant engagement is often maximized when tasks are neither too easy nor too hard.</s><s>Indeed it is notable that staircasing procedures (that aim to titrate task difficulty so that error rate is fixed during learning) are commonly designed to produce about 80-85% accuracy <ref type="bibr" target="#b16">17</ref> .</s><s>Similarly, when given a free choice about the difficulty of task they can perform, participants will spontaneously choose tasks of intermediate difficulty levels as they learn <ref type="bibr" target="#b22">23</ref> .</s><s>Despite the prevalence of this intuition, to the best of our knowledge no formal theoretical work has addressed the effect of training accuracy on learning, a test of which is an important direction for future work.</s></p><p><s>More generally, our work closely relates to the Region of Proximal Learning and Desirable Difficulty frameworks in education <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref> and Curriculum Learning and Self-Paced Learning <ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8</ref> in computer science.</s><s>These related, but distinct, frameworks propose that people and machines should learn best when training tasks involve just the right amount of difficulty.</s><s>In the Desirable Difficulties framework, the difficulty in the task must be of a 'desirable' kind, such as spacing practice over time, that promotes learning as opposed to an undesirable kind that does not.</s><s>In the Region of Proximal Learning framework, which builds on early work by Piaget <ref type="bibr" target="#b26">27</ref> and Vygotsky <ref type="bibr" target="#b27">28</ref> , this optimal difficulty is in a region of difficulty just beyond the person's current ability.</s><s>Curriculum and Self-Paced Learning in computer science build on similar intuitions, that machines should learn best when training examples are presented in order from easy to hard.</s><s>In practice, the optimal difficulty in all of these domains is determined empirically and is often dependent on many factors <ref type="bibr" target="#b28">29</ref> .</s><s>In this context, our work offers a way of deriving the desired difficulty and the region of proximal learning in the special case of binary classification tasks for which stochastic gradient-descent learning rules apply.</s><s>As such our work represents the first step towards a more mathematical instantiation of these theories, although it remains to be generalized to a broader class of circumstances, such as multi-choice tasks and different learning algorithms.</s></p><p><s>With regard to different learning algorithms, it is important to note that not all models will exhibit a sweet spot of difficulty for learning.</s><s>As an example, consider how a Bayesian learner with a perfect memory would infer parameters ϕ by computing the posterior distribution given past stimuli, x 1:t , and labels, y 1:t , pðϕjx 1:t ; y 1:t Þ / pðy 1:t jϕ;</s></p><formula xml:id="formula_21">x 1:t ÞpðϕÞ ¼ Q t i¼1 pðy i jϕ; x i ÞpðϕÞ<label>ð22Þ</label></formula><p><s>where the last line holds when the label depends only on the current stimulus.</s><s>Clearly this posterior distribution over parameters is independent of the ordering of the trials meaning that a Bayesian learner (with perfect memory) would learn equally well if hard or easy examples are presented first.</s><s>This is not to say that Bayesian learners cannot benefit from carefully constructed training sets, but that for a given set of training items the order of presentation has no bearing on what is ultimately learned.</s><s>This contrasts markedly with gradient-based algorithms, many of which try to approximate the maximum a posteriori solution of a Bayesian model, whose training is order dependent and whose learning is optimized with ∂ER/∂β.</s><s>Finally, we note that our analysis for maximizing the gradient, ∂ER/∂β, not only applies to learning but to any process that affects the precision of neural representations, such as attention, engagement, or more generally cognitive control <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31</ref> .</s><s>For example, attention is known to improve the precision with which sensory stimuli are represented in the brain, e.g., ref. <ref type="bibr" target="#b31">32</ref> .</s><s>If exerting control leads to a change in precision of δβ, then the change in error rate associated with exerting this control is</s></p><formula xml:id="formula_22">δER ¼ ∂ER ∂β δβ<label>ð23Þ</label></formula><p><s>This predicts that the benefits of engaging cognitive control should be maximized when ∂ER/∂β is maximized, that is at ER * .</s><s>More generally this relates to the Expected Value of Control theory <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33</ref> which suggests that the learning gradient, ∂ER/∂β, is monitored by control-related areas of the brain such as anterior cingulate cortex.</s><s>Along similar lines, our work points to a mathematical theory of the state of 'Flow' <ref type="bibr" target="#b33">34</ref> .</s><s>This state, 'in which an individual is completely immersed in an activity without reflective selfconsciousness but with a deep sense of control' [ref. <ref type="bibr" target="#b34">35</ref></s><s>, p. 1], is thought to occur most often when the demands of the task are well matched to the skills of the participant.</s><s>This idea of balance between skill and challenge was captured originally with a simple conceptual diagram (Fig. <ref type="figure" target="#fig_4">5</ref>) with two other states: 'anxiety' when challenge exceeds skill and 'boredom' when skill exceeds challenge.</s><s>These three qualitatively different regions (flow, anxiety, and boredom) arise naturally in our model.</s><s>Identifying the precision, β, with the level of skill and the level challenge with the inverse of true decision variable, 1/Δ, we see that when challenge equals skill, flow is associated with a high learning rate and accuracy, anxiety with low learning rate and accuracy and boredom with high accuracy but low learning rate (Fig. <ref type="figure" target="#fig_4">5b,</ref><ref type="figure">c</ref>).</s><s>Intriguingly, recent work by Vuorre and Metcalfe, has found that subjective feelings of Flow peaks on tasks that are subjectively rated as being of intermediate difficulty <ref type="bibr" target="#b35">36</ref> .</s><s>In addition work on learning to control brain computer interfaces finds that subjective, self-reported measures of 'optimal difficulty', peak at a difficulty associated with maximal learning, and not at a difficulty associated with optimal decoding of neural activity <ref type="bibr" target="#b36">37</ref> .</s><s>Going forward, it will be interesting to test whether these subjective measures of engagement peak at the point of maximal learning gradient, which for binary classification tasks is 85%.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p><s>Optimal error rate for learning.</s><s>In order to compute the optimal difficulty for training, we need to find the value of Δ that maximizes the learning gradient, ∂ER/ ∂β.</s><s>From Eq. (3) we have</s></p><formula xml:id="formula_23">∂ER ∂β ¼ ΔpðÀβΔÞ<label>ð24Þ</label></formula><p><s>From here the optimal difficulty, Δ * , can be found by computing the derivative of the gradient with respect to Δ, i.e.,</s></p><formula xml:id="formula_24">∂ ∂Δ ∂ER ∂β ¼ À ∂ ∂Δ ΔpðÀβΔÞ ð Þ ¼ À pðÀβΔÞ þ βΔ ∂pðxÞ ∂x x¼ÀβΔ<label>ð25Þ</label></formula><p><s>Setting this derivative equal to zero gives us the following expression for the optimal difficulty, Δ * , and error rate, ER *</s></p><formula xml:id="formula_25">βΔ Ã ¼ pðÀβΔ Ã Þ p′ðÀβΔ Ã Þ and ER Ã ¼ FðÀβΔ Ã Þ ð<label>26Þ</label></formula><p><s>where p′(x) denotes the derivative of p(x) with respect to x.</s><s>Because β and Δ * only ever appear together in these expressions, Eq. ( <ref type="formula" target="#formula_25">26</ref>) implies that βΔ * is a constant.</s><s>Thus, while the optimal difficulty, Δ * , changes as a function of precision (Fig. <ref type="figure" target="#fig_0">1c</ref>), the optimal training error rate, ER * does not (Fig. <ref type="figure" target="#fig_0">1d</ref>).</s><s>That is, training with the error rate clamped at ER * is guaranteed to maximize the rate of learning.</s><s>The exact value of ER * depends on the distribution of noise, n, in Eq. ( <ref type="formula" target="#formula_1">2</ref>).</s><s>In the case of Gaussian noise, we have</s></p><formula xml:id="formula_26">pðxÞ ¼ 1 ffiffiffiffiffi 2π p exp À x 2 2<label>ð27Þ</label></formula><p><s>which implies that</s></p><formula xml:id="formula_27">pðxÞ p′ðxÞ ¼ À 1 x<label>ð28Þ</label></formula><p><s>and that the optimal difficulty is</s></p><formula xml:id="formula_28">Δ Ã ¼ β À1<label>ð29Þ</label></formula><p><s>Consequently the optimal error rate for Gaussian noise is</s></p><formula xml:id="formula_29">ER Ã ¼ 1 2 1 À erf 1 ffiffi ffi 2 p % 0:1587<label>ð30Þ</label></formula><p><s>Similarly for Laplacian noise (pðxÞ ¼ 1 2 expðÀjxjÞ) and Cauchy noise (p(x) = (π(1 + x 2 )) -1 ) we have optimal error rates of</s></p><formula xml:id="formula_30">ER Ã Laplace ¼ 1 2 expðÀ1Þ % 0:1839 ER Ã Cauchy ¼ 1 π arctanðÀ1Þ þ 1 2 ¼ 0:25<label>ð31Þ</label></formula><p><s>Optimal learning with endogenous noise.</s><s>The above analyses for optimal training accuracy also applies in the case where the decision variable, h, is corrupted by endogenous, irreducible noise, ϵ, in addition to representation noise, n, that can be reduced by learning; i.e.,</s></p><formula xml:id="formula_31">h ¼ Δ þ n þ ϵ<label>ð32Þ</label></formula><p><s>In this case we can split the overall precision, β, into two components, one based on representational uncertainty that can be reduced, β n , and another based on endogenous uncertainty that cannot, β ϵ .</s><s>For Gaussian noise, these precisions are related to each other by</s></p><formula xml:id="formula_32">1 β 2 ¼ 1 β 2 n þ 1 β 2 ϵ<label>ð33Þ</label></formula><p><s>More generally, the precisions are related by some function, G, such that β = G(β n , β ϵ ).</s><s>Since only n can be reduced by learning, it makes sense to perform stochastic</s></p><formula xml:id="formula_33">dβ n dt ¼ À η ∂ER ∂β n ¼ À η ∂ER ∂β ∂β ∂β n<label>ð34Þ</label></formula><p><s>Note that ∂β/∂β n is independent of Δ so maximizing learning rate w.r.t.</s><s>Δ means maximizing ∂ER/∂β as before.</s><s>This implies that the optimal training difficulty will be the same, e.g., 85% for Gaussian noise, regardless whether endogenous noise is present or not.</s></p><p><s>Dynamics of learning.</s><s>To calculate the dynamics of learning we need to integrate Eq. ( <ref type="formula" target="#formula_6">7</ref>) over time.</s><s>This, of course depends on the learning gradient, ∂ER/∂β, which varies depending on the noise and whether the error rate or the true decision variable is fixed during training.</s></p><p><s>In the fixed error rate case, we fix the error rate during training to ER f .</s><s>This implies that the difficulty should change over time according to</s></p><formula xml:id="formula_34">ΔðtÞ ¼ À 1 βðtÞ F À1 ðER f Þ<label>ð35Þ</label></formula><p><s>where F -1 (⋅) is the inverse cdf.</s><s>This implies that β evolves over time according to</s></p><formula xml:id="formula_35">dβ dt ¼ Àη ∂ER ∂β ¼ ηΔðtÞpðÀβΔðtÞÞ ¼ À η βðtÞ F À1 ðER f ÞpðF À1 ðER f ÞÞ ¼ ηK f βðtÞ<label>ð36Þ</label></formula><p><s>where we have introduced K f as</s></p><formula xml:id="formula_36">K f ¼ ÀF À1 ðER f ÞpðF À1 ðER f ÞÞ<label>ð37Þ</label></formula><p><s>Integrating Eq. ( <ref type="formula" target="#formula_35">36</ref>) and solving for β(t) we get</s></p><formula xml:id="formula_37">βðtÞ ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi β 2 0 þ 2ηK f ðt À t 0 Þ q<label>ð38Þ</label></formula><p><s>where t 0 is the initial time point, and β 0 is the initial value of β.</s><s>Thus, for fixed error rate the precision grows as the square root of time with the rate determined by K f which depends on both the training error rate and the noise distribution.</s><s>For the optimal error rate we have, K f = p(-1).</s></p><p><s>In the fixed decision variable case, the true decision variable is fixed at Δ f and the error rate varies as a function of time.</s><s>In this case we have</s></p><formula xml:id="formula_38">dβ dt ¼ Àη ∂ER ∂β ¼ Δ f pðÀβΔ f Þ<label>ð39Þ</label></formula><p><s>Formally, this can be solved as</s></p><formula xml:id="formula_39">Z β β 0 1 pðÀβΔ f Þ dβ ¼ Δ f ðt À t 0 Þ<label>ð40Þ</label></formula><p><s>However, the exact form for β(t) will depend on p(x).</s></p><p><s>In the Gaussian case we cannot derive a closed form expression for β(t).</s><s>The closest we can get is to write</s></p><formula xml:id="formula_40">Z βΔ f ffi ffi 2 p 0 expðx 2 Þdx ¼ Z 0 β 0 Δ f ffi ffi 2 p expðx 2 Þdx þ Δ 2 2 ffiffiffi π p ðt À t 0 Þ<label>ð41Þ</label></formula><p><s>For long times, and large β, we can write Z</s></p><formula xml:id="formula_41">0 βΔ f ffi ffi 2 p expðx 2 Þdx &lt; exp β 2 Δ 2 f 2<label>ð42Þ</label></formula><p><s>which implies that for long times β grows slower than ffiffiffiffiffiffiffiffi ffi log t p , which is exponentially slower than the fixed error rate case.</s></p><p><s>In contrast to the Gaussian case, the Laplacian case lends itself to closed form analysis and we can derive the following expression for β</s></p><formula xml:id="formula_42">β ¼ 1 Δ f log expðβ 0 Δ f Þ þ 1 2 ηΔ 2 f ðt À t 0 Þ<label>ð43Þ</label></formula><p><s>Again this shows logarithmic dependence on t indicating that learning is much slower with a fixed difficulty.</s></p><p><s>In the case of Cauchy noise we can compute the integral in Eq. ( <ref type="formula" target="#formula_39">40</ref>) and find that β is the root of the following equation</s></p><formula xml:id="formula_43">Δ f 3 β 3 þ β ¼ Δ f 3 β 3 0 þ β 0 þ Δ f π ðt À t 0 Þ<label>ð44Þ</label></formula><p><s>For long training times this implies that β grows as the cube root of t.</s><s>Thus in the Cauchy case, while the rate of learning is still greatest at the optimal difficulty, the improvement is not as dramatic as in the other cases.</s></p><p><s>Application to the perceptron.</s><s>To implement the Perceptron example, we assumed that true labels t were generated by a 'Teacher Perceptron' <ref type="bibr" target="#b37">38</ref> with normalized weight vector, e. Learning was quantified by decomposing the learned weights w into two components: one proportional to e and a second orthogonal to e, i.e.,</s></p><formula xml:id="formula_44">w ¼ jwj e cos θ þ e ? sin θ ð Þ ð<label>45Þ</label></formula><p><s>where θ is the angle between w and e, and e ⊥ is the unit vector perpendicular to e in the plane defined by e and w.</s><s>This allows us to write the decision variable h in terms of signal and noise components as</s></p><formula xml:id="formula_45">h ¼ jwj ðe Á xÞ cos θ þ ðe ? Á xÞ sin θ ð Þ ¼ jwjð2t À 1ÞΔ cos θ |fflfflfflfflfflfflfflfflfflfflfflfflffl ffl{zfflfflfflfflfflfflfflfflfflfflfflfflffl ffl} signal þ jwjðe ? Á xÞ sin θ |fflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflffl} noise<label>ð46Þ</label></formula><p><s>where the difficulty Δ = |e ⋅ x| is the distance between x and the decision boundary, and the (2t -1) term simply controls which side of the boundary x is on.</s><s>This implies that the precision β is proportional to cot θ, with a constant of proportionality determined by the dimensionality of x.</s></p><p><s>In the case where the observations x are sampled from distributions that obey the central limit theorem, then the noise term is approximately Gaussian implying that the optimal error rate for training the Perceptron, ER * = 15.87%.</s></p><p><s>To test this prediction we simulated the Perceptron learning rule for a range of training error rates between 0.01 and 0.5 in steps of 0.01 (1000 simulations per error rate).</s><s>Stimuli, x, were 100 dimensional and independently sampled from a Gaussian distribution with mean 0 and variance 1.</s><s>Similarly, the true weights e were sampled from a mean 0, variance 1 Gaussian.</s><s>To mimic the effect of a modest degree of initial training, we initialized the weight vector w randomly with the constraint that |θ| &lt; 1.6π.</s><s>The difficulty Δ was adjusted on a trial-by-trial basis according to</s></p><formula xml:id="formula_46">Δ ¼ F À1 ðERÞλ tan θ<label>ð47Þ</label></formula><p><s>which ensures that the training error rate is clamped at ER.</s><s>The degree of learning was captured by the precision β.</s></p><p><s>Application to the two-layer neural network.</s><s>To implement the two-layer network, we built a sigmoidal neural network with one hidden layer (of 50 neurons) and one output neuron.</s><s>The weights between the input layer and the hidden layer and between the hidden layer and output layer were trained using the standard Backpropagation algorithm.</s></p><p><s>In order to clamp the error rate during training we first had to rate the images according to their 'difficulty'.</s><s>To this end, we trained a teacher network with the same basic architecture (i.e., 50 hidden units and 1 output unit) until its performance was near perfect (training error rate = 99.6% for the Parity Task and 99.4% for the Magnitude Task; test error rate = 97% for the Magnitude Task and 95.6% for the Parity Task).</s><s>We then used the absolute value of the decision variable from this network, |h teacher | as a proxy for the true difficulty, Δ-with larger values of |h teacher | indicating easier stimuli to classify.</s></p><p><s>Weights in the network were initialized randomly from a Gaussian distribution (mean 0, variance 1).</s><s>To achieve a fixed error rate during training, on each trial, we selected a stimulus that was closest to a target difficulty, h target .</s><s>This target difficulty was adjusted based on the performance of the network during training-increasing if the network classified the stimulus incorrectly, and decreasing if the network classified the stimulus correctly.</s><s>More specifically, the target difficulty was adjusted as</s></p><formula xml:id="formula_47">h target h target þ D A target À A av ð Þ ð<label>48Þ</label></formula><p><s>where D is the step size (=1), A target is the target training accuracy and A av is the running average of the accuracy from the last 50 trials.</s></p><p><s>On each trial we selected the 'eligible' stimulus whose value of h teacher was closest to h target .</s><s>To ensure that a given stimulus was not selected too often during training, stimuli were only eligible to be chosen if they had not been used in the last 50 trials.</s></p><p><s>Each initial state of the network was trained on either the Parity or Magnitude Task at a fixed training error rate between 5 and 30% in steps of 5%.</s><s>At the end of training performance was assessed on the whole test set.</s><s>This process was repeated 1000 times, with a new set of initial random weights each time.</s></p><p><s>Application to Law and Gold model.</s><s>The model of perceptual learning follows the exposition in Law and Gold 11 .</s><s>To aid comparison with that paper we retain almost all of their notation, with the three exceptions being their β parameter, which we rename as B to avoid confusion with the precision, their ϕ i parameter which we rename as F i to avoid confusion with the parameters of the learner, and their learning rate parameter α which we write as η.</s></p><p><s>Following Law and Gold <ref type="bibr" target="#b10">11</ref> , the average firing rate of an MT neuron, i, in response to a moving dot stimulus with direction θ and coherence COH is</s></p><formula xml:id="formula_48">m i ¼ Tðk 0 i þ COHðk n i þ ðk p i À k n i Þf ðθjΘ i ÞÞÞ<label>ð49Þ</label></formula><p><s>where T is the duration of the stimulus, k 0 i is the response of neuron i to a zeromotion coherence stimulus, k p i is the response to a stimulus moving in the preferred direction and k n i is the response to a stimulus in the null direction.</s><s>f(θ|Θ i ) is the tuning curve of the neuron around its preferred direction</s></p><formula xml:id="formula_49">Θ i f ðθjΘ i Þ ¼ exp À ðθ À Θ i Þ 2 2σ 2 θ<label>ð50Þ</label></formula><p><s>where σ θ (=30 degrees) is the width of the tuning curve which is assumed to be identical for all neurons.</s><s>Neural activity on each trial was assumed to be noisily distributed around this mean firing rate.</s><s>Specifically the activity, x i , of each neuron is given by a rectified (to ensure x i &gt; 0) sample from a Gaussian with mean m i and variance v i</s></p><formula xml:id="formula_50">v i ¼ F i m i<label>ð51Þ</label></formula><p><s>where F i is the Fano factor of the neuron.</s><s>Thus each MT neuron was characterized by five free parameters.</s><s>These free parameters were sampled randomly for each neuron such that θ i $ UðÀ180; 180Þ, k 0 i $ Uð0; 20Þ, k p i $ Uð0; 50Þ, k n i $ UðÀk 0 i ; 0Þ and F i $ Uð1; 5Þ.</s><s>Note that k n i is set between -k 0 i and 0 to ensure that the minimum average firing rate never dips below zero.</s><s>Each trial was defined by three task parameters: T = 1 s, Θ = ±90 degrees and COH which was adjusted based on performance to achieve a fixed error rate during training (see below).</s><s>As in the original paper, the number of neurons was set to 7200 and the learning rate, η was 10 -7 .</s></p><p><s>The predicted reward E[r] was computed according to Eq. (20).</s><s>In line with Law and Gold (Supplementary Fig. <ref type="figure" target="#fig_1">2</ref> in ref. <ref type="bibr" target="#b10">11</ref> ), the proportionality constant B was computed using logistic regression on the accuracy and absolute value of the decision variable, |h|, from last L trials, where L = min(300, t).</s></p><p><s>In addition to the weight update rule (Eq.</s><s>( <ref type="formula" target="#formula_20">21</ref>)), weights were normalized after each update to keep the sum of the squared weights, P i w 2 i ¼ w amp a constant (=0.02).</s><s>While this normalization has only a small overall effect (see Supplementary Material in ref. <ref type="bibr" target="#b10">11</ref> ), we replicate this weight normalization here for consistency with the original model.</s></p><p><s>To initialize the network, the first 50 trials of the simulation had a fixed coherence COH = 0.9.</s><s>After this initialization period, the coherence was adjusted according to the difference between the target accuracy, A target , and actual accuracy in the last L trials, A L , where L = min(300, t).</s><s>Specifically, the coherence on trial t was set as</s></p><formula xml:id="formula_51">COH t ¼ 1 1 þ expðÀΓ t Þ<label>ð52Þ</label></formula><p><s>where Γ t was adjusted according to</s></p><formula xml:id="formula_52">Γ tþ1 ¼ Γ t þ dΓðA target À A L Þ<label>ð53Þ</label></formula><p><s>and dΓ was 0.1.</s></p><p><s>To estimate the post-training precision parameter, β, we simulated behavior of the trained network on a set of 20 logarithmically spaced coherences between 10 -3 and 1. Behavior at each coherence was simulated 100 times and learning was disabled during this testing phase.</s><s>The precision parameter, β, was estimated using logistic regression between accuracy on each trial (0 or 1) and coherence; i.e.,</s></p><formula xml:id="formula_53">ACC $ 1 1 þ expðÀβ COHÞ<label>ð54Þ</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc><div><p><s>Fig.1Illustration of the model.</s><s>a Distributions over decision variable h given a particular difficulty, Δ = 16, with lower precision before learning and higher precision after learning.</s><s>The shaded regions corresponds to the error rate-the probability of making an incorrect response at each difficulty.</s><s>b The error rate as a function of difficulty before and after learning.</s><s>c The derivative that determines the rate of learning as a function of difficulty before and after learning showing that the optimal difficulty for learning is lower after learning than before.</s><s>d The same derivative as in c re-plotted as a function of error rate showing that the optimal error rate (at 15.87% or ~85% accuracy) is the same both before and after learning</s></p></div></figDesc><graphic coords="2,75.13,550.97,85.00,56.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc><div><p><s>Fig. 2 The Eighty Five Percent Rule applied to the Perceptron.</s><s>a The relative precision, β/β max , as a function of training error rate and training duration.</s><s>Training at the optimal error rate leads to the fastest learning throughout.</s><s>b The dynamics of learning agree well with the theory</s></p></div></figDesc><graphic coords="3,335.50,600.86,93.88,71.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc><div><p><s>Fig. 3 The Eighty Five Percent Rule applied to a multilayered neural network.</s><s>Test accuracy vs training error rate on the MNIST dataset for the a Parity and b Magnitude tasks for 1000 different simulations.</s><s>In both cases the test accuracy peaks at or near the optimal error rate.</s><s>Each color corresponds to a different target training accuracy</s></p></div></figDesc><graphic coords="4,76.57,575.72,85.72,85.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4</head><label>4</label><figDesc><div><p><s>Fig. 4 The Eighty Five Percent Rule applied to the Law and Gold model of perceptual learning.</s><s>a Precision of the trained network as function of training error rate.</s><s>Gray dots represent the results of individual simulations -note that the empirical error rate on each run often differs slightly from the target error rate due to noise.</s><s>Red dots correspond to the average precision and empirical error rate for each target error rate (error bars ± standard deviation in both measures).</s><s>b Accuracy as a function of coherence for the network trained at three different error rates corresponding to near optimal (ER = 0.17), too high (ER = 0.38) and too low (ER = 0.06)</s></p></div></figDesc><graphic coords="5,67.18,59.69,88.12,78.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5</head><label>5</label><figDesc><div><p><s>Fig. 5 Proposed relationship between the Eighty Five Percent Rule and Flow.</s><s>a Original model of flow as a state that is achieved when skill and challenge are well balanced.</s><s>Normalized learning rate, ∂ER/∂β, b and accuracy c as a function of skill and challenge suggests that flow corresponds to high learning and accuracy, boredom corresponds to low learning and high accuracy, while anxiety is associated with low learning and low accuracy</s></p></div></figDesc><graphic coords="6,393.19,66.47,98.44,97.72" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p><s>NATURE COMMUNICATIONS | (2019) 10:4646 | https://doi.org/10.1038/s41467-019-12552-4</s><s>| www.nature.com/naturecommunications</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This project was made possible through the support of a grant from the <rs type="funder">John Templeton Foundation</rs> to J.D.C., a <rs type="grantName">Center of Biomedical Research Excellence grant</rs> <rs type="grantNumber">P20GM103645</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9TjY3cr">
					<idno type="grant-number">P20GM103645</idno>
					<orgName type="grant-name">Center of Biomedical Research Excellence grant</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p><s>Data sharing not applicable to this article as no datasets were generated or analysed during the current study.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p><s>All code is publicly available on GitHub at https://github.com/bobUA/</s><s>EightyFivePercentRule</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s>from the National Institute of General Medical Sciences to A.S., and National Institute on Aging grant R56 AG061888 to R.C.W.</s><s>The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of the funders.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p><s>R.C.W., A.S., M.S., and J.D.C. developed the idea and wrote the paper.</s><s>R.C.W. derived mathematical results and ran simulations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p><s>The authors declare no competing interests.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The goldilocks effect: Human infants allocate attention to visual sequences that are neither too simple nor too complex</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kidd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Piantadosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">36399</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metacognitive judgments and control of study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Metcalfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Directions Psychological Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="159" to="163" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The Behavior of Organisms: An Experimental Analysis. (D. appleton-century company</title>
		<author>
			<persName><forename type="first">B</forename><surname>Skinner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1938">1938</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The transfer of a discrimination along a continuum</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Physiological Psychol</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">511</biblScope>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning and development in neural networks: the importance of starting small</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="71" to="99" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Flexible shaping: how learning in small steps helps</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="380" to="394" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. modeling</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reinforcement learning can account for associative and perceptual learning on a visual-decision task</title>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="655" to="663" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Time scales of adaptive behavior and motor learning in the presence of stochastic perturbations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Schöllhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mayer-Kress</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Michelbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Mov. Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="319" to="333" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Rev</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">386</biblScope>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A selective impairment of motion perception following lesions of the middle temporal visual area (mt)</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Pare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2201" to="2211" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The analysis of visual motion: a comparison of neuronal and psychophysical performance</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Britten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="4745" to="4765" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Forced-choice staircases with fixed step sizes: asymptotic and small-sample properties</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Garca-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1861" to="1881" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Mackay</surname></persName>
		</author>
		<title level="m">Information Theory, Inference and Learning Algorithms</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<title level="m">The mnist database of handwritten digits</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The echo state approach to analysing and training recurrent neural networks-with an erratum note</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bonn., Ger.: Ger. Natl. Res. Cent. Inf. Technol. GMD Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Real-time computing without stable states: a new framework for neural computation based on perturbations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Natschläger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Markram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2531" to="2560" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The effects of task difficulty, novelty and the size of the search space on intrinsically motivated exploration</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Baranes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gottlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">317</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A region of proximal learning model of study time allocation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Metcalfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mem. Lang</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="463" to="477" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bjork</surname></persName>
		</author>
		<title level="m">Metacognition: Knowing about Knowing</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Metcalfe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Shimamura</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="185" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A reconsideration of cognitive load theory</title>
		<author>
			<persName><forename type="first">W</forename><surname>Schnotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kürschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educ. Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="469" to="508" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Piaget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Origins of Intelligence in Children</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="1952">1952</date>
			<publisher>International Universities Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The Collected Works of LS Vygotsky: Problems of the Theory and History of Psychology</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Vygotsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning from errors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Metcalfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="465" to="489" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The expected value of control: an integrative theory of anterior cingulate cortex function</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="217" to="240" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Toward a rational and mechanistic account of mental effort</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="99" to="124" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention enhances synaptic efficacy and the signal-to-noise ratio in neural circuits</title>
		<author>
			<persName><forename type="first">F</forename><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Mangun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Usrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">499</biblScope>
			<biblScope unit="page" from="476" to="480" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learned predictions of error likelihood in the anterior cingulate cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Braver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">307</biblScope>
			<biblScope unit="page" from="1118" to="1121" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Csikszentmihalyi</surname></persName>
		</author>
		<title level="m">Beyond Boredom and Anxiety</title>
		<imprint>
			<publisher>Jossey-Bass</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Engeser</surname></persName>
		</author>
		<title level="m">Advances in Flow Research</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The relation between the sense of agency and the experience of flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vuorre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Metcalfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conscious. Cognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="133" to="142" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Closed-loop adaptation of neurofeedback based on mental effort facilitates reinforcement learning of brain self-regulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Royter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gharabaghi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="3156" to="3164" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving a network generalization ability by selecting examples</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kinzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rujan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europhys. Lett</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="473" to="477" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
